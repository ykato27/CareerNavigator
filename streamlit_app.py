"""
ã‚­ãƒ£ãƒªã‚¢æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  Streamlitã‚¢ãƒ—ãƒª - ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
"""

import os
import tempfile

import streamlit as st
import pandas as pd

from skillnote_recommendation.core.data_loader import DataLoader
from skillnote_recommendation.core.data_transformer import DataTransformer


# =========================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =========================================================
st.set_page_config(
    page_title="ã‚­ãƒ£ãƒªã‚¢æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿",
    page_icon="ğŸ“",
    layout="wide"
)

st.title("ğŸ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
st.markdown("**ã‚¹ãƒ†ãƒƒãƒ—1**: 6ç¨®é¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã™ã€‚")


# =========================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
# =========================================================
def _init_session_state():
    defaults = {
        "data_loaded": False,
        "model_trained": False,
        "raw_data": None,
        "transformed_data": None,
        "ml_recommender": None,
        "temp_dir": None,
        "last_recommendations_df": None,
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


_init_session_state()


# =========================================================
# è£œåŠ©é–¢æ•°
# =========================================================
def load_csv_to_memory(uploaded_file) -> pd.DataFrame:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå˜ä¸€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’DataFrameã«èª­ã¿è¾¼ã‚€"""
    return pd.read_csv(uploaded_file, encoding="utf-8-sig")


def save_uploaded_files(temp_dir: str, subdir_name: str, uploaded_files):
    """
    æŒ‡å®šã‚«ãƒ†ã‚´ãƒªç”¨ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—
    ãã®ä¸­ã«è¤‡æ•°ã®CSVã‚’UTF-8ã§ä¿å­˜ã™ã‚‹
    """
    category_dir = os.path.join(temp_dir, subdir_name)
    os.makedirs(category_dir, exist_ok=True)

    for i, file in enumerate(uploaded_files):
        df = load_csv_to_memory(file)
        filename_base = os.path.splitext(file.name)[0]
        out_path = os.path.join(category_dir, f"{filename_base}_{i+1}.csv")
        df.to_csv(out_path, index=False, encoding="utf-8-sig")


def create_temp_dir_with_csv(uploaded_dict: dict) -> str:
    """
    ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®è¤‡æ•°CSVã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸‹ã«ä¿å­˜ã™ã‚‹
    """
    temp_dir = tempfile.mkdtemp()
    for category, files in uploaded_dict.items():
        if files:
            save_uploaded_files(temp_dir, category, files)
    return temp_dir


def build_transformed_data(raw_data: dict) -> dict:
    """
    DataTransformerã‚’ä½¿ã„
    æ¨è–¦ã‚„å­¦ç¿’ã«ä½¿ã†å½¢å¼ã«ã¾ã¨ã‚ã‚‹
    """
    transformer = DataTransformer()

    competence_master = transformer.create_competence_master(raw_data)
    member_competence, valid_members = transformer.create_member_competence(
        raw_data,
        competence_master
    )
    skill_matrix = transformer.create_skill_matrix(member_competence)
    members_clean = transformer.clean_members_data(raw_data)

    transformed_data = {
        "competence_master": competence_master,
        "member_competence": member_competence,
        "skill_matrix": skill_matrix,
        "members_clean": members_clean,
        "valid_members": valid_members,
    }
    return transformed_data


# =========================================================
# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UI
# =========================================================
st.subheader("ğŸ“¤ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

st.info("ä»¥ä¸‹ã®6ç¨®é¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

uploaded_dict = {}

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### 1ï¸âƒ£ ãƒ¡ãƒ³ãƒãƒ¼")
    uploaded_dict["members"] = st.file_uploader(
        "ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="members"
    )

    st.markdown("#### 2ï¸âƒ£ ã‚¹ã‚­ãƒ«")
    uploaded_dict["skills"] = st.file_uploader(
        "åŠ›é‡ï¼ˆã‚¹ã‚­ãƒ«ï¼‰ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="skills"
    )

    st.markdown("#### 3ï¸âƒ£ æ•™è‚²")
    uploaded_dict["education"] = st.file_uploader(
        "åŠ›é‡ï¼ˆæ•™è‚²ï¼‰ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="education"
    )

with col2:
    st.markdown("#### 4ï¸âƒ£ è³‡æ ¼")
    uploaded_dict["license"] = st.file_uploader(
        "åŠ›é‡ï¼ˆè³‡æ ¼ï¼‰ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="license"
    )

    st.markdown("#### 5ï¸âƒ£ ã‚«ãƒ†ã‚´ãƒªãƒ¼")
    uploaded_dict["categories"] = st.file_uploader(
        "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="categories"
    )

    st.markdown("#### 6ï¸âƒ£ ä¿æœ‰åŠ›é‡")
    uploaded_dict["acquired"] = st.file_uploader(
        "ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="acquired"
    )


# =========================================================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
# =========================================================
all_uploaded = all(uploaded_dict.values())

if all_uploaded:
    if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", type="primary"):
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            try:
                # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
                temp_dir = create_temp_dir_with_csv(uploaded_dict)

                # DataLoaderã§èª­ã¿è¾¼ã¿
                loader = DataLoader(temp_dir)
                raw_data = loader.load_all_data()

                # DataTransformerã§å¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
                transformed_data = build_transformed_data(raw_data)

                # Knowledge Graphã‚’æ§‹ç¯‰
                from skillnote_recommendation.graph import CompetenceKnowledgeGraph

                with st.spinner("Knowledge Graphã‚’æ§‹ç¯‰ä¸­..."):
                    knowledge_graph = CompetenceKnowledgeGraph(
                        member_competence=transformed_data['member_competence'],
                        member_master=transformed_data['members_clean'],
                        competence_master=transformed_data['competence_master']
                    )

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.temp_dir = temp_dir
                st.session_state.raw_data = raw_data
                st.session_state.transformed_data = transformed_data
                st.session_state.knowledge_graph = knowledge_graph
                st.session_state.data_loaded = True

                # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                st.session_state.model_trained = False
                st.session_state.ml_recommender = None
                st.session_state.last_recommendations_df = None

                st.success("âœ… ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚")
                st.info("ğŸ‘‰ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¦ã€MLãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")

            except Exception as e:
                import traceback
                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {e}")

                # è©³ç´°ãªãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’è¡¨ç¤º
                with st.expander("ğŸ” è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º"):
                    st.code(traceback.format_exc())

                    st.markdown("### ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
                    st.write("**ã‚¨ãƒ©ãƒ¼å‹:**", type(e).__name__)
                    st.write("**ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:**", str(e))

                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±
                    st.markdown("### ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«")
                    for category, files in uploaded_dict.items():
                        if files:
                            st.write(f"**{category}:**", [f.name for f in files])

                    st.info("ğŸ’¡ ã“ã®ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã—ã¦é–‹ç™ºè€…ã«å…±æœ‰ã—ã¦ãã ã•ã„ã€‚")
else:
    st.warning("å…¨ã¦ã®ã‚«ãƒ†ã‚´ãƒªã§å°‘ãªãã¨ã‚‚1ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")


# =========================================================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿çŠ¶æ…‹ã®è¡¨ç¤º
# =========================================================
if st.session_state.data_loaded:
    st.markdown("---")
    st.subheader("ğŸ“Š èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦")

    td = st.session_state.transformed_data

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("ãƒ¡ãƒ³ãƒãƒ¼æ•°", len(td["members_clean"]))

    with col2:
        st.metric("åŠ›é‡æ•°", len(td["competence_master"]))

    with col3:
        st.metric("ä¿æœ‰åŠ›é‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", len(td["member_competence"]))

    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    with st.expander("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
        st.markdown("#### ãƒ¡ãƒ³ãƒãƒ¼")
        st.dataframe(td["members_clean"].head(10))

        st.markdown("#### åŠ›é‡ãƒã‚¹ã‚¿")
        st.dataframe(td["competence_master"].head(10))

        st.markdown("#### ãƒ¡ãƒ³ãƒãƒ¼ä¿æœ‰åŠ›é‡")
        st.dataframe(td["member_competence"].head(10))

else:
    st.markdown("---")
    st.markdown("### ğŸ“Œ å¿…è¦ãªãƒ‡ãƒ¼ã‚¿")
    st.markdown(
        "1. **ãƒ¡ãƒ³ãƒãƒ¼**: ç™»éŒ²ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±\n"
        "2. **åŠ›é‡ï¼ˆã‚¹ã‚­ãƒ«ï¼‰**: ã‚¹ã‚­ãƒ«ãƒã‚¹ã‚¿\n"
        "3. **åŠ›é‡ï¼ˆæ•™è‚²ï¼‰**: ç ”ä¿®ãƒã‚¹ã‚¿\n"
        "4. **åŠ›é‡ï¼ˆè³‡æ ¼ï¼‰**: è³‡æ ¼ãƒã‚¹ã‚¿\n"
        "5. **åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼**: ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒã‚¹ã‚¿\n"
        "6. **ä¿æœ‰åŠ›é‡**: ãƒ¡ãƒ³ãƒãƒ¼ã®ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿"
    )

