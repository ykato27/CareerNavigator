"""
CareerNavigator - AIã‚­ãƒ£ãƒªã‚¢æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ 

ã‚¹ã‚­ãƒ«ãƒ‡ãƒ¼ã‚¿ã¨æ©Ÿæ¢°å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸã€ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ãªã‚­ãƒ£ãƒªã‚¢é–‹ç™ºæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import tempfile

import streamlit as st
import pandas as pd

from skillnote_recommendation.core.data_loader import DataLoader
from skillnote_recommendation.core.data_transformer import DataTransformer
from skillnote_recommendation.utils.ui_components import (
    apply_enterprise_styles,
    render_page_header
)


# =========================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =========================================================
st.set_page_config(
    page_title="CareerNavigator - ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿",
    page_icon="ğŸ§­",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Apply enterprise UI styles
apply_enterprise_styles()

# ãƒšãƒ¼ã‚¸ãƒ˜ãƒƒãƒ€ãƒ¼
render_page_header(
    title="ğŸ§­ CareerNavigator",
    icon="ğŸ“",
    description="ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ - 6ç¨®é¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã™"
)


# =========================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
# =========================================================
def _init_session_state():
    defaults = {
        "data_loaded": False,
        "model_trained": False,
        "raw_data": None,
        "transformed_data": None,
        "ml_recommender": None,
        "temp_dir": None,
        "last_recommendations_df": None,
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


_init_session_state()


# =========================================================
# è£œåŠ©é–¢æ•°
# =========================================================
def load_csv_to_memory(uploaded_file) -> pd.DataFrame:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå˜ä¸€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’DataFrameã«èª­ã¿è¾¼ã‚€"""
    return pd.read_csv(uploaded_file, encoding="utf-8-sig")


def save_uploaded_files(temp_dir: str, subdir_name: str, uploaded_files):
    """
    æŒ‡å®šã‚«ãƒ†ã‚´ãƒªç”¨ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—
    ãã®ä¸­ã«è¤‡æ•°ã®CSVã‚’UTF-8ã§ä¿å­˜ã™ã‚‹
    """
    category_dir = os.path.join(temp_dir, subdir_name)
    os.makedirs(category_dir, exist_ok=True)

    for i, file in enumerate(uploaded_files):
        df = load_csv_to_memory(file)
        filename_base = os.path.splitext(file.name)[0]
        out_path = os.path.join(category_dir, f"{filename_base}_{i+1}.csv")
        df.to_csv(out_path, index=False, encoding="utf-8-sig")


def create_temp_dir_with_csv(uploaded_dict: dict) -> str:
    """
    ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®è¤‡æ•°CSVã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸‹ã«ä¿å­˜ã™ã‚‹
    """
    temp_dir = tempfile.mkdtemp()
    for category, files in uploaded_dict.items():
        if files:
            save_uploaded_files(temp_dir, category, files)
    return temp_dir


def build_transformed_data(raw_data: dict) -> dict:
    """
    DataTransformerã‚’ä½¿ã„
    æ¨è–¦ã‚„å­¦ç¿’ã«ä½¿ã†å½¢å¼ã«ã¾ã¨ã‚ã‚‹
    """
    transformer = DataTransformer()

    competence_master = transformer.create_competence_master(raw_data)
    member_competence, valid_members = transformer.create_member_competence(
        raw_data,
        competence_master
    )
    skill_matrix = transformer.create_skill_matrix(member_competence)
    members_clean = transformer.clean_members_data(raw_data)

    transformed_data = {
        "competence_master": competence_master,
        "member_competence": member_competence,
        "skill_matrix": skill_matrix,
        "members_clean": members_clean,
        "valid_members": valid_members,
    }
    return transformed_data


# =========================================================
# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UI
# =========================================================
st.subheader("ğŸ“¤ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

st.info("ä»¥ä¸‹ã®6ç¨®é¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

uploaded_dict = {}

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### 1ï¸âƒ£ ãƒ¡ãƒ³ãƒãƒ¼")
    uploaded_dict["members"] = st.file_uploader(
        "ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="members"
    )

    st.markdown("#### 2ï¸âƒ£ ã‚¹ã‚­ãƒ«")
    uploaded_dict["skills"] = st.file_uploader(
        "åŠ›é‡ï¼ˆã‚¹ã‚­ãƒ«ï¼‰ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="skills"
    )

    st.markdown("#### 3ï¸âƒ£ æ•™è‚²")
    uploaded_dict["education"] = st.file_uploader(
        "åŠ›é‡ï¼ˆæ•™è‚²ï¼‰ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="education"
    )

with col2:
    st.markdown("#### 4ï¸âƒ£ è³‡æ ¼")
    uploaded_dict["license"] = st.file_uploader(
        "åŠ›é‡ï¼ˆè³‡æ ¼ï¼‰ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="license"
    )

    st.markdown("#### 5ï¸âƒ£ ã‚«ãƒ†ã‚´ãƒªãƒ¼")
    uploaded_dict["categories"] = st.file_uploader(
        "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒã‚¹ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="categories"
    )

    st.markdown("#### 6ï¸âƒ£ ä¿æœ‰åŠ›é‡")
    uploaded_dict["acquired"] = st.file_uploader(
        "ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿",
        type=["csv"],
        accept_multiple_files=True,
        key="acquired"
    )


# =========================================================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
# =========================================================
all_uploaded = all(uploaded_dict.values())

if all_uploaded:
    if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", type="primary"):
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            try:
                # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
                temp_dir = create_temp_dir_with_csv(uploaded_dict)

                # DataLoaderã§èª­ã¿è¾¼ã¿
                loader = DataLoader(temp_dir)
                raw_data = loader.load_all_data()

                # DataTransformerã§å¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
                transformed_data = build_transformed_data(raw_data)

                # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
                if transformed_data['member_competence'].empty:
                    st.error("âŒ ãƒ¡ãƒ³ãƒãƒ¼ã®ç¿’å¾—åŠ›é‡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
                    st.warning(
                        "**ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:**\n\n"
                        "1. **ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿ (acquiredCompetenceLevel.csv)** ã«ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹\n"
                        "2. **å¿…é ˆã‚«ãƒ©ãƒ **ãŒå­˜åœ¨ã™ã‚‹ã‹:\n"
                        "   - ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰\n"
                        "   - åŠ›é‡ã‚³ãƒ¼ãƒ‰\n"
                        "   - åŠ›é‡ã‚¿ã‚¤ãƒ—\n"
                        "   - ãƒ¬ãƒ™ãƒ«\n"
                        "3. **ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿**ã«æœ‰åŠ¹ãªãƒ¡ãƒ³ãƒãƒ¼ï¼ˆå‰Šé™¤ãƒ»ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ä»¥å¤–ï¼‰ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‹\n"
                        "4. **ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ä¸€è‡´**: ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿ã¨ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹\n"
                        "   - å…¨è§’/åŠè§’ã€ã‚¹ãƒšãƒ¼ã‚¹ã€å¤§æ–‡å­—/å°æ–‡å­—ãªã©ã«æ³¨æ„"
                    )

                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                    with st.expander("ğŸ” è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=True):
                        st.markdown("### ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿")
                        members_df = transformed_data['members_clean']
                        st.write(f"**æœ‰åŠ¹ãªãƒ¡ãƒ³ãƒãƒ¼æ•°**: {len(members_df)}å")
                        if not members_df.empty:
                            st.write("**ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ä¾‹ï¼ˆå…ˆé ­10ä»¶ï¼‰:**")
                            member_codes = members_df['ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰'].head(10).tolist()
                            for i, code in enumerate(member_codes, 1):
                                st.code(f"{i}. [{type(code).__name__}] '{code}' (é•·ã•: {len(str(code))})")
                            st.dataframe(members_df.head())
                        else:
                            st.warning("æœ‰åŠ¹ãªãƒ¡ãƒ³ãƒãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                        st.markdown("---")
                        st.markdown("### ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰")
                        acquired_raw = raw_data.get('acquired', pd.DataFrame())
                        st.write(f"**ç·è¡Œæ•°**: {len(acquired_raw)}ä»¶")
                        st.write(f"**ã‚«ãƒ©ãƒ **: {list(acquired_raw.columns)}")
                        if not acquired_raw.empty:
                            st.write("**ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ä¾‹ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå…ˆé ­10ä»¶ï¼‰:**")
                            acquired_codes = acquired_raw['ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰'].dropna().unique()[:10]
                            for i, code in enumerate(acquired_codes, 1):
                                st.code(f"{i}. [{type(code).__name__}] '{code}' (é•·ã•: {len(str(code))})")
                            st.dataframe(acquired_raw.head())
                        else:
                            st.warning("ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

                        # ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ä¸€è‡´ãƒã‚§ãƒƒã‚¯
                        if not members_df.empty and not acquired_raw.empty:
                            st.markdown("---")
                            st.markdown("### ğŸ” ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ä¸€è‡´ç¢ºèª")
                            member_codes_set = set(members_df['ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰'].unique())
                            acquired_codes_set = set(acquired_raw['ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰'].dropna().unique())
                            matching_codes = member_codes_set & acquired_codes_set

                            st.write(f"**ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æ•°**: {len(member_codes_set)}")
                            st.write(f"**ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æ•°**: {len(acquired_codes_set)}")
                            st.write(f"**ä¸€è‡´ã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æ•°**: {len(matching_codes)}")

                            if len(matching_codes) == 0:
                                st.error("âš ï¸ ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãŒ1ã¤ã‚‚ä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ï¼")
                                st.write("**å‹ã‚„å½¢å¼ã®é•ã„ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š**")
                                st.write("- ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰å‹:", type(list(member_codes_set)[0]).__name__ if member_codes_set else "N/A")
                                st.write("- ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰å‹:", type(list(acquired_codes_set)[0]).__name__ if acquired_codes_set else "N/A")
                            else:
                                st.success(f"âœ… {len(matching_codes)}ä»¶ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ã¦ã„ã¾ã™")
                                st.write("**ä¸€è‡´ä¾‹ï¼ˆå…ˆé ­5ä»¶ï¼‰:**", list(matching_codes)[:5])

                    st.info("ğŸ’¡ ã‚ˆã‚Šè©³ç´°ãªãƒ­ã‚°æƒ…å ±ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã¾ãŸã¯ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    st.stop()

                # Knowledge Graphã‚’æ§‹ç¯‰
                from skillnote_recommendation.graph import CompetenceKnowledgeGraph

                with st.spinner("Knowledge Graphã‚’æ§‹ç¯‰ä¸­..."):
                    knowledge_graph = CompetenceKnowledgeGraph(
                        member_competence=transformed_data['member_competence'],
                        member_master=transformed_data['members_clean'],
                        competence_master=transformed_data['competence_master']
                    )

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.temp_dir = temp_dir
                st.session_state.raw_data = raw_data
                st.session_state.transformed_data = transformed_data
                st.session_state.knowledge_graph = knowledge_graph
                st.session_state.data_loaded = True

                # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                st.session_state.model_trained = False
                st.session_state.ml_recommender = None
                st.session_state.last_recommendations_df = None

                st.success("âœ… ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚")
                st.info("ğŸ‘‰ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¦ã€MLãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")

            except Exception as e:
                import traceback
                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {e}")

                # è©³ç´°ãªãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’è¡¨ç¤º
                with st.expander("ğŸ” è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º"):
                    st.code(traceback.format_exc())

                    st.markdown("### ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
                    st.write("**ã‚¨ãƒ©ãƒ¼å‹:**", type(e).__name__)
                    st.write("**ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:**", str(e))

                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±
                    st.markdown("### ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«")
                    for category, files in uploaded_dict.items():
                        if files:
                            st.write(f"**{category}:**", [f.name for f in files])

                    st.info("ğŸ’¡ ã“ã®ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã—ã¦é–‹ç™ºè€…ã«å…±æœ‰ã—ã¦ãã ã•ã„ã€‚")
else:
    st.warning("å…¨ã¦ã®ã‚«ãƒ†ã‚´ãƒªã§å°‘ãªãã¨ã‚‚1ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")


# =========================================================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿çŠ¶æ…‹ã®è¡¨ç¤º
# =========================================================
if st.session_state.data_loaded:
    st.markdown("---")
    st.subheader("ğŸ“Š èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦")

    td = st.session_state.transformed_data

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("ãƒ¡ãƒ³ãƒãƒ¼æ•°", len(td["members_clean"]))

    with col2:
        st.metric("åŠ›é‡æ•°", len(td["competence_master"]))

    with col3:
        st.metric("ä¿æœ‰åŠ›é‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", len(td["member_competence"]))

    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    with st.expander("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
        st.markdown("#### ãƒ¡ãƒ³ãƒãƒ¼")
        st.dataframe(td["members_clean"].head(10))

        st.markdown("#### åŠ›é‡ãƒã‚¹ã‚¿")
        st.dataframe(td["competence_master"].head(10))

        st.markdown("#### ãƒ¡ãƒ³ãƒãƒ¼ä¿æœ‰åŠ›é‡")
        st.dataframe(td["member_competence"].head(10))

else:
    st.markdown("---")
    st.markdown("### ğŸ“Œ å¿…è¦ãªãƒ‡ãƒ¼ã‚¿")
    st.markdown(
        "1. **ãƒ¡ãƒ³ãƒãƒ¼**: ç™»éŒ²ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±\n"
        "2. **åŠ›é‡ï¼ˆã‚¹ã‚­ãƒ«ï¼‰**: ã‚¹ã‚­ãƒ«ãƒã‚¹ã‚¿\n"
        "3. **åŠ›é‡ï¼ˆæ•™è‚²ï¼‰**: ç ”ä¿®ãƒã‚¹ã‚¿\n"
        "4. **åŠ›é‡ï¼ˆè³‡æ ¼ï¼‰**: è³‡æ ¼ãƒã‚¹ã‚¿\n"
        "5. **åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼**: ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒã‚¹ã‚¿\n"
        "6. **ä¿æœ‰åŠ›é‡**: ãƒ¡ãƒ³ãƒãƒ¼ã®ä¿æœ‰åŠ›é‡ãƒ‡ãƒ¼ã‚¿"
    )

