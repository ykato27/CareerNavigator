"""
CareerNavigator - ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨åˆ†æ
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go

from skillnote_recommendation.ml.ml_recommender import MLRecommender
from skillnote_recommendation.utils.ui_components import (
    apply_rich_ui_styles,
    render_gradient_header
)
from skillnote_recommendation.ml.optuna_visualization_helper import (
    generate_optuna_visualizations,
    get_best_trials_summary,
    get_pruned_trials_count,
    plot_training_history,
)


# =========================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =========================================================
st.set_page_config(
    page_title="CareerNavigator - ãƒ¢ãƒ‡ãƒ«å­¦ç¿’",
    page_icon="ğŸ§­",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Apply rich UI styles
apply_rich_ui_styles()

# ãƒªãƒƒãƒãªãƒ˜ãƒƒãƒ€ãƒ¼
render_gradient_header(
    title="ğŸ§­ CareerNavigator",
    icon="ğŸ¤–",
    description="ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨åˆ†æ - AIãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€å­¦ç¿’çµæœã‚’åˆ†æã—ã¾ã™"
)


# =========================================================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒã‚§ãƒƒã‚¯
# =========================================================
if not st.session_state.get("data_loaded", False):
    st.warning("âš ï¸ ã¾ãšãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
    st.info("ğŸ‘‰ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€ãƒšãƒ¼ã‚¸ã«æˆ»ã£ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()


# =========================================================
# è£œåŠ©é–¢æ•°
# =========================================================
def build_ml_recommender(
    transformed_data: dict,
    use_preprocessing: bool = True,
    use_tuning: bool = False,
    tuning_n_trials: int = None,
    tuning_timeout: int = None,
    tuning_search_space: dict = None,
    tuning_sampler: str = None,
    tuning_random_state: int = None,
    tuning_progress_callback = None
) -> MLRecommender:
    """
    MLRecommenderã‚’å­¦ç¿’æ¸ˆã¿ã®çŠ¶æ…‹ã§ä½œæˆã™ã‚‹

    Args:
        transformed_data: å¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        use_preprocessing: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        use_tuning: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        tuning_n_trials: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è©¦è¡Œå›æ•°
        tuning_timeout: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        tuning_search_space: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¢ç´¢ç©ºé–“
        tuning_sampler: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ©ãƒ¼
        tuning_random_state: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰
        tuning_progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
    if transformed_data is None:
        raise ValueError("transformed_data ãŒ None ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    if not isinstance(transformed_data, dict):
        raise TypeError(f"transformed_data ã¯ dict å‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®Ÿéš›ã®å‹: {type(transformed_data).__name__}")

    # å¿…è¦ãªã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª
    required_keys = ["member_competence", "competence_master", "members_clean"]
    missing_keys = [key for key in required_keys if key not in transformed_data]
    if missing_keys:
        raise KeyError(f"å¿…è¦ãªã‚­ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_keys)}ã€‚åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ¼: {', '.join(transformed_data.keys())}")

    recommender = MLRecommender.build(
        member_competence=transformed_data["member_competence"],
        competence_master=transformed_data["competence_master"],
        member_master=transformed_data["members_clean"],
        use_preprocessing=use_preprocessing,
        use_tuning=use_tuning,
        tuning_n_trials=tuning_n_trials,
        tuning_timeout=tuning_timeout,
        tuning_search_space=tuning_search_space,
        tuning_sampler=tuning_sampler,
        tuning_random_state=tuning_random_state,
        tuning_progress_callback=tuning_progress_callback
    )
    return recommender


# =========================================================
# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# =========================================================
st.subheader("ğŸ“ MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’")

if st.session_state.get("model_trained", False):
    st.success("âœ… MLãƒ¢ãƒ‡ãƒ«ã¯æ—¢ã«å­¦ç¿’æ¸ˆã¿ã§ã™ã€‚")

    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆå­¦ç¿’å¾Œã‚‚ä¿æŒï¼‰
    if st.session_state.get("show_debug_info", False) and st.session_state.get("debug_messages"):
        with st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆå‰å›ã®å­¦ç¿’ï¼‰", expanded=False):
            st.code("\n".join(st.session_state.debug_messages))

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒœã‚¿ãƒ³
            if st.button("ğŸ—‘ï¸ ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚¯ãƒªã‚¢"):
                st.session_state.show_debug_info = False
                st.rerun()

    if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã™ã‚‹"):
        st.session_state.model_trained = False
        st.session_state.ml_recommender = None
        st.session_state.show_debug_info = False
        st.rerun()
else:
    st.info("ğŸ“š NMFï¼ˆéè² å€¤è¡Œåˆ—åˆ†è§£ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¡ãƒ³ãƒãƒ¼ã®åŠ›é‡ç¿’å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã¾ã™ã€‚")

    # å¤‰æ•°ã®åˆæœŸåŒ–
    sampler_choice = "tpe"
    n_trials = 50
    random_state = 42
    custom_search_space = None

    # å­¦ç¿’ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    with st.expander("âš™ï¸ å­¦ç¿’ã‚ªãƒ—ã‚·ãƒ§ãƒ³", expanded=True):
        col1, col2 = st.columns(2)

        with col1:
            use_preprocessing = st.checkbox(
                "ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’ä½¿ç”¨",
                value=True,
                help="å¤–ã‚Œå€¤é™¤å»ã¨æ­£è¦åŒ–ã‚’è¡Œã„ã¾ã™ã€‚å†æ§‹æˆèª¤å·®ã®æ”¹å–„ã«åŠ¹æœçš„ã§ã™ã€‚"
            )

        with col2:
            # OptunaãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            try:
                import optuna
                optuna_available = True
            except ImportError:
                optuna_available = False

            use_tuning = st.checkbox(
                "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Optuna)",
                value=False,
                help="ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª¿æ•´ã—ã¾ã™ã€‚æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ãŒã€æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚",
                disabled=not optuna_available
            )

            if not optuna_available:
                st.error("âš ï¸ OptunaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`uv pip install --system optuna` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

        if use_preprocessing:
            st.markdown("""
            **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®å†…å®¹:**
            - å¤–ã‚Œå€¤é™¤å»: åŠ›é‡æ•°ãŒæ¥µç«¯ã«å°‘ãªã„ãƒ¡ãƒ³ãƒãƒ¼/ä¿æœ‰è€…ãŒå°‘ãªã„åŠ›é‡ã‚’é™¤å¤–
            - æ­£è¦åŒ–: Min-Maxã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆ0-1ç¯„å›²ã«æ­£è¦åŒ–ï¼‰
            """)

        if use_tuning and optuna_available:
            st.markdown("---")
            st.markdown("### âš™ï¸ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è©³ç´°è¨­å®š")

            # ã‚µãƒ³ãƒ—ãƒ©ãƒ¼é¸æŠ
            sampler_col1, sampler_col2, sampler_col3 = st.columns(3)
            with sampler_col1:
                sampler_choice = st.selectbox(
                    "æ¢ç´¢æ–¹æ³•ï¼ˆã‚µãƒ³ãƒ—ãƒ©ãƒ¼ï¼‰",
                    options=["tpe", "random", "cmaes"],
                    format_func=lambda x: {
                        "tpe": "TPE (Tree-structured Parzen Estimator) - æ¨å¥¨",
                        "random": "ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ",
                        "cmaes": "CMA-ES (é€²åŒ–æˆ¦ç•¥)"
                    }[x],
                    help="TPE: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§åŠ¹ç‡çš„ã«æ¢ç´¢\nãƒ©ãƒ³ãƒ€ãƒ : ãƒ©ãƒ³ãƒ€ãƒ ã«æ¢ç´¢\nCMA-ES: é€²åŒ–æˆ¦ç•¥ã«ã‚ˆã‚‹æœ€é©åŒ–"
                )

            with sampler_col2:
                n_trials = st.number_input(
                    "è©¦è¡Œå›æ•°",
                    min_value=10,
                    max_value=200,
                    value=50,
                    step=10,
                    help="æ¢ç´¢ã™ã‚‹çµ„ã¿åˆã‚ã›ã®æ•°ã€‚å¤šã„ã»ã©è‰¯ã„è§£ãŒè¦‹ã¤ã‹ã‚‹å¯èƒ½æ€§ãŒé«˜ã¾ã‚Šã¾ã™ãŒã€æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚"
                )

            with sampler_col3:
                random_state = st.number_input(
                    "ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆRandom Stateï¼‰",
                    min_value=0,
                    max_value=2147483647,
                    value=42,
                    step=1,
                    help="ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®šã™ã‚‹ã“ã¨ã§ã€åŒã˜æ¢ç´¢éç¨‹ã‚’å†ç¾ã§ãã¾ã™ã€‚å®Ÿé¨“ã®å†ç¾æ€§ãŒå¿…è¦ãªå ´åˆã«ä½¿ç”¨ã—ã¾ã™ã€‚"
                )

            # æ¢ç´¢ç¯„å›²ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            n_comp_min, n_comp_max = 10, 30
            alpha_w_min, alpha_w_max = 0.001, 0.5
            alpha_h_min, alpha_h_max = 0.001, 0.5
            l1_min, l1_max = 0.0, 1.0

            # æ¢ç´¢ç¯„å›²ã®è¨­å®š
            with st.expander("ğŸ” æ¢ç´¢ç¯„å›²ã®è©³ç´°è¨­å®š", expanded=False):
                st.markdown("å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ç¯„å›²ã‚’è¨­å®šã—ã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‹ã‚‰å¤‰æ›´ã™ã‚‹å ´åˆã®ã¿èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")

                range_col1, range_col2 = st.columns(2)

                with range_col1:
                    st.markdown("**æ½œåœ¨å› å­æ•° (n_components)**")
                    n_comp_min = st.number_input("æœ€å°å€¤", min_value=5, max_value=50, value=n_comp_min, key="n_comp_min")
                    n_comp_max = st.number_input("æœ€å¤§å€¤", min_value=5, max_value=50, value=n_comp_max, key="n_comp_max")

                    st.markdown("**æ­£å‰‡åŒ–ä¿‚æ•° W (alpha_W)**")
                    alpha_w_min = st.number_input("æœ€å°å€¤", min_value=0.0001, max_value=1.0, value=alpha_w_min, format="%.4f", key="alpha_w_min")
                    alpha_w_max = st.number_input("æœ€å¤§å€¤", min_value=0.0001, max_value=1.0, value=alpha_w_max, format="%.4f", key="alpha_w_max")

                with range_col2:
                    st.markdown("**æ­£å‰‡åŒ–ä¿‚æ•° H (alpha_H)**")
                    alpha_h_min = st.number_input("æœ€å°å€¤", min_value=0.0001, max_value=1.0, value=alpha_h_min, format="%.4f", key="alpha_h_min")
                    alpha_h_max = st.number_input("æœ€å¤§å€¤", min_value=0.0001, max_value=1.0, value=alpha_h_max, format="%.4f", key="alpha_h_max")

                    st.markdown("**L1æ¯”ç‡ (l1_ratio)**")
                    l1_min = st.number_input("æœ€å°å€¤", min_value=0.0, max_value=1.0, value=l1_min, format="%.2f", key="l1_min")
                    l1_max = st.number_input("æœ€å¤§å€¤", min_value=0.0, max_value=1.0, value=l1_max, format="%.2f", key="l1_max")

            # æ¢ç´¢ç©ºé–“ã‚’æ§‹ç¯‰ï¼ˆexpanderã®å¤–ã§ï¼‰
            custom_search_space = {
                'n_components': (int(n_comp_min), int(n_comp_max)),
                'alpha_W': (float(alpha_w_min), float(alpha_w_max)),
                'alpha_H': (float(alpha_h_min), float(alpha_h_max)),
                'l1_ratio': (float(l1_min), float(l1_max))
            }

            st.info(f"""
            **é¸æŠã—ãŸè¨­å®š:**
            - æ¢ç´¢æ–¹æ³•: {sampler_choice.upper()}
            - è©¦è¡Œå›æ•°: {int(n_trials)}å›
            - æ¨å®šæ™‚é–“: {int(n_trials) * 0.1:.1f}ã€œ{int(n_trials) * 0.2:.1f}åˆ†
            """)
            st.warning("â±ï¸ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")

    # å­¦ç¿’å®Ÿè¡Œãƒœã‚¿ãƒ³
    button_label = "ğŸš€ MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ã‚Šï¼‰" if use_tuning else "ğŸš€ MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œ"

    if st.button(button_label, type="primary"):
        # Optunaãƒã‚§ãƒƒã‚¯ï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æœ‰åŠ¹æ™‚ï¼‰
        if use_tuning:
            try:
                import optuna
            except ImportError:
                st.error("âŒ OptunaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
                st.info("ğŸ’¡ ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:\n```bash\nuv pip install --system optuna\n```")
                st.stop()

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’session_stateã«åˆæœŸåŒ–
        st.session_state.debug_messages = []
        st.session_state.show_debug_info = True

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å°‚ç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
        debug_container = st.container()

        with debug_container:
            st.markdown("### ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
            debug_info = st.empty()

            # åˆæœŸè¨­å®šã‚’è¡¨ç¤º
            debug_messages = []
            debug_messages.append(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
            debug_messages.append(f"âœ… use_tuning={use_tuning}")
            debug_messages.append(f"âœ… use_preprocessing={use_preprocessing}")

            if use_tuning:
                debug_messages.append(f"âœ… sampler_choice={sampler_choice}")
                debug_messages.append(f"âœ… n_trials={int(n_trials)} (å‹: {type(n_trials)})")
                debug_messages.append(f"âœ… random_state={int(random_state)} (å‹: {type(random_state)})")
                debug_messages.append(f"âœ… custom_search_space={custom_search_space}")

            debug_info.code("\n".join(debug_messages))
            st.session_state.debug_messages = debug_messages.copy()

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–ç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        progress_placeholder = st.empty()
        chart_placeholder = st.empty()
        metrics_placeholder = st.empty()

        # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é€²æ—ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
        trial_history = []
        callback_counter = [0]  # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå‘¼ã°ã‚ŒãŸå›æ•°

        def progress_callback(trial, study):
            """ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤º"""
            callback_counter[0] += 1

            trial_history.append({
                'trial': trial.number,
                'value': trial.value,
                'best_value': study.best_value
            })

            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
            progress_pct = (trial.number + 1) / int(n_trials) if use_tuning else 1.0
            progress_placeholder.progress(
                progress_pct,
                text=f"Trial {trial.number + 1}/{int(n_trials) if use_tuning else 1} - ç¾åœ¨ã®èª¤å·®: {trial.value:.6f} - æœ€è‰¯: {study.best_value:.6f}"
            )

            # ã‚°ãƒ©ãƒ•ã‚’æ›´æ–°ï¼ˆæ¯å›æ›´æ–°ï¼‰
            if True:  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
                import pandas as pd
                import plotly.graph_objects as go

                df_history = pd.DataFrame(trial_history)

                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=df_history['trial'],
                    y=df_history['value'],
                    mode='markers',
                    name='å„è©¦è¡Œ',
                    marker=dict(size=8, opacity=0.6, color='lightblue')
                ))
                fig.add_trace(go.Scatter(
                    x=df_history['trial'],
                    y=df_history['best_value'],
                    mode='lines',
                    name='æœ€è‰¯å€¤ã®æ¨ç§»',
                    line=dict(color='red', width=2)
                ))
                fig.update_layout(
                    title='ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã®é€²æ—',
                    xaxis_title='Trial',
                    yaxis_title='å†æ§‹æˆèª¤å·®',
                    height=400
                )
                chart_placeholder.plotly_chart(fig, use_container_width=True)

                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¡¨ç¤º
                col1, col2, col3 = metrics_placeholder.columns(3)
                with col1:
                    st.metric("ç¾åœ¨ã® Trial", f"{trial.number + 1}/{int(n_trials) if use_tuning else 1}")
                with col2:
                    st.metric("ç¾åœ¨ã®èª¤å·®", f"{trial.value:.6f}")
                with col3:
                    st.metric("æœ€è‰¯èª¤å·®", f"{study.best_value:.6f}")

        with st.spinner("MLãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­..." if not use_tuning else "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­..."):
            try:
                # è¿½åŠ ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                if use_tuning:
                    debug_messages.append(f"â³ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
                    debug_messages.append(f"   - n_trials={int(n_trials)}")
                    debug_messages.append(f"   - sampler={sampler_choice}")
                    debug_messages.append(f"   - callbackè¨­å®š={progress_callback is not None}")

                    # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
                    if "member_competence" in st.session_state.transformed_data:
                        mc = st.session_state.transformed_data["member_competence"]
                        debug_messages.append(f"   - member_competence shape: {mc.shape}")
                        debug_messages.append(f"   - member_competence åˆ—: {list(mc.columns)}")

                    debug_info.code("\n".join(debug_messages))
                    st.session_state.debug_messages = debug_messages.copy()

                # print()ã®å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
                import sys
                from io import StringIO

                stdout_capture = StringIO()
                stderr_capture = StringIO()
                old_stdout = sys.stdout
                old_stderr = sys.stderr

                try:
                    # stdoutã¨stderrã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
                    sys.stdout = stdout_capture
                    sys.stderr = stderr_capture

                    ml_recommender = build_ml_recommender(
                        st.session_state.transformed_data,
                        use_preprocessing=use_preprocessing,
                        use_tuning=use_tuning,
                        tuning_n_trials=int(n_trials) if use_tuning else None,
                        tuning_timeout=None,
                        tuning_search_space=custom_search_space if use_tuning else None,
                        tuning_sampler=sampler_choice if use_tuning else None,
                        tuning_random_state=int(random_state) if use_tuning else None,
                        tuning_progress_callback=progress_callback if use_tuning else None
                    )
                finally:
                    # stdoutã¨stderrã‚’å¾©å…ƒ
                    sys.stdout = old_stdout
                    sys.stderr = old_stderr

                    # ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸå‡ºåŠ›ã‚’å–å¾—
                    captured_stdout = stdout_capture.getvalue()
                    captured_stderr = stderr_capture.getvalue()

                    # ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                    if captured_stdout:
                        debug_messages.append(f"\n--- æ¨™æº–å‡ºåŠ› (stdout) ---")
                        debug_messages.append(captured_stdout)
                    if captured_stderr:
                        debug_messages.append(f"\n--- ã‚¨ãƒ©ãƒ¼å‡ºåŠ› (stderr) ---")
                        debug_messages.append(captured_stderr)

                    st.session_state.debug_messages = debug_messages.copy()

                # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ã®ãƒ­ã‚°
                if use_tuning:
                    debug_messages.append(f"\nâœ… ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
                    debug_messages.append(f"   - å®Ÿè¡Œã•ã‚ŒãŸè©¦è¡Œæ•°: {len(trial_history)}")
                    debug_messages.append(f"   - ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‘¼ã³å‡ºã—å›æ•°: {callback_counter[0]}")
                    if ml_recommender.tuning_results:
                        debug_messages.append(f"   - æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {ml_recommender.tuning_results['best_params']}")
                        debug_messages.append(f"   - æœ€å°èª¤å·®: {ml_recommender.tuning_results['best_value']:.6f}")
                        if hasattr(ml_recommender.tuning_results.get('tuner'), 'study'):
                            study = ml_recommender.tuning_results['tuner'].study
                            debug_messages.append(f"   - Studyã®è©¦è¡Œæ•°: {len(study.trials)}")
                    else:
                        debug_messages.append(f"   âš ï¸ tuning_resultsãŒNone")
                        debug_messages.append(f"   âš ï¸ ã“ã‚Œã¯ã€Optunaã®study.optimize()ãŒè©¦è¡Œã‚’å®Ÿè¡Œã—ãªã‹ã£ãŸã“ã¨ã‚’æ„å‘³ã—ã¾ã™")
                        debug_messages.append(f"   âš ï¸ ä¸Šè¨˜ã®æ¨™æº–å‡ºåŠ›/ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                    debug_info.code("\n".join(debug_messages))
                    # session_stateã«æœ€çµ‚çµæœã‚’ä¿å­˜
                    st.session_state.debug_messages = debug_messages.copy()

                # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚¯ãƒªã‚¢
                progress_placeholder.empty()
                chart_placeholder.empty()
                metrics_placeholder.empty()
                st.session_state.ml_recommender = ml_recommender
                st.session_state.model_trained = True

                # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ï¼ˆpersistence_managerãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                if 'persistence_manager' in globals():
                    current_user = persistence_manager.get_current_user()
                    if current_user:
                        with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­..."):
                            try:
                                # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
                                mf_model = ml_recommender.mf_model
                                parameters = {
                                    "n_components": mf_model.n_components,
                                    "use_preprocessing": use_preprocessing,
                                    "use_tuning": use_tuning,
                                }
                                metrics = {
                                    "reconstruction_error": mf_model.get_reconstruction_error(),
                                }

                                # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
                                model_id = persistence_manager.save_trained_model(
                                    model=ml_recommender,
                                    model_type="nmf",
                                    parameters=parameters,
                                    metrics=metrics,
                                    training_data=st.session_state.transformed_data.get("skill_matrix"),
                                    description=f"NMF model (preprocessing={use_preprocessing}, tuning={use_tuning})"
                                )

                                if model_id:
                                    st.success(f"âœ… MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒå®Œäº†ã—ã€ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼ˆID: {model_id[:8]}...ï¼‰")
                                else:
                                    st.success("âœ… MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                            except Exception as save_error:
                                st.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ãƒ¢ãƒ‡ãƒ«ã¯ä½¿ç”¨å¯èƒ½ã§ã™: {save_error}")
                else:
                    st.success("âœ… MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    st.info("ğŸ’¡ ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¦å†åˆ©ç”¨ã§ãã¾ã™ã€‚")

                st.rerun()
            except Exception as e:
                import traceback
                import sys
                from io import StringIO

                # stdoutã¨stderrã‚’å¾©å…ƒï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã«å¾©å…ƒã•ã‚Œã¦ã„ãªã„å ´åˆã«å‚™ãˆã¦ï¼‰
                if hasattr(sys.stdout, 'getvalue'):
                    try:
                        captured_stdout = sys.stdout.getvalue()
                        captured_stderr = sys.stderr.getvalue() if hasattr(sys.stderr, 'getvalue') else ""

                        if captured_stdout:
                            debug_messages.append(f"\n--- æ¨™æº–å‡ºåŠ› (stdout) [ã‚¨ãƒ©ãƒ¼å‰] ---")
                            debug_messages.append(captured_stdout)
                        if captured_stderr:
                            debug_messages.append(f"\n--- ã‚¨ãƒ©ãƒ¼å‡ºåŠ› (stderr) [ã‚¨ãƒ©ãƒ¼å‰] ---")
                            debug_messages.append(captured_stderr)
                    except:
                        pass

                # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                debug_messages.append(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ")
                debug_messages.append(f"   - ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
                debug_messages.append(f"   - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {e}")
                debug_messages.append(f"\n--- ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ ---")
                debug_messages.append(traceback.format_exc())
                st.session_state.debug_messages = debug_messages.copy()

                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {e}")
                st.code(traceback.format_exc())
                st.info("ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
                st.write("transformed_data keys:", list(st.session_state.transformed_data.keys()))

                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                with st.expander("ğŸ” ã‚­ãƒ£ãƒ—ãƒãƒ£ã•ã‚ŒãŸå‡ºåŠ›", expanded=True):
                    st.code("\n".join(debug_messages))

                # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                st.warning("âš ï¸ è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¯ä¸Šè¨˜ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚‚æƒ…å ±ã¯æ®‹ã‚Šã¾ã™ã€‚")


# =========================================================
# å­¦ç¿’çµæœã®åˆ†æ
# =========================================================
if st.session_state.get("model_trained", False):
    st.markdown("---")
    st.subheader("ğŸ“Š å­¦ç¿’çµæœã®åˆ†æ")

    recommender = st.session_state.ml_recommender
    mf_model = recommender.mf_model

    # ç›®çš„é–¢æ•°ã®æ˜ç¢ºãªè¡¨ç¤ºï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ï¼‰
    if hasattr(recommender, 'tuning_results') and recommender.tuning_results is not None:
        tuner = recommender.tuning_results['tuner']
        st.markdown("---")
        st.markdown("### ğŸ¯ æœ€é©åŒ–ã®ç›®çš„é–¢æ•°")
        st.success(
            f"""
            ## {tuner.objective_description}

            **èª¬æ˜ï¼š** NMFãƒ¢ãƒ‡ãƒ«ã¯ã€è¤‡æ•°ã®ç•°ãªã‚‹ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸå€¤ã‹ã‚‰é–‹å§‹ã—ãŸå­¦ç¿’ã‚’ã€K-foldäº¤å·®æ¤œè¨¼ã«ã‚ˆã‚Šè©•ä¾¡ã—ã€
            æœ€ã‚‚å†æ§‹æˆèª¤å·®ãŒä½ã„ï¼ˆï¼ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ˆã‚Šæ­£ç¢ºã«å¾©å…ƒã§ãã‚‹ï¼‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªå‹•çš„ã«è¦‹ã¤ã‘ã¾ã™ã€‚

            **æ­£è¦åŒ–å†æ§‹æˆèª¤å·®ã¨ã¯ï¼š** å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹å¾©å…ƒç²¾åº¦ã‚’ã€ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚±ãƒ¼ãƒ«éä¾å­˜ãªç›¸å¯¾çš„ãªèª¤å·®ã¨ã—ã¦è¨ˆç®—ã—ãŸã‚‚ã®ã§ã€
            å€¤ãŒå°ã•ã„ã»ã©ãƒ¢ãƒ‡ãƒ«ãŒãƒ¡ãƒ³ãƒãƒ¼Ã—åŠ›é‡ãƒãƒˆãƒªã‚¯ã‚¹ã‚’ã‚ˆã‚Šæ­£ç¢ºã«åˆ†è§£ãƒ»å¾©å…ƒã§ãã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
            """
        )
        st.markdown("---")

        # Optunaãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®å¯è¦–åŒ–
        st.markdown("### ğŸ“Š ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®å¯è¦–åŒ–")

        try:
            study = tuner.study

            # Pruningçµ±è¨ˆæƒ…å ±
            pruning_stats = get_pruned_trials_count(study)

            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
            with col_stat1:
                st.metric("ç·è©¦è¡Œæ•°", pruning_stats['total'])
            with col_stat2:
                st.metric("å®Œäº†è©¦è¡Œæ•°", pruning_stats['complete'])
            with col_stat3:
                st.metric("æåˆˆã‚Šæ•°", pruning_stats['pruned'])
            with col_stat4:
                st.metric("æåˆˆã‚Šç‡", f"{pruning_stats['pruning_rate']:.1f}%")

            if pruning_stats['pruned'] > 0:
                st.info(
                    f"ğŸ’¡ **Pruningï¼ˆæåˆˆã‚Šï¼‰åŠ¹æœ**: {pruning_stats['pruned']}å€‹ã®æœ‰æœ›ã§ãªã„è©¦è¡Œã‚’æ—©æœŸçµ‚äº†ã™ã‚‹ã“ã¨ã§ã€"
                    f"è¨ˆç®—æ™‚é–“ã‚’ç´„{pruning_stats['pruning_rate']:.0f}%å‰Šæ¸›ã—ã¾ã—ãŸã€‚"
                )

            # ä¸Šä½è©¦è¡Œã®ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
            with st.expander("ğŸ† ä¸Šä½10è©¦è¡Œã®è©³ç´°", expanded=False):
                best_trials_df = get_best_trials_summary(study, top_n=10)
                st.dataframe(best_trials_df, use_container_width=True)
                st.download_button(
                    label="ğŸ“¥ ä¸Šä½è©¦è¡Œãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆCSVï¼‰",
                    data=best_trials_df.to_csv(index=False).encode('utf-8-sig'),
                    file_name="optuna_best_trials.csv",
                    mime="text/csv",
                )

            # Optunaã®å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ç”Ÿæˆ
            st.markdown("#### ğŸ“ˆ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°éç¨‹ã®è©³ç´°åˆ†æ")

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚’å–å¾—
            param_names = list(study.best_params.keys())

            with st.spinner("å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆä¸­..."):
                visualizations = generate_optuna_visualizations(study, params_to_plot=param_names)

            # 6ç¨®é¡ã®ã‚°ãƒ©ãƒ•ã‚’ã‚¿ãƒ–ã§è¡¨ç¤º
            tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                "ğŸ“ˆ æœ€é©åŒ–å±¥æ­´",
                "ğŸ¯ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦",
                "ğŸ”— ãƒ‘ãƒ©ãƒ¬ãƒ«åº§æ¨™",
                "ğŸ—ºï¸ ç­‰é«˜ç·šå›³",
                "ğŸ“Š ã‚¹ãƒ©ã‚¤ã‚¹",
                "ğŸ“‰ çµŒé¨“åˆ†å¸ƒé–¢æ•°"
            ])

            with tab1:
                if 'optimization_history' in visualizations:
                    st.plotly_chart(visualizations['optimization_history'], use_container_width=True)
                    st.markdown("""
                    **æœ€é©åŒ–å±¥æ­´**: å„è©¦è¡Œã®ç›®çš„é–¢æ•°å€¤ã®æ¨ç§»ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
                    é’ç·šã¯å„è©¦è¡Œã®å€¤ã€èµ¤ç·šã¯æœ€è‰¯å€¤ã®æ›´æ–°ã‚’ç¤ºã—ã¾ã™ã€‚
                    """)
                else:
                    st.warning("âš ï¸ æœ€é©åŒ–å±¥æ­´ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

            with tab2:
                if 'param_importances' in visualizations:
                    st.plotly_chart(visualizations['param_importances'], use_container_width=True)
                    st.markdown("""
                    **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦**: å„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒç›®çš„é–¢æ•°ã«ä¸ãˆã‚‹å½±éŸ¿åº¦ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
                    é‡è¦åº¦ãŒé«˜ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã»ã©ã€æœ€é©åŒ–ã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚
                    """)
                else:
                    st.warning("âš ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

            with tab3:
                if 'parallel_coordinate' in visualizations:
                    st.plotly_chart(visualizations['parallel_coordinate'], use_container_width=True)
                    st.markdown("""
                    **ãƒ‘ãƒ©ãƒ¬ãƒ«åº§æ¨™ãƒ—ãƒ­ãƒƒãƒˆ**: ã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ç›®çš„é–¢æ•°ã®é–¢ä¿‚ã‚’åŒæ™‚ã«å¯è¦–åŒ–ã—ã¾ã™ã€‚
                    å„ç·šã¯1ã¤ã®è©¦è¡Œã‚’è¡¨ã—ã€è‰²ã¯ç›®çš„é–¢æ•°å€¤ã‚’ç¤ºã—ã¾ã™ï¼ˆé’=è‰¯ã„ã€èµ¤=æ‚ªã„ï¼‰ã€‚
                    """)
                else:
                    st.warning("âš ï¸ ãƒ‘ãƒ©ãƒ¬ãƒ«åº§æ¨™ãƒ—ãƒ­ãƒƒãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

            with tab4:
                if 'contour' in visualizations:
                    st.plotly_chart(visualizations['contour'], use_container_width=True)
                    st.markdown("""
                    **ç­‰é«˜ç·šå›³**: 2ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®ç›¸äº’ä½œç”¨ã¨ç›®çš„é–¢æ•°å€¤ã®é–¢ä¿‚ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
                    è‰²ãŒæ¿ƒã„é ˜åŸŸã»ã©ç›®çš„é–¢æ•°å€¤ãŒä½ã„ï¼ˆè‰¯ã„ï¼‰ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
                    """)
                else:
                    st.warning("âš ï¸ ç­‰é«˜ç·šå›³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

            with tab5:
                if 'slice' in visualizations:
                    st.plotly_chart(visualizations['slice'], use_container_width=True)
                    st.markdown("""
                    **ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ**: å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒç›®çš„é–¢æ•°ã«ä¸ãˆã‚‹å€‹åˆ¥ã®å½±éŸ¿ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
                    ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å›ºå®šã—ãŸçŠ¶æ…‹ã§ã€1ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’å¤‰åŒ–ã•ã›ãŸå ´åˆã®åŠ¹æœã‚’ç¢ºèªã§ãã¾ã™ã€‚
                    """)
                else:
                    st.warning("âš ï¸ ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

            with tab6:
                if 'edf' in visualizations:
                    st.plotly_chart(visualizations['edf'], use_container_width=True)
                    st.markdown("""
                    **çµŒé¨“åˆ†å¸ƒé–¢æ•°ï¼ˆEDFï¼‰**: ç›®çš„é–¢æ•°å€¤ã®ç´¯ç©åˆ†å¸ƒã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
                    æ¢ç´¢ãŒã©ã®ç¯„å›²ã®å€¤ã«é›†ä¸­ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã§ãã¾ã™ã€‚
                    """)
                else:
                    st.warning("âš ï¸ çµŒé¨“åˆ†å¸ƒé–¢æ•°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

        except Exception as viz_error:
            st.error(f"âŒ å¯è¦–åŒ–ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {viz_error}")
            import traceback
            st.code(traceback.format_exc())

        st.markdown("---")

    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("æ½œåœ¨å› å­æ•°", mf_model.n_components)

    with col2:
        st.metric("ãƒ¡ãƒ³ãƒãƒ¼æ•°", len(mf_model.member_index))

    with col3:
        st.metric("åŠ›é‡æ•°", len(mf_model.competence_index))

    with col4:
        error = mf_model.get_reconstruction_error()
        st.metric("å†æ§‹æˆèª¤å·®", f"{error:.4f}")

    # NMFæˆåˆ†ã®åˆ†æ
    st.markdown("### ğŸ” NMFæ½œåœ¨å› å­ã®åˆ†æ")

    st.markdown(
        "NMFã¯ãƒ¡ãƒ³ãƒãƒ¼Ã—åŠ›é‡ãƒãƒˆãƒªã‚¯ã‚¹ã‚’**ãƒ¡ãƒ³ãƒãƒ¼å› å­è¡Œåˆ—**ã¨**åŠ›é‡å› å­è¡Œåˆ—**ã«åˆ†è§£ã—ã¾ã™ã€‚\n"
        "å„æ½œåœ¨å› å­ã¯ã€ç‰¹å®šã®åŠ›é‡ç¾¤ï¼ˆã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆï¼‰ã‚’è¡¨ã—ã€ãƒ¡ãƒ³ãƒãƒ¼ã¯ã“ã‚Œã‚‰ã®å› å­ã®çµ„ã¿åˆã‚ã›ã§è¡¨ç¾ã•ã‚Œã¾ã™ã€‚"
    )

    # å„æ½œåœ¨å› å­ã®ç‰¹å¾´ã‚’åˆ†æ
    with st.expander("ğŸ“ˆ æ½œåœ¨å› å­ã”ã¨ã®ä»£è¡¨åŠ›é‡ï¼ˆãƒˆãƒƒãƒ—10ï¼‰"):
        competence_master = st.session_state.transformed_data["competence_master"]

        # è¡¨ç¤ºå¯¾è±¡ã®æ½œåœ¨å› å­æ•°ã‚’é¸æŠ
        col_factor_select1, col_factor_select2 = st.columns(2)
        with col_factor_select1:
            show_all_factors = st.checkbox(
                "ã™ã¹ã¦ã®æ½œåœ¨å› å­ã‚’è¡¨ç¤º",
                value=False,
                help="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ã™ã¹ã¦ã®æ½œåœ¨å› å­ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚æœªãƒã‚§ãƒƒã‚¯æ™‚ã¯æœ€åˆã®10å€‹ã‚’è¡¨ç¤º"
            )

        n_factors_to_show = mf_model.n_components if show_all_factors else min(10, mf_model.n_components)

        for factor_idx in range(n_factors_to_show):
            st.markdown(f"#### æ½œåœ¨å› å­ {factor_idx + 1}")

            # ã“ã®å› å­ã§é‡ã¿ãŒé«˜ã„åŠ›é‡ã‚’å–å¾—
            factor_weights = mf_model.H[factor_idx, :]

            # éã‚¼ãƒ­ã®é‡ã¿ã‚’æŒã¤åŠ›é‡ã®ã¿ã‚’å–å¾—
            non_zero_indices = np.where(factor_weights > 1e-10)[0]

            if len(non_zero_indices) > 0:
                # éã‚¼ãƒ­ã®åŠ›é‡ã‹ã‚‰ä¸Šä½10å€‹ã‚’é¸æŠ
                non_zero_weights = factor_weights[non_zero_indices]
                top_local_indices = non_zero_weights.argsort()[-10:][::-1]
                top_indices = non_zero_indices[top_local_indices]
            else:
                # ã™ã¹ã¦ãŒ0ã«è¿‘ã„å ´åˆï¼ˆæ½œåœ¨å› å­ãŒä¸è¦ï¼‰
                st.warning(f"âš ï¸ æ½œåœ¨å› å­ {factor_idx + 1} ã¯ã™ã¹ã¦ 0 ã¾ãŸã¯ 0 ã«éå¸¸ã«è¿‘ã„å€¤ã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ä¸ä½¿ç”¨ã®æ½œåœ¨å› å­ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚")
                st.info("ğŸ’¡ æ½œåœ¨å› å­æ•°ï¼ˆn_componentsï¼‰ãŒå¤šã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ¸›ã‚‰ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
                continue

            top_competences = [mf_model.competence_codes[i] for i in top_indices]
            top_weights = [factor_weights[i] for i in top_indices]

            # åŠ›é‡åã‚’å–å¾—
            top_competence_names = []
            for comp_code in top_competences:
                comp_info = competence_master[competence_master["åŠ›é‡ã‚³ãƒ¼ãƒ‰"] == comp_code]
                if len(comp_info) > 0:
                    top_competence_names.append(comp_info.iloc[0]["åŠ›é‡å"])
                else:
                    top_competence_names.append(comp_code)

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã§è¡¨ç¤ºï¼ˆé‡ã¿ãŒå¤§ãã„é †ã«ä¸Šã‹ã‚‰è¡¨ç¤ºã™ã‚‹ãŸã‚ã€é™é †ã§ã‚½ãƒ¼ãƒˆï¼‰
            df_factor = pd.DataFrame({
                "åŠ›é‡å": top_competence_names,
                "é‡ã¿": top_weights
            }).sort_values("é‡ã¿", ascending=False).reset_index(drop=True)

            col1, col2 = st.columns([2, 1])

            with col1:
                # æ£’ã‚°ãƒ©ãƒ•ï¼ˆé‡ã¿ãŒå¤§ãã„é †ã«ä¸Šã‹ã‚‰è¡¨ç¤ºï¼‰
                fig = px.bar(
                    df_factor,
                    x="é‡ã¿",
                    y="åŠ›é‡å",
                    orientation="h",
                    title=f"æ½œåœ¨å› å­ {factor_idx + 1} ã®ä»£è¡¨åŠ›é‡ï¼ˆä¸Šã»ã©é‡ã¿ãŒå¤§ãã„ï¼‰"
                )
                # yè»¸ã®é †åºã‚’é€†ã«ã—ã¦ã€é‡ã¿ãŒå¤§ãã„ã‚‚ã®ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«ã™ã‚‹
                fig.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                # ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆé‡ã¿ãŒå¤§ãã„é †ã«è¡¨ç¤ºï¼‰
                st.dataframe(df_factor, use_container_width=True, height=400)

    # ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­åˆ†å¸ƒ
    with st.expander("ğŸ‘¥ ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­åˆ†å¸ƒ"):
        st.markdown("å„ãƒ¡ãƒ³ãƒãƒ¼ãŒã©ã®æ½œåœ¨å› å­ã‚’å¼·ãæŒã£ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚")

        # ãƒ©ãƒ³ãƒ€ãƒ ã«10åã‚’ã‚µãƒ³ãƒ—ãƒ«
        import numpy as np

        n_members_to_show = min(10, len(mf_model.member_codes))
        random_indices = np.random.choice(len(mf_model.member_codes), n_members_to_show, replace=False)

        member_codes = [mf_model.member_codes[i] for i in random_indices]
        member_names = []
        members_df = st.session_state.transformed_data["members_clean"]
        for code in member_codes:
            member_info = members_df[members_df["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"] == code]
            if len(member_info) > 0:
                member_names.append(member_info.iloc[0]["ãƒ¡ãƒ³ãƒãƒ¼å"])
            else:
                member_names.append(code)

        # å„ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­ã®é‡ã¿ã‚’å–å¾—ï¼ˆãƒ¡ãƒ³ãƒãƒ¼åã¨ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ä¸¡æ–¹ã‚’å«ã‚ã‚‹ï¼‰
        member_factors_data = []
        for i, (idx, member_code) in enumerate(zip(random_indices, member_codes)):
            factors = mf_model.W[idx, :]
            for factor_idx, weight in enumerate(factors):
                member_factors_data.append({
                    "ãƒ¡ãƒ³ãƒãƒ¼å": member_names[i],
                    "ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰": member_code,
                    "æ½œåœ¨å› å­": f"å› å­{factor_idx + 1}",
                    "é‡ã¿": weight
                })

        df_member_factors = pd.DataFrame(member_factors_data)

        # ã‚¿ãƒ–ã§2ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ‡ã‚Šæ›¿ãˆ
        tab1, tab2 = st.tabs(["ğŸ“ ãƒ¡ãƒ³ãƒãƒ¼åã§è¡¨ç¤º", "ğŸ”¢ ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã§è¡¨ç¤º"])

        with tab1:
            # ãƒ¡ãƒ³ãƒãƒ¼åã§ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            duplicates = df_member_factors[df_member_factors.duplicated(subset=["ãƒ¡ãƒ³ãƒãƒ¼å", "æ½œåœ¨å› å­"], keep=False)]
            if not duplicates.empty:
                st.warning(f"âš ï¸ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆ{len(duplicates)}ä»¶ï¼‰ã€‚é‡è¤‡ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
                df_member_factors_name = df_member_factors.drop_duplicates(subset=["ãƒ¡ãƒ³ãƒãƒ¼å", "æ½œåœ¨å› å­"], keep="first")
            else:
                df_member_factors_name = df_member_factors.copy()

            pivot_table_name = df_member_factors_name.pivot_table(
                index="ãƒ¡ãƒ³ãƒãƒ¼å",
                columns="æ½œåœ¨å› å­",
                values="é‡ã¿",
                aggfunc="mean"
            )

            fig_name = px.imshow(
                pivot_table_name,
                labels=dict(x="æ½œåœ¨å› å­", y="ãƒ¡ãƒ³ãƒãƒ¼å", color="é‡ã¿"),
                title="ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­åˆ†å¸ƒãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆãƒ¡ãƒ³ãƒãƒ¼åï¼‰",
                color_continuous_scale="Blues"
            )
            fig_name.update_layout(height=500)
            st.plotly_chart(fig_name, use_container_width=True)

        with tab2:
            # ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã§ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            duplicates_code = df_member_factors[df_member_factors.duplicated(subset=["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰", "æ½œåœ¨å› å­"], keep=False)]
            if not duplicates_code.empty:
                st.warning(f"âš ï¸ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆ{len(duplicates_code)}ä»¶ï¼‰ã€‚é‡è¤‡ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
                df_member_factors_code = df_member_factors.drop_duplicates(subset=["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰", "æ½œåœ¨å› å­"], keep="first")
            else:
                df_member_factors_code = df_member_factors.copy()

            # ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’æ–‡å­—åˆ—å‹ã¨ã—ã¦æ˜ç¤ºçš„ã«å¤‰æ›
            df_member_factors_code["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"] = df_member_factors_code["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"].astype(str)

            pivot_table_code = df_member_factors_code.pivot_table(
                index="ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰",
                columns="æ½œåœ¨å› å­",
                values="é‡ã¿",
                aggfunc="mean"
            )

            # go.Heatmapã‚’ä½¿ç”¨ã—ã¦ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ‰±ã†
            import plotly.graph_objects as go

            fig_code = go.Figure(data=go.Heatmap(
                z=pivot_table_code.values,
                x=pivot_table_code.columns.tolist(),
                y=pivot_table_code.index.tolist(),
                colorscale="Blues",
                colorbar=dict(title="é‡ã¿"),
                hoverongaps=False,
                hovertemplate="ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰: %{y}<br>æ½œåœ¨å› å­: %{x}<br>é‡ã¿: %{z:.3f}<extra></extra>"
            ))

            fig_code.update_layout(
                title="ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­åˆ†å¸ƒãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ï¼‰",
                xaxis_title="æ½œåœ¨å› å­",
                yaxis_title="ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰",
                height=500,
                yaxis=dict(type='category')  # ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ‰±ã†
            )
            st.plotly_chart(fig_code, use_container_width=True)

    # åŠ›é‡ã®æ½œåœ¨å› å­åˆ†å¸ƒ
    with st.expander("ğŸ’¡ åŠ›é‡ã®æ½œåœ¨å› å­åˆ†å¸ƒ"):
        st.markdown("å„åŠ›é‡ãŒã©ã®æ½œåœ¨å› å­ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚")

        # ãƒ©ãƒ³ãƒ€ãƒ ã«10å€‹ã®åŠ›é‡ã‚’ã‚µãƒ³ãƒ—ãƒ«
        n_competences_to_show = min(10, len(mf_model.competence_codes))
        random_comp_indices = np.random.choice(len(mf_model.competence_codes), n_competences_to_show, replace=False)

        competence_codes = [mf_model.competence_codes[i] for i in random_comp_indices]
        competence_names = []
        for code in competence_codes:
            comp_info = competence_master[competence_master["åŠ›é‡ã‚³ãƒ¼ãƒ‰"] == code]
            if len(comp_info) > 0:
                competence_names.append(comp_info.iloc[0]["åŠ›é‡å"])
            else:
                competence_names.append(code)

        # å„åŠ›é‡ã®æ½œåœ¨å› å­ã®é‡ã¿ã‚’å–å¾—
        competence_factors_data = []
        for i, (idx, comp_code) in enumerate(zip(random_comp_indices, competence_codes)):
            factors = mf_model.H[:, idx]
            for factor_idx, weight in enumerate(factors):
                competence_factors_data.append({
                    "åŠ›é‡": competence_names[i],  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ç›´æ¥å‚ç…§
                    "æ½œåœ¨å› å­": f"å› å­{factor_idx + 1}",
                    "é‡ã¿": weight
                })

        df_competence_factors = pd.DataFrame(competence_factors_data)

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        duplicates_comp = df_competence_factors[df_competence_factors.duplicated(subset=["åŠ›é‡", "æ½œåœ¨å› å­"], keep=False)]
        if not duplicates_comp.empty:
            st.warning(f"âš ï¸ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆ{len(duplicates_comp)}ä»¶ï¼‰ã€‚é‡è¤‡ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
            df_competence_factors = df_competence_factors.drop_duplicates(subset=["åŠ›é‡", "æ½œåœ¨å› å­"], keep="first")

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        pivot_table_comp = df_competence_factors.pivot_table(
            index="åŠ›é‡",
            columns="æ½œåœ¨å› å­",
            values="é‡ã¿",
            aggfunc="mean"  # ä¸‡ãŒä¸€é‡è¤‡ãŒã‚ã‚‹å ´åˆã¯å¹³å‡ã‚’å–ã‚‹
        )

        fig = px.imshow(
            pivot_table_comp,
            labels=dict(x="æ½œåœ¨å› å­", y="åŠ›é‡", color="é‡ã¿"),
            title="åŠ›é‡ã®æ½œåœ¨å› å­åˆ†å¸ƒãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
            color_continuous_scale="Greens"
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)

    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™
    with st.expander("ğŸ“‰ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™"):
        st.markdown("### å†æ§‹æˆèª¤å·®ã®è©³ç´°")

        error = mf_model.get_reconstruction_error()
        normalized_error = mf_model.get_normalized_reconstruction_error()

        col1, col2 = st.columns(2)
        with col1:
            st.metric("å†æ§‹æˆèª¤å·®ï¼ˆFrobenius ãƒãƒ«ãƒ ï¼‰", f"{error:.6f}")
        with col2:
            st.metric("æ­£è¦åŒ–å†æ§‹æˆèª¤å·®ï¼ˆç›¸å¯¾èª¤å·®ï¼‰", f"{normalized_error:.6f}")

        st.info("""
        **ãƒ¡ãƒˆãƒªã‚¯ã‚¹è§£èª¬:**
        - **å†æ§‹æˆèª¤å·®ï¼ˆFrobenius ãƒãƒ«ãƒ ï¼‰**: ãƒ¢ãƒ‡ãƒ«ãŒå…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å†æ§‹æˆã™ã‚‹éš›ã®çµ¶å¯¾çš„ãªèª¤å·®
        - **æ­£è¦åŒ–å†æ§‹æˆèª¤å·®**: ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«ä¾å­˜ã—ãªã„ç›¸å¯¾çš„ãªèª¤å·®ï¼ˆç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã§ã®æ¯”è¼ƒã«æœ‰ç”¨ï¼‰
        """)

        # è©•ä¾¡åŸºæº–ã¨æ”¹å–„ææ¡ˆ
        if normalized_error < 0.1:
            st.success("âœ… **éå¸¸ã«è‰¯å¥½ãªãƒ¢ãƒ‡ãƒ«ã§ã™**")
            st.markdown("æ­£è¦åŒ–å†æ§‹æˆèª¤å·®ãŒ0.1ä»¥ä¸‹ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’éå¸¸ã«ã‚ˆãå†ç¾ã—ã¦ã„ã¾ã™ã€‚")
        elif normalized_error < 0.2:
            st.success("âœ… **è‰¯å¥½ãªãƒ¢ãƒ‡ãƒ«ã§ã™**")
            st.markdown("æ­£è¦åŒ–å†æ§‹æˆèª¤å·®ãŒ0.2ä»¥ä¸‹ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ˆãå†ç¾ã—ã¦ã„ã¾ã™ã€‚")
        elif normalized_error < 0.3:
            st.warning("âš ï¸ **è¨±å®¹ç¯„å›²ã§ã™ãŒã€æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™**")
            st.markdown("æ­£è¦åŒ–å†æ§‹æˆèª¤å·®ãŒ0.3ä»¥ä¸‹ã§è¨±å®¹ç¯„å›²å†…ã§ã™ãŒã€ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¯èƒ½ã§ã™ã€‚")
        else:
            st.error("âŒ **æ”¹å–„ãŒå¿…è¦ã§ã™**")
            st.markdown("æ­£è¦åŒ–å†æ§‹æˆèª¤å·®ãŒ0.3ä»¥ä¸Šã§ã€ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦å‘ä¸ŠãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚")

        # ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã®åˆ†æ
        st.markdown("---")
        st.markdown("### ğŸ“Š ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ï¼ˆç–è¡Œåˆ—æ€§ï¼‰")

        sparsity_info = mf_model.get_model_sparsity()

        col1, col2 = st.columns(2)
        with col1:
            st.metric("ãƒ¡ãƒ³ãƒãƒ¼å› å­ï¼ˆWï¼‰ã®ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§", f"{sparsity_info['W_sparsity']:.2f}%")
        with col2:
            st.metric("åŠ›é‡å› å­ï¼ˆHï¼‰ã®ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§", f"{sparsity_info['H_sparsity']:.2f}%")

        # è¨ºæ–­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        st.markdown(sparsity_info['recommendation'])

        if sparsity_info['unused_factors']:
            st.warning(f"""
            **âš ï¸ æœªä½¿ç”¨ã®æ½œåœ¨å› å­ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ**

            æœªä½¿ç”¨ã®æ½œåœ¨å› å­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {sparsity_info['unused_factors']}

            ç¾åœ¨ã®æ½œåœ¨å› å­æ•°ã‚’ {mf_model.n_components - len(sparsity_info['unused_factors'])} ã«å‰Šæ¸›ã—ã¦å†å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
            ã“ã‚Œã«ã‚ˆã‚Šè¨ˆç®—åŠ¹ç‡ãŒå‘ä¸Šã—ã€ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚
            """)

        # è¿½åŠ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        st.markdown("---")
        st.markdown("### ğŸ“ˆ å­¦ç¿’æƒ…å ±")

        col1, col2, col3 = st.columns(3)

        with col1:
            n_iter = mf_model.actual_n_iter_ if mf_model.actual_n_iter_ is not None else getattr(mf_model.model, 'n_iter_', 'N/A')
            st.metric("ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°", n_iter)

        with col2:
            st.metric("æ½œåœ¨å› å­æ•°", mf_model.n_components)

        with col3:
            st.metric("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°", len(mf_model.member_codes) * len(mf_model.competence_codes))

        # æ”¹å–„ææ¡ˆ
        if normalized_error >= 0.2:
            st.markdown("---")
            st.markdown("### ğŸ’¡ æ”¹å–„ææ¡ˆ")

            current_components = mf_model.n_components

            st.info(f"""
            **æ¨å¥¨ã•ã‚Œã‚‹æ”¹å–„ç­–:**

            1. **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**:
               - ä¸Šè¨˜ã®ã€Œå­¦ç¿’ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ã§ã€Œãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Optuna)ã€ã‚’æœ‰åŠ¹ã«ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã¦ãã ã•ã„
               - ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã«ã‚ˆã‚Šæœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè‡ªå‹•çš„ã«æ¢ç´¢ã•ã‚Œã¾ã™

            2. **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®æœ‰åŠ¹åŒ–**:
               - ã€Œãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’ä½¿ç”¨ã€ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã“ã¨ã§ã€å¤–ã‚Œå€¤ã®é™¤å»ã¨æ­£è¦åŒ–ãŒè¡Œã‚ã‚Œã¾ã™
               - ã‚¹ãƒ‘ãƒ¼ã‚¹ãªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ç‰¹ã«åŠ¹æœçš„ã§ã™

            3. **æ‰‹å‹•ã§ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´** (config.py):
               - æ½œåœ¨å› å­æ•°: ç¾åœ¨ {current_components} â†’ 25ã€œ35 ã«å¢—åŠ ã‚’æ¤œè¨
               - æ­£å‰‡åŒ–å¼·åº¦: alpha_W, alpha_H ã‚’ 0.05ã€œ0.1 ã«èª¿æ•´
               - æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: max_iter ã‚’ 1500ã€œ2000 ã«å¢—åŠ 

            è©³ç´°ã¯ `docs/EVALUATION.md` ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
            """)

    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®è¡¨ç¤º
    if recommender.tuning_results is not None:
        with st.expander("ğŸ¯ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœ", expanded=True):
            tuning_results = recommender.tuning_results
            tuner = tuning_results['tuner']

            # ç›®çš„é–¢æ•°ã®èª¬æ˜
            st.markdown("### ğŸ¯ æœ€é©åŒ–ã®ç›®çš„")
            st.info(
                f"""
                **{tuner.objective_description}**

                **æ¢ç´¢å¯¾è±¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
                - **n_components**: æ½œåœ¨å› å­æ•°ï¼ˆ10-30ã®ç¯„å›²ï¼‰
                - **alpha_W**: ãƒ¡ãƒ³ãƒãƒ¼å› å­ã®æ­£å‰‡åŒ–å¼·åº¦ï¼ˆ0.001-0.5ã€å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
                - **alpha_H**: åŠ›é‡å› å­ã®æ­£å‰‡åŒ–å¼·åº¦ï¼ˆ0.001-0.5ã€å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
                - **l1_ratio**: L1æ­£å‰‡åŒ–ã®å‰²åˆï¼ˆ0.0-1.0ï¼‰
                - **n_init**: åˆæœŸåŒ–è©¦è¡Œå›æ•°ï¼ˆ1-5ã€è¤‡æ•°åˆæœŸå€¤ã‹ã‚‰æœ€è‰¯ã‚’é¸æŠï¼‰

                **è‡ªå‹•è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
                - **max_iter**: ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã‹ã‚‰è‡ªå‹•è¨ˆç®—ï¼ˆ{tuner.max_iter}ï¼‰
                  - ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã€Early Stoppingè¨­å®šã«åŸºã¥ã„ã¦æ±ºå®š

                **å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
                - init=nndsvda, solver=cd, tol=1e-5

                **æ”¹å–„æ©Ÿèƒ½:**
                - Early StoppingãŒæ¤œè¨¼ã‚»ãƒƒãƒˆã®èª¤å·®ã‚’ç›£è¦–ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
                - è¨“ç·´èª¤å·®ã¨æ¤œè¨¼èª¤å·®ã®ä¹–é›¢ã‚’è¨˜éŒ²ï¼ˆæ±åŒ–ã‚®ãƒ£ãƒƒãƒ—ç›£è¦–ï¼‰
                """
            )

            st.markdown("---")
            st.markdown("### ğŸ“Š ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒãƒªãƒ¼")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                default_params = tuning_results['default_params']
                for key, value in default_params.items():
                    if key in ['n_components', 'max_iter', 'alpha_W', 'alpha_H', 'l1_ratio', 'n_init']:
                        st.text(f"{key}: {value}")

            with col2:
                st.markdown("#### æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                best_params = tuning_results['best_params']
                for key, value in best_params.items():
                    if isinstance(value, float):
                        st.text(f"{key}: {value:.4f}")
                    else:
                        st.text(f"{key}: {value}")

                # æœ€è‰¯ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã®random_stateã‚’è¡¨ç¤º
                tuner = tuning_results['tuner']
                best_trial = tuner.study.best_trial
                best_random_state = best_trial.user_attrs.get('random_state', 'N/A')
                st.text(f"random_state: {best_random_state}")

            st.markdown("---")
            st.markdown("### ğŸ“ˆ æœ€é©åŒ–å±¥æ­´")

            # æœ€é©åŒ–å±¥æ­´ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
            tuner = tuning_results['tuner']

            try:
                fig_history = tuner.plot_optimization_history()
                if fig_history:
                    st.plotly_chart(fig_history, use_container_width=True)

                st.markdown("### ğŸ” ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é‡è¦åº¦")
                fig_importance = tuner.plot_param_importances()
                if fig_importance:
                    st.plotly_chart(fig_importance, use_container_width=True)

                st.info("""
                **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é‡è¦åº¦**ã¯ã€å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå†æ§‹æˆèª¤å·®ã«ä¸ãˆã‚‹å½±éŸ¿ã®å¤§ãã•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
                é‡è¦åº¦ãŒé«˜ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã»ã©ã€ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã«å¤§ããå½±éŸ¿ã—ã¾ã™ã€‚
                """)

            except Exception as e:
                st.warning(f"ã‚°ãƒ©ãƒ•ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ç¯„å›²çµ±è¨ˆ
            st.markdown("### ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ç¯„å›²ã®çµ±è¨ˆ")
            try:
                trials_df = tuner.get_optimization_history()

                # å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
                # max_iterã¯è‡ªå‹•è¨ˆç®—ã•ã‚Œã‚‹ãŸã‚é™¤å¤–
                param_stats = {}
                param_cols = ['params_n_components', 'params_alpha_W', 'params_alpha_H',
                             'params_l1_ratio']

                stats_data = []
                for col in param_cols:
                    if col in trials_df.columns:
                        param_name = col.replace('params_', '')
                        stats_data.append({
                            'ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿': param_name,
                            'æœ€å°å€¤': f"{trials_df[col].min():.6f}",
                            'æœ€å¤§å€¤': f"{trials_df[col].max():.6f}",
                            'å¹³å‡å€¤': f"{trials_df[col].mean():.6f}",
                            'æ¨™æº–åå·®': f"{trials_df[col].std():.6f}"
                        })

                if stats_data:
                    stats_df = pd.DataFrame(stats_data)
                    st.dataframe(stats_df, use_container_width=True)

                    st.info("""
                    **æ¢ç´¢ç¯„å›²ã®çµ±è¨ˆ**ã¯ã€OptunaãŒå®Ÿéš›ã«è©¦ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
                    - **æœ€å°å€¤ãƒ»æœ€å¤§å€¤**ï¼šå®Ÿéš›ã«è©¦ã•ã‚ŒãŸå€¤ã®ç¯„å›²
                    - **æ¨™æº–åå·®**ãŒå¤§ãã„ï¼šåºƒã„ç¯„å›²ã‚’æ¢ç´¢ã—ã¦ã„ã‚‹ï¼ˆè‰¯ã„å…†å€™ï¼‰
                    - **æ¨™æº–åå·®**ãŒå°ã•ã„ï¼šç‹­ã„ç¯„å›²ã«é›†ä¸­ã—ã¦ã„ã‚‹ï¼ˆæ¢ç´¢ãŒä¸ååˆ†ãªå¯èƒ½æ€§ï¼‰
                    """)

                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’è¡¨ç¤º
                with st.expander("ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ "):
                    import plotly.graph_objects as go
                    from plotly.subplots import make_subplots

                    # alpha_W ã¨ alpha_H ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«é‡è¦ï¼‰
                    fig = make_subplots(
                        rows=2, cols=2,
                        subplot_titles=('alpha_W (å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«)', 'alpha_H (å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«)',
                                       'l1_ratio', 'n_components')
                    )

                    if 'params_alpha_W' in trials_df.columns:
                        fig.add_trace(
                            go.Histogram(x=trials_df['params_alpha_W'], name='alpha_W', nbinsx=20),
                            row=1, col=1
                        )
                        fig.update_xaxes(type="log", row=1, col=1)

                    if 'params_alpha_H' in trials_df.columns:
                        fig.add_trace(
                            go.Histogram(x=trials_df['params_alpha_H'], name='alpha_H', nbinsx=20),
                            row=1, col=2
                        )
                        fig.update_xaxes(type="log", row=1, col=2)

                    if 'params_l1_ratio' in trials_df.columns:
                        fig.add_trace(
                            go.Histogram(x=trials_df['params_l1_ratio'], name='l1_ratio', nbinsx=20),
                            row=2, col=1
                        )

                    if 'params_n_components' in trials_df.columns:
                        fig.add_trace(
                            go.Histogram(x=trials_df['params_n_components'], name='n_components', nbinsx=20),
                            row=2, col=2
                        )

                    fig.update_layout(height=600, showlegend=False, title_text="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒï¼ˆå…¨ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ï¼‰")
                    st.plotly_chart(fig, use_container_width=True)

                    st.info("""
                    **ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ **ã§ã€OptunaãŒå„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã©ã‚Œã ã‘åºƒãæ¢ç´¢ã—ãŸã‹ç¢ºèªã§ãã¾ã™ã€‚
                    - å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆalpha_W, alpha_Hï¼‰ã¯åºƒã„ç¯„å›²ï¼ˆ0.001ï½1.0ï¼‰ã‚’æ¢ç´¢
                    - åˆ†å¸ƒãŒåã£ã¦ã„ã‚‹å ´åˆã€æ¢ç´¢ç¯„å›²ã®èª¿æ•´ãŒå¿…è¦ãªå¯èƒ½æ€§
                    """)

            except Exception as e:
                st.warning(f"çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            # è©³ç´°ãªè©¦è¡Œçµæœã‚’è¡¨ç¤º
            with st.expander("ğŸ“‹ å…¨è©¦è¡Œã®è©³ç´°çµæœ"):
                try:
                    trials_df = tuner.get_optimization_history()
                    # å¿…è¦ãªåˆ—ã®ã¿ã‚’è¡¨ç¤ºï¼ˆrandom_stateã‚‚è¿½åŠ ï¼‰
                    display_cols = ['number', 'value', 'params_n_components', 'params_alpha_W',
                                   'params_alpha_H', 'params_l1_ratio', 'params_max_iter',
                                   'user_attrs_random_state', 'user_attrs_n_iter', 'state']
                    available_cols = [col for col in display_cols if col in trials_df.columns]

                    if available_cols:
                        # å†æ§‹æˆèª¤å·®ã§ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤º
                        display_df = trials_df[available_cols].sort_values('value')
                        st.dataframe(
                            display_df,
                            use_container_width=True,
                            height=400
                        )

                        # æœ€è‰¯ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã®è©³ç´°ã‚’å¼·èª¿è¡¨ç¤º
                        best_trial_num = display_df.iloc[0]['number']
                        best_value = display_df.iloc[0]['value']
                        st.success(f"âœ¨ æœ€è‰¯ãƒˆãƒ©ã‚¤ã‚¢ãƒ«: #{int(best_trial_num)} (å†æ§‹æˆèª¤å·®: {best_value:.6f})")

                    else:
                        st.dataframe(trials_df, use_container_width=True, height=400)

                    st.info("""
                    **user_attrs_random_state**: å„ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã§ä½¿ç”¨ã•ã‚ŒãŸrandom_stateï¼ˆç•°ãªã‚‹å€¤ã§æ¢ç´¢ï¼‰
                    **user_attrs_n_iter**: åæŸã¾ã§ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°
                    """)

                except Exception as e:
                    st.warning(f"è©¦è¡Œçµæœã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # è¨“ç·´ vs ãƒ†ã‚¹ãƒˆèª¤å·®ã®è©•ä¾¡
    if recommender.tuning_results is not None and hasattr(recommender.tuning_results.get('tuner'), 'evaluate_training_vs_test'):
        tuner = recommender.tuning_results.get('tuner')
        if hasattr(tuner, 'test_matrix') and tuner.test_matrix is not None:
            with st.expander("ğŸ“Š è¨“ç·´ vs ãƒ†ã‚¹ãƒˆèª¤å·®ã®åˆ†æï¼ˆæ±åŒ–æ€§èƒ½è¨ºæ–­ï¼‰"):
                st.markdown("### ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’è¨ºæ–­ã—ã¾ã™")

                try:
                    # è¨“ç·´ vs ãƒ†ã‚¹ãƒˆèª¤å·®ã‚’è¨ˆç®—
                    eval_results = tuner.evaluate_training_vs_test(mf_model)

                    # çµæœã‚’è¡¨ç¤º
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("è¨“ç·´ãƒ‡ãƒ¼ã‚¿èª¤å·®", f"{eval_results['train_error']:.6f}")
                        st.text(f"ã‚µã‚¤ã‚º: {eval_results['train_size']}")

                    with col2:
                        if 'test_error' in eval_results:
                            st.metric("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª¤å·®", f"{eval_results['test_error']:.6f}")
                            st.text(f"ã‚µã‚¤ã‚º: {eval_results['test_size']}")
                        else:
                            st.metric("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª¤å·®", "N/A")

                    with col3:
                        if 'generalization_gap' in eval_results:
                            gap = eval_results['generalization_gap']
                            st.metric("æ±åŒ–ã‚®ãƒ£ãƒƒãƒ—", f"{gap:.6f}")
                            st.text(f"å·®åˆ†æ¯”: {(gap/eval_results['train_error']*100):.1f}%")

                    st.markdown("---")
                    st.markdown("### è¨ºæ–­çµæœ")

                    # è¨ºæ–­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                    diagnosis = eval_results.get('diagnosis', '')
                    if 'å„ªã‚ŒãŸ' in diagnosis or 'âœ…' in diagnosis:
                        st.success(diagnosis)
                    elif 'è»½åº¦' in diagnosis or 'âš ï¸' in diagnosis:
                        st.warning(diagnosis)
                    else:
                        st.error(diagnosis)

                    # è©³ç´°èª¬æ˜
                    st.info("""
                    **æ±åŒ–ã‚®ãƒ£ãƒƒãƒ—ã®è§£é‡ˆ:**
                    - **ã‚®ãƒ£ãƒƒãƒ—ãŒå°ã•ã„ï¼ˆ<10%ï¼‰**: ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ãŒå„ªã‚Œã¦ã„ã‚‹
                    - **ã‚®ãƒ£ãƒƒãƒ—ãŒä¸­ç¨‹åº¦ï¼ˆ10-30%ï¼‰**: è»½åº¦ã®éå­¦ç¿’ãŒè¦‹ã‚‰ã‚Œã‚‹ãŒè¨±å®¹ç¯„å›²
                    - **ã‚®ãƒ£ãƒƒãƒ—ãŒå¤§ãã„ï¼ˆ>30%ï¼‰**: é¡•è‘—ãªéå­¦ç¿’ã®å¯èƒ½æ€§ã€ãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„æ¨å¥¨

                    **æ”¹å–„æ–¹æ³•:**
                    1. æ­£å‰‡åŒ–å¼·åº¦ï¼ˆalpha_W, alpha_Hï¼‰ã‚’å¢—åŠ ã•ã›ã‚‹
                    2. æ—©æœŸåœæ­¢ï¼ˆEarly Stoppingï¼‰ã‚’æœ‰åŠ¹ã«ã™ã‚‹
                    3. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’æœ‰åŠ¹ã«ã™ã‚‹
                    4. ã‚ˆã‚Šå¤šãã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã™ã‚‹
                    """)

                except Exception as e:
                    st.warning(f"æ±åŒ–æ€§èƒ½ã®è¨ºæ–­ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    st.info("ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆãŒåˆ†é›¢ã•ã‚Œã¦ã„ãªã„ã‹ã€è¨ºæ–­ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

    st.markdown("---")
    st.success("âœ… å­¦ç¿’çµæœã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    st.info("ğŸ‘‰ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œæ¨è«–ã€ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¦ã€æ¨è–¦ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
