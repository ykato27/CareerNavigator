"""
ã‚­ãƒ£ãƒªã‚¢æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨åˆ†æ
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

from skillnote_recommendation.ml.ml_recommender import MLRecommender


# =========================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =========================================================
st.set_page_config(
    page_title="ã‚­ãƒ£ãƒªã‚¢æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¢ãƒ‡ãƒ«å­¦ç¿’",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨åˆ†æ")
st.markdown("**ã‚¹ãƒ†ãƒƒãƒ—2**: MLãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€å­¦ç¿’çµæœã‚’åˆ†æã—ã¾ã™ã€‚")


# =========================================================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒã‚§ãƒƒã‚¯
# =========================================================
if not st.session_state.get("data_loaded", False):
    st.warning("âš ï¸ ã¾ãšãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
    st.info("ğŸ‘‰ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€ãƒšãƒ¼ã‚¸ã«æˆ»ã£ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()


# =========================================================
# è£œåŠ©é–¢æ•°
# =========================================================
def build_ml_recommender(transformed_data: dict) -> MLRecommender:
    """
    MLRecommenderã‚’å­¦ç¿’æ¸ˆã¿ã®çŠ¶æ…‹ã§ä½œæˆã™ã‚‹
    """
    recommender = MLRecommender.build(
        member_competence=transformed_data["member_competence"],
        competence_master=transformed_data["competence_master"],
        member_master=transformed_data["members_clean"]
    )
    return recommender


# =========================================================
# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# =========================================================
st.subheader("ğŸ“ MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’")

if st.session_state.get("model_trained", False):
    st.success("âœ… MLãƒ¢ãƒ‡ãƒ«ã¯æ—¢ã«å­¦ç¿’æ¸ˆã¿ã§ã™ã€‚")

    if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã™ã‚‹"):
        st.session_state.model_trained = False
        st.session_state.ml_recommender = None
        st.rerun()
else:
    st.info("ğŸ“š NMFï¼ˆéè² å€¤è¡Œåˆ—åˆ†è§£ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¡ãƒ³ãƒãƒ¼ã®åŠ›é‡ç¿’å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã¾ã™ã€‚")

    if st.button("ğŸš€ MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œ", type="primary"):
        with st.spinner("MLãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­..."):
            try:
                ml_recommender = build_ml_recommender(
                    st.session_state.transformed_data
                )
                st.session_state.ml_recommender = ml_recommender
                st.session_state.model_trained = True
                st.success("âœ… MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                st.rerun()
            except Exception as e:
                import traceback
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {e}")
                st.code(traceback.format_exc())
                st.info("ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
                st.write("transformed_data keys:", list(st.session_state.transformed_data.keys()))


# =========================================================
# å­¦ç¿’çµæœã®åˆ†æ
# =========================================================
if st.session_state.get("model_trained", False):
    st.markdown("---")
    st.subheader("ğŸ“Š å­¦ç¿’çµæœã®åˆ†æ")

    recommender = st.session_state.ml_recommender
    mf_model = recommender.mf_model

    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("æ½œåœ¨å› å­æ•°", mf_model.n_components)

    with col2:
        st.metric("ãƒ¡ãƒ³ãƒãƒ¼æ•°", len(mf_model.member_index))

    with col3:
        st.metric("åŠ›é‡æ•°", len(mf_model.competence_index))

    with col4:
        error = mf_model.get_reconstruction_error()
        st.metric("å†æ§‹æˆèª¤å·®", f"{error:.4f}")

    # NMFæˆåˆ†ã®åˆ†æ
    st.markdown("### ğŸ” NMFæ½œåœ¨å› å­ã®åˆ†æ")

    st.markdown(
        "NMFã¯ãƒ¡ãƒ³ãƒãƒ¼Ã—åŠ›é‡ãƒãƒˆãƒªã‚¯ã‚¹ã‚’**ãƒ¡ãƒ³ãƒãƒ¼å› å­è¡Œåˆ—**ã¨**åŠ›é‡å› å­è¡Œåˆ—**ã«åˆ†è§£ã—ã¾ã™ã€‚\n"
        "å„æ½œåœ¨å› å­ã¯ã€ç‰¹å®šã®åŠ›é‡ç¾¤ï¼ˆã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆï¼‰ã‚’è¡¨ã—ã€ãƒ¡ãƒ³ãƒãƒ¼ã¯ã“ã‚Œã‚‰ã®å› å­ã®çµ„ã¿åˆã‚ã›ã§è¡¨ç¾ã•ã‚Œã¾ã™ã€‚"
    )

    # å„æ½œåœ¨å› å­ã®ç‰¹å¾´ã‚’åˆ†æ
    with st.expander("ğŸ“ˆ æ½œåœ¨å› å­ã”ã¨ã®ä»£è¡¨åŠ›é‡ï¼ˆãƒˆãƒƒãƒ—10ï¼‰"):
        competence_master = st.session_state.transformed_data["competence_master"]

        n_factors_to_show = min(5, mf_model.n_components)

        for factor_idx in range(n_factors_to_show):
            st.markdown(f"#### æ½œåœ¨å› å­ {factor_idx + 1}")

            # ã“ã®å› å­ã§é‡ã¿ãŒé«˜ã„åŠ›é‡ã‚’å–å¾—
            factor_weights = mf_model.H[factor_idx, :]
            top_indices = factor_weights.argsort()[-10:][::-1]
            top_competences = [mf_model.competence_codes[i] for i in top_indices]
            top_weights = [factor_weights[i] for i in top_indices]

            # åŠ›é‡åã‚’å–å¾—
            top_competence_names = []
            for comp_code in top_competences:
                comp_info = competence_master[competence_master["åŠ›é‡ã‚³ãƒ¼ãƒ‰"] == comp_code]
                if len(comp_info) > 0:
                    top_competence_names.append(comp_info.iloc[0]["åŠ›é‡å"])
                else:
                    top_competence_names.append(comp_code)

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã§è¡¨ç¤º
            df_factor = pd.DataFrame({
                "åŠ›é‡å": top_competence_names,
                "é‡ã¿": top_weights
            })

            col1, col2 = st.columns([2, 1])

            with col1:
                # æ£’ã‚°ãƒ©ãƒ•
                fig = px.bar(
                    df_factor,
                    x="é‡ã¿",
                    y="åŠ›é‡å",
                    orientation="h",
                    title=f"æ½œåœ¨å› å­ {factor_idx + 1} ã®ä»£è¡¨åŠ›é‡"
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                # ãƒ†ãƒ¼ãƒ–ãƒ«
                st.dataframe(df_factor, use_container_width=True, height=400)

    # ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­åˆ†å¸ƒ
    with st.expander("ğŸ‘¥ ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­åˆ†å¸ƒ"):
        st.markdown("å„ãƒ¡ãƒ³ãƒãƒ¼ãŒã©ã®æ½œåœ¨å› å­ã‚’å¼·ãæŒã£ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚")

        # ãƒ©ãƒ³ãƒ€ãƒ ã«10åã‚’ã‚µãƒ³ãƒ—ãƒ«
        import numpy as np

        n_members_to_show = min(10, len(mf_model.member_codes))
        random_indices = np.random.choice(len(mf_model.member_codes), n_members_to_show, replace=False)

        member_codes = [mf_model.member_codes[i] for i in random_indices]
        member_names = []
        members_df = st.session_state.transformed_data["members_clean"]
        for code in member_codes:
            member_info = members_df[members_df["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"] == code]
            if len(member_info) > 0:
                member_names.append(member_info.iloc[0]["ãƒ¡ãƒ³ãƒãƒ¼å"])
            else:
                member_names.append(code)

        # å„ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­ã®é‡ã¿ã‚’å–å¾—
        member_factors_data = []
        for i, (idx, member_code) in enumerate(zip(random_indices, member_codes)):
            factors = mf_model.W[idx, :]
            for factor_idx, weight in enumerate(factors):
                member_factors_data.append({
                    "ãƒ¡ãƒ³ãƒãƒ¼": member_names[i],  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ç›´æ¥å‚ç…§
                    "æ½œåœ¨å› å­": f"å› å­{factor_idx + 1}",
                    "é‡ã¿": weight
                })

        df_member_factors = pd.DataFrame(member_factors_data)

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        duplicates = df_member_factors[df_member_factors.duplicated(subset=["ãƒ¡ãƒ³ãƒãƒ¼", "æ½œåœ¨å› å­"], keep=False)]
        if not duplicates.empty:
            st.warning(f"âš ï¸ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆ{len(duplicates)}ä»¶ï¼‰ã€‚é‡è¤‡ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
            df_member_factors = df_member_factors.drop_duplicates(subset=["ãƒ¡ãƒ³ãƒãƒ¼", "æ½œåœ¨å› å­"], keep="first")

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        pivot_table = df_member_factors.pivot_table(
            index="ãƒ¡ãƒ³ãƒãƒ¼",
            columns="æ½œåœ¨å› å­",
            values="é‡ã¿",
            aggfunc="mean"  # ä¸‡ãŒä¸€é‡è¤‡ãŒã‚ã‚‹å ´åˆã¯å¹³å‡ã‚’å–ã‚‹
        )

        fig = px.imshow(
            pivot_table,
            labels=dict(x="æ½œåœ¨å› å­", y="ãƒ¡ãƒ³ãƒãƒ¼", color="é‡ã¿"),
            title="ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å› å­åˆ†å¸ƒãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
            color_continuous_scale="Blues"
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)

    # åŠ›é‡ã®æ½œåœ¨å› å­åˆ†å¸ƒ
    with st.expander("ğŸ’¡ åŠ›é‡ã®æ½œåœ¨å› å­åˆ†å¸ƒ"):
        st.markdown("å„åŠ›é‡ãŒã©ã®æ½œåœ¨å› å­ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚")

        # ãƒ©ãƒ³ãƒ€ãƒ ã«10å€‹ã®åŠ›é‡ã‚’ã‚µãƒ³ãƒ—ãƒ«
        n_competences_to_show = min(10, len(mf_model.competence_codes))
        random_comp_indices = np.random.choice(len(mf_model.competence_codes), n_competences_to_show, replace=False)

        competence_codes = [mf_model.competence_codes[i] for i in random_comp_indices]
        competence_names = []
        for code in competence_codes:
            comp_info = competence_master[competence_master["åŠ›é‡ã‚³ãƒ¼ãƒ‰"] == code]
            if len(comp_info) > 0:
                competence_names.append(comp_info.iloc[0]["åŠ›é‡å"])
            else:
                competence_names.append(code)

        # å„åŠ›é‡ã®æ½œåœ¨å› å­ã®é‡ã¿ã‚’å–å¾—
        competence_factors_data = []
        for i, (idx, comp_code) in enumerate(zip(random_comp_indices, competence_codes)):
            factors = mf_model.H[:, idx]
            for factor_idx, weight in enumerate(factors):
                competence_factors_data.append({
                    "åŠ›é‡": competence_names[i],  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ç›´æ¥å‚ç…§
                    "æ½œåœ¨å› å­": f"å› å­{factor_idx + 1}",
                    "é‡ã¿": weight
                })

        df_competence_factors = pd.DataFrame(competence_factors_data)

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        duplicates_comp = df_competence_factors[df_competence_factors.duplicated(subset=["åŠ›é‡", "æ½œåœ¨å› å­"], keep=False)]
        if not duplicates_comp.empty:
            st.warning(f"âš ï¸ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆ{len(duplicates_comp)}ä»¶ï¼‰ã€‚é‡è¤‡ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
            df_competence_factors = df_competence_factors.drop_duplicates(subset=["åŠ›é‡", "æ½œåœ¨å› å­"], keep="first")

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        pivot_table_comp = df_competence_factors.pivot_table(
            index="åŠ›é‡",
            columns="æ½œåœ¨å› å­",
            values="é‡ã¿",
            aggfunc="mean"  # ä¸‡ãŒä¸€é‡è¤‡ãŒã‚ã‚‹å ´åˆã¯å¹³å‡ã‚’å–ã‚‹
        )

        fig = px.imshow(
            pivot_table_comp,
            labels=dict(x="æ½œåœ¨å› å­", y="åŠ›é‡", color="é‡ã¿"),
            title="åŠ›é‡ã®æ½œåœ¨å› å­åˆ†å¸ƒãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
            color_continuous_scale="Greens"
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)

    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™
    with st.expander("ğŸ“‰ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™"):
        st.markdown("### å†æ§‹æˆèª¤å·®ã®è©³ç´°")

        error = mf_model.get_reconstruction_error()

        st.metric("å†æ§‹æˆèª¤å·®ï¼ˆFrobenius ãƒãƒ«ãƒ ï¼‰", f"{error:.6f}")

        st.markdown(
            "**å†æ§‹æˆèª¤å·®ãŒä½ã„ã»ã©ã€ãƒ¢ãƒ‡ãƒ«ã¯å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ˆãå†ç¾ã§ãã¦ã„ã¾ã™ã€‚**\n\n"
            "- èª¤å·®ãŒ0.1ä»¥ä¸‹: éå¸¸ã«è‰¯å¥½\n"
            "- èª¤å·®ãŒ0.1-0.3: è‰¯å¥½\n"
            "- èª¤å·®ãŒ0.3-0.5: è¨±å®¹ç¯„å›²\n"
            "- èª¤å·®ãŒ0.5ä»¥ä¸Š: æ”¹å–„ã®ä½™åœ°ã‚ã‚Šï¼ˆæ½œåœ¨å› å­æ•°ã®èª¿æ•´ã‚’æ¨å¥¨ï¼‰"
        )

    st.markdown("---")
    st.success("âœ… å­¦ç¿’çµæœã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    st.info("ğŸ‘‰ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œæ¨è«–ã€ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¦ã€æ¨è–¦ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
