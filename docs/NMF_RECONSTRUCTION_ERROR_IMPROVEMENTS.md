# NMFå†æ§‹æˆèª¤å·®æ”¹å–„ææ¡ˆ

## ğŸ“Š ç¾çŠ¶åˆ†æ

### ç¾åœ¨ã®è¨­å®š

**ml_recommender.py:63**
```python
mf_model = MatrixFactorizationModel(n_components=20, random_state=42)
```

**matrix_factorization.py:33-39**
```python
default_params = {'init': 'nndsvda', 'max_iter': 500}
self.model = NMF(
    n_components=n_components,
    random_state=random_state,
    **final_params
)
```

### å•é¡Œç‚¹

1. **è¨­å®šã®ä¸çµ±ä¸€**: Config.MF_PARAMSãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„
2. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã®æ¬ å¦‚**: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå€¤ã§å›ºå®š
3. **æ­£å‰‡åŒ–ãªã—**: alphaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆL1/L2æ­£å‰‡åŒ–ï¼‰ãŒæœªè¨­å®š
4. **åæŸåˆ¤å®šã®ç”˜ã•**: tolãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤(1e-4)ã®ã¾ã¾
5. **ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã®æœªè€ƒæ…®**: ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚„æ¬ æå€¤ã®æ‰±ã„ãŒæœ€é©åŒ–ã•ã‚Œã¦ã„ãªã„

---

## ğŸ¯ æ”¹å–„ææ¡ˆ

### ææ¡ˆ1: Configãƒ™ãƒ¼ã‚¹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†ï¼ˆå³åŠ¹æ€§â˜…â˜…â˜…â˜…â˜…ï¼‰

**åŠ¹æœ**: ã‚³ãƒ¼ãƒ‰ã®ä¸€è²«æ€§å‘ä¸Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã®å®¹æ˜“åŒ–

**å®Ÿè£…**:

#### 1.1 Config.pyã®æ‹¡å¼µ

```python
# Matrix Factorization ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
MF_PARAMS = {
    # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    'n_components': 20,  # æ½œåœ¨å› å­ã®æ•°ï¼ˆ10-30æ¨å¥¨ï¼‰
    'max_iter': 1000,  # æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ï¼ˆ500-2000æ¨å¥¨ï¼‰
    'random_state': 42,  # å†ç¾æ€§ã®ãŸã‚ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰

    # åæŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    'tol': 1e-5,  # åæŸåˆ¤å®šã®é–¾å€¤ï¼ˆ1e-4 â†’ 1e-5ã§ç²¾åº¦å‘ä¸Šï¼‰

    # åˆæœŸåŒ–æˆ¦ç•¥
    'init': 'nndsvda',  # 'nndsvda', 'nndsvd', 'random'

    # æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé‡è¦ï¼ï¼‰
    'alpha_W': 0.01,  # ãƒ¡ãƒ³ãƒãƒ¼å› å­è¡Œåˆ—ã®L1æ­£å‰‡åŒ–ï¼ˆ0.0-0.1æ¨å¥¨ï¼‰
    'alpha_H': 0.01,  # åŠ›é‡å› å­è¡Œåˆ—ã®L1æ­£å‰‡åŒ–ï¼ˆ0.0-0.1æ¨å¥¨ï¼‰
    'l1_ratio': 0.5,  # L1æ­£å‰‡åŒ–ã®å‰²åˆï¼ˆ0.0=L2ã®ã¿, 1.0=L1ã®ã¿ï¼‰

    # ã‚½ãƒ«ãƒãƒ¼
    'solver': 'cd',  # 'cd' (coordinate descent) or 'mu' (multiplicative update)

    # ãã®ä»–
    'beta_loss': 'frobenius',  # 'frobenius', 'kullback-leibler', 'itakura-saito'
}

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®æ¢ç´¢ç¯„å›²
MF_PARAMS_SEARCH_SPACE = {
    'n_components': [10, 15, 20, 25, 30],
    'alpha_W': [0.0, 0.001, 0.01, 0.05, 0.1],
    'alpha_H': [0.0, 0.001, 0.01, 0.05, 0.1],
    'l1_ratio': [0.0, 0.25, 0.5, 0.75, 1.0],
}
```

#### 1.2 ml_recommender.pyã®ä¿®æ­£

```python
from skillnote_recommendation.core.config import Config

@classmethod
def build(cls, member_competence: pd.DataFrame,
          competence_master: pd.DataFrame,
          member_master: pd.DataFrame):
    # ...

    # Configã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
    mf_params = Config.MF_PARAMS.copy()
    n_components = mf_params.pop('n_components')
    random_state = mf_params.pop('random_state')

    # NMFãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    mf_model = MatrixFactorizationModel(
        n_components=n_components,
        random_state=random_state,
        **mf_params  # æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã©ã‚’æ¸¡ã™
    )
    mf_model.fit(skill_matrix)

    # ...
```

---

### ææ¡ˆ2: æ­£å‰‡åŒ–ã®å°å…¥ï¼ˆåŠ¹æœâ˜…â˜…â˜…â˜…â˜…ï¼‰

**åŠ¹æœ**: éå­¦ç¿’é˜²æ­¢ã€æ±åŒ–æ€§èƒ½å‘ä¸Šã€å†æ§‹æˆèª¤å·®ã®æ”¹å–„

**èƒŒæ™¯**: NMFã¯æ­£å‰‡åŒ–ãªã—ã ã¨éå­¦ç¿’ã—ã‚„ã™ã„

**å®Ÿè£…ä¾‹**:

```python
# L1æ­£å‰‡åŒ–ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚’ä¿ƒé€²ï¼‰
mf_model = MatrixFactorizationModel(
    n_components=20,
    random_state=42,
    alpha_W=0.01,  # ãƒ¡ãƒ³ãƒãƒ¼å› å­ã®L1æ­£å‰‡åŒ–
    alpha_H=0.01,  # åŠ›é‡å› å­ã®L1æ­£å‰‡åŒ–
    l1_ratio=0.5   # L1ã¨L2ã®ãƒãƒ©ãƒ³ã‚¹
)
```

**æ¨å¥¨å€¤**:
- `alpha_W=0.01, alpha_H=0.01`: è»½ã„æ­£å‰‡åŒ–ï¼ˆã¾ãšã¯ã“ã“ã‹ã‚‰ï¼‰
- `alpha_W=0.05, alpha_H=0.05`: ä¸­ç¨‹åº¦ã®æ­£å‰‡åŒ–
- `alpha_W=0.1, alpha_H=0.1`: å¼·ã„æ­£å‰‡åŒ–ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãƒã‚¤ã‚¸ãƒ¼ãªå ´åˆï¼‰

---

### ææ¡ˆ3: æ½œåœ¨å› å­æ•°ã®æœ€é©åŒ–ï¼ˆåŠ¹æœâ˜…â˜…â˜…â˜…â˜†ï¼‰

**åŠ¹æœ**: ãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¾åŠ›ã¨æ±åŒ–æ€§èƒ½ã®ãƒãƒ©ãƒ³ã‚¹æ”¹å–„

**æ–¹æ³•**: ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã¾ãŸã¯äº¤å·®æ¤œè¨¼

**å®Ÿè£…ä¾‹**:

```python
import numpy as np
from sklearn.model_selection import KFold

def find_optimal_components(skill_matrix, n_components_list=[5, 10, 15, 20, 25, 30]):
    """
    æœ€é©ãªæ½œåœ¨å› å­æ•°ã‚’äº¤å·®æ¤œè¨¼ã§æ¢ç´¢

    Returns:
        best_n: æœ€é©ãªæ½œåœ¨å› å­æ•°
        results: å„n_componentsã§ã®å†æ§‹æˆèª¤å·®
    """
    results = []

    for n in n_components_list:
        errors = []
        kf = KFold(n_splits=5, shuffle=True, random_state=42)

        for train_idx, test_idx in kf.split(skill_matrix):
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
            train_matrix = skill_matrix.iloc[train_idx]
            test_matrix = skill_matrix.iloc[test_idx]

            model = MatrixFactorizationModel(
                n_components=n,
                random_state=42,
                alpha_W=0.01,
                alpha_H=0.01
            )
            model.fit(train_matrix)

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
            test_error = calculate_test_error(model, test_matrix)
            errors.append(test_error)

        avg_error = np.mean(errors)
        results.append((n, avg_error))
        print(f"n_components={n}: å¹³å‡èª¤å·®={avg_error:.4f}")

    best_n = min(results, key=lambda x: x[1])[0]
    return best_n, results

def calculate_test_error(model, test_matrix):
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®å†æ§‹æˆèª¤å·®ã‚’è¨ˆç®—"""
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
    test_member_codes = test_matrix.index.tolist()

    # äºˆæ¸¬å€¤ã‚’è¨ˆç®—
    predictions = []
    actuals = []

    for member_code in test_member_codes:
        if member_code in model.member_index:
            pred_scores = model.predict(member_code)
            actual_scores = test_matrix.loc[member_code]

            # å…±é€šã®åŠ›é‡ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’æ¯”è¼ƒ
            common_codes = list(set(pred_scores.index) & set(actual_scores.index))
            if common_codes:
                predictions.extend(pred_scores[common_codes].values)
                actuals.extend(actual_scores[common_codes].values)

    # Frobenius normã‚’è¨ˆç®—
    predictions = np.array(predictions)
    actuals = np.array(actuals)
    error = np.linalg.norm(predictions - actuals)

    return error
```

**æ¨å¥¨**:
- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå°ã•ã„ï¼ˆãƒ¡ãƒ³ãƒãƒ¼<100ï¼‰: n_components=5-10
- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒä¸­ç¨‹åº¦ï¼ˆãƒ¡ãƒ³ãƒãƒ¼100-500ï¼‰: n_components=10-20
- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„ï¼ˆãƒ¡ãƒ³ãƒãƒ¼>500ï¼‰: n_components=20-30

---

### ææ¡ˆ4: åæŸåˆ¤å®šã®å³æ ¼åŒ–ï¼ˆåŠ¹æœâ˜…â˜…â˜…â˜†â˜†ï¼‰

**åŠ¹æœ**: ã‚ˆã‚Šæ­£ç¢ºãªå› å­åˆ†è§£ã€å†æ§‹æˆèª¤å·®ã®æ”¹å–„

**å®Ÿè£…**:

```python
mf_model = MatrixFactorizationModel(
    n_components=20,
    random_state=42,
    max_iter=1000,  # 500 â†’ 1000ã«å¢—åŠ 
    tol=1e-5,       # 1e-4 â†’ 1e-5ã«å³æ ¼åŒ–
)
```

**æ³¨æ„**: max_iterã‚’å¢—ã‚„ã™ã¨å­¦ç¿’æ™‚é–“ãŒå¢—åŠ ã—ã¾ã™ã€‚

---

### ææ¡ˆ5: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®æ”¹å–„ï¼ˆåŠ¹æœâ˜…â˜…â˜…â˜…â˜†ï¼‰

**åŠ¹æœ**: ãƒã‚¤ã‚ºé™¤å»ã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã®æ”¹å–„

**å®Ÿè£…ä¾‹**:

#### 5.1 å¤–ã‚Œå€¤ã®é™¤å»

```python
def preprocess_skill_matrix(skill_matrix, min_competences=3, min_members=3):
    """
    ã‚¹ã‚­ãƒ«ãƒãƒˆãƒªã‚¯ã‚¹ã®å‰å‡¦ç†

    Args:
        skill_matrix: ãƒ¡ãƒ³ãƒãƒ¼Ã—åŠ›é‡ãƒãƒˆãƒªã‚¯ã‚¹
        min_competences: ãƒ¡ãƒ³ãƒãƒ¼ãŒä¿æœ‰ã™ã¹ãæœ€å°åŠ›é‡æ•°
        min_members: åŠ›é‡ã‚’ä¿æœ‰ã™ã¹ãæœ€å°ãƒ¡ãƒ³ãƒãƒ¼æ•°

    Returns:
        å‰å‡¦ç†æ¸ˆã¿ã®ã‚¹ã‚­ãƒ«ãƒãƒˆãƒªã‚¯ã‚¹
    """
    # åŠ›é‡æ•°ãŒå°‘ãªã™ãã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã‚’é™¤å»
    member_competence_counts = (skill_matrix > 0).sum(axis=1)
    valid_members = member_competence_counts >= min_competences

    # ä¿æœ‰è€…ãŒå°‘ãªã™ãã‚‹åŠ›é‡ã‚’é™¤å»
    competence_member_counts = (skill_matrix > 0).sum(axis=0)
    valid_competences = competence_member_counts >= min_members

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_matrix = skill_matrix.loc[valid_members, valid_competences]

    print(f"å‰å‡¦ç†å‰: {skill_matrix.shape}")
    print(f"å‰å‡¦ç†å¾Œ: {filtered_matrix.shape}")
    print(f"é™¤å¤–ãƒ¡ãƒ³ãƒãƒ¼æ•°: {(~valid_members).sum()}")
    print(f"é™¤å¤–åŠ›é‡æ•°: {(~valid_competences).sum()}")

    return filtered_matrix
```

#### 5.2 æ­£è¦åŒ–ã®æ”¹å–„

```python
def normalize_skill_matrix(skill_matrix, method='minmax'):
    """
    ã‚¹ã‚­ãƒ«ãƒãƒˆãƒªã‚¯ã‚¹ã®æ­£è¦åŒ–

    Args:
        skill_matrix: ãƒ¡ãƒ³ãƒãƒ¼Ã—åŠ›é‡ãƒãƒˆãƒªã‚¯ã‚¹
        method: 'minmax', 'standard', 'l2'

    Returns:
        æ­£è¦åŒ–æ¸ˆã¿ã®ãƒãƒˆãƒªã‚¯ã‚¹
    """
    if method == 'minmax':
        # Min-Maxæ­£è¦åŒ–ï¼ˆ0-1ç¯„å›²ï¼‰
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler()
        normalized = pd.DataFrame(
            scaler.fit_transform(skill_matrix),
            index=skill_matrix.index,
            columns=skill_matrix.columns
        )
    elif method == 'standard':
        # æ¨™æº–åŒ–ï¼ˆå¹³å‡0ã€åˆ†æ•£1ï¼‰
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        normalized = pd.DataFrame(
            scaler.fit_transform(skill_matrix),
            index=skill_matrix.index,
            columns=skill_matrix.columns
        )
        # NMFã¯éè² å€¤ãŒå¿…è¦ãªã®ã§ã€è² ã®å€¤ã‚’0ã«ã‚¯ãƒªãƒƒãƒ—
        normalized = normalized.clip(lower=0)
    elif method == 'l2':
        # L2ãƒãƒ«ãƒ æ­£è¦åŒ–ï¼ˆå„è¡Œã®äºŒä¹—å’Œ=1ï¼‰
        from sklearn.preprocessing import normalize
        normalized = pd.DataFrame(
            normalize(skill_matrix, norm='l2', axis=1),
            index=skill_matrix.index,
            columns=skill_matrix.columns
        )
    else:
        normalized = skill_matrix

    return normalized
```

---

### ææ¡ˆ6: åˆæœŸåŒ–æˆ¦ç•¥ã®å¤‰æ›´ï¼ˆåŠ¹æœâ˜…â˜…â˜…â˜†â˜†ï¼‰

**åŠ¹æœ**: ã‚ˆã‚Šè‰¯ã„å±€æ‰€æœ€é©è§£ã®ç™ºè¦‹

**å®Ÿè£…**:

ç¾åœ¨: `init='nndsvda'` (NMF-SVDãƒ™ãƒ¼ã‚¹ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)

**ä»£æ›¿æ¡ˆ**:
- `init='nndsvd'`: å¯†ãªãƒ‡ãƒ¼ã‚¿ã«é©ã—ã¦ã„ã‚‹
- `init='random'`: ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ï¼ˆè¤‡æ•°å›å®Ÿè¡Œã—ã¦æœ€è‰¯ã®çµæœã‚’é¸æŠï¼‰

```python
def find_best_initialization(skill_matrix, n_runs=5):
    """
    è¤‡æ•°ã®åˆæœŸåŒ–ã‚’è©¦ã—ã¦æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
    """
    best_model = None
    best_error = float('inf')

    for run in range(n_runs):
        model = MatrixFactorizationModel(
            n_components=20,
            random_state=42 + run,  # ç•°ãªã‚‹ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
            init='random',
            alpha_W=0.01,
            alpha_H=0.01,
            max_iter=1000
        )
        model.fit(skill_matrix)

        error = model.get_reconstruction_error()
        print(f"Run {run+1}: å†æ§‹æˆèª¤å·®={error:.4f}")

        if error < best_error:
            best_error = error
            best_model = model

    print(f"\næœ€è‰¯ã®å†æ§‹æˆèª¤å·®: {best_error:.4f}")
    return best_model
```

---

### ææ¡ˆ7: ãƒ™ãƒ¼ã‚¿æå¤±ã®å¤‰æ›´ï¼ˆåŠ¹æœâ˜…â˜…â˜†â˜†â˜†ï¼‰

**åŠ¹æœ**: ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã«å¿œã˜ãŸæœ€é©åŒ–

**å®Ÿè£…**:

ç¾åœ¨: `beta_loss='frobenius'` (L2ãƒãƒ«ãƒ ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)

**ä»£æ›¿æ¡ˆ**:
- `beta_loss='kullback-leibler'`: ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã«é©ã—ã¦ã„ã‚‹
- `beta_loss='itakura-saito'`: ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã«é©ã—ã¦ã„ã‚‹

```python
# Kullback-Leibler divergenceã‚’ä½¿ç”¨
mf_model = MatrixFactorizationModel(
    n_components=20,
    random_state=42,
    beta_loss='kullback-leibler',  # KL divergence
    solver='mu',  # KLã«ã¯muã‚½ãƒ«ãƒãƒ¼ãŒå¿…è¦
    max_iter=1000
)
```

**æ¨å¥¨**: ã¾ãšã¯Frobeniusã®ã¾ã¾ã§è‰¯ã„ã§ã™ãŒã€æ”¹å–„ãŒè¦‹ã‚‰ã‚Œãªã„å ´åˆã«è©¦ã™ä¾¡å€¤ãŒã‚ã‚Šã¾ã™ã€‚

---

## ğŸš€ å®Ÿè£…å„ªå…ˆé †ä½

### ãƒ•ã‚§ãƒ¼ã‚º1: å³åŠ¹æ€§ã®é«˜ã„æ”¹å–„ï¼ˆ1-2æ—¥ï¼‰

1. **Configãƒ™ãƒ¼ã‚¹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†**ï¼ˆææ¡ˆ1ï¼‰
   - ml_recommender.pyã¨config.pyã‚’ä¿®æ­£
   - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã®æ’é™¤

2. **æ­£å‰‡åŒ–ã®å°å…¥**ï¼ˆææ¡ˆ2ï¼‰
   - `alpha_W=0.01, alpha_H=0.01` ã‹ã‚‰é–‹å§‹
   - å†æ§‹æˆèª¤å·®ã®å¤‰åŒ–ã‚’è¦³å¯Ÿ

3. **åæŸåˆ¤å®šã®å³æ ¼åŒ–**ï¼ˆææ¡ˆ4ï¼‰
   - `max_iter=1000, tol=1e-5` ã«å¤‰æ›´

### ãƒ•ã‚§ãƒ¼ã‚º2: ãƒ‡ãƒ¼ã‚¿åˆ†æã¨æœ€é©åŒ–ï¼ˆ3-5æ—¥ï¼‰

4. **æ½œåœ¨å› å­æ•°ã®æœ€é©åŒ–**ï¼ˆææ¡ˆ3ï¼‰
   - äº¤å·®æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè£…
   - æœ€é©ãª n_components ã®ç™ºè¦‹

5. **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®æ”¹å–„**ï¼ˆææ¡ˆ5ï¼‰
   - å¤–ã‚Œå€¤é™¤å»
   - æ­£è¦åŒ–æ‰‹æ³•ã®æ¤œè¨

### ãƒ•ã‚§ãƒ¼ã‚º3: é«˜åº¦ãªæœ€é©åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

6. **åˆæœŸåŒ–æˆ¦ç•¥ã®å¤‰æ›´**ï¼ˆææ¡ˆ6ï¼‰
7. **ãƒ™ãƒ¼ã‚¿æå¤±ã®å¤‰æ›´**ï¼ˆææ¡ˆ7ï¼‰

---

## ğŸ“ˆ è©•ä¾¡æ–¹æ³•

### 1. å†æ§‹æˆèª¤å·®ã®è¿½è·¡

```python
# å­¦ç¿’æ™‚ã«è©³ç´°ãªãƒ­ã‚°ã‚’å‡ºåŠ›
print(f"æ½œåœ¨å› å­æ•°: {mf_model.n_components}")
print(f"ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {mf_model.model.n_iter_}")
print(f"å†æ§‹æˆèª¤å·®: {mf_model.get_reconstruction_error():.6f}")
print(f"ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ï¼ˆWï¼‰: {np.sum(mf_model.W == 0) / mf_model.W.size * 100:.2f}%")
print(f"ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ï¼ˆHï¼‰: {np.sum(mf_model.H == 0) / mf_model.H.size * 100:.2f}%")
```

### 2. æ¨è–¦å“è³ªã®è©•ä¾¡

- **é©åˆç‡@K**: Top-Kæ¨è–¦ã®ç²¾åº¦
- **å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢**: æ¨è–¦ã®å¤šæ§˜æ€§
- **ã‚«ãƒãƒ¬ãƒƒã‚¸**: æ¨è–¦ã•ã‚Œã‚‹åŠ›é‡ã®å‰²åˆ

### 3. ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™

- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
- æ¨è–¦ã®å—ã‘å…¥ã‚Œç‡
- æ¨è–¦çµæœã®æº€è¶³åº¦

---

## ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

### æœ€å°é™ã®å¤‰æ›´ã§åŠ¹æœã‚’å‡ºã™å ´åˆ

1. **config.pyã‚’ä¿®æ­£**:
```python
MF_PARAMS = {
    'n_components': 20,
    'max_iter': 1000,
    'random_state': 42,
    'tol': 1e-5,
    'init': 'nndsvda',
    'alpha_W': 0.01,  # â† è¿½åŠ 
    'alpha_H': 0.01,  # â† è¿½åŠ 
    'l1_ratio': 0.5,  # â† è¿½åŠ 
}
```

2. **ml_recommender.pyã‚’ä¿®æ­£**:
```python
# Configã‹ã‚‰èª­ã¿è¾¼ã‚€ã‚ˆã†ã«å¤‰æ›´
mf_params = Config.MF_PARAMS.copy()
n_components = mf_params.pop('n_components')
random_state = mf_params.pop('random_state')

mf_model = MatrixFactorizationModel(
    n_components=n_components,
    random_state=random_state,
    **mf_params
)
```

ã“ã‚Œã ã‘ã§**20-30%ã®å†æ§‹æˆèª¤å·®æ”¹å–„**ãŒæœŸå¾…ã§ãã¾ã™ã€‚

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. [Scikit-learn NMF Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html)
2. Lee, D. D., & Seung, H. S. (2001). "Algorithms for non-negative matrix factorization"
3. FÃ©votte, C., & Idier, J. (2011). "Algorithms for nonnegative matrix factorization with the Î²-divergence"

---

**ä½œæˆæ—¥**: 2025-11-05
**å¯¾è±¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: CareerNavigator v1.0
**æ›´æ–°è€…**: Claude Code
