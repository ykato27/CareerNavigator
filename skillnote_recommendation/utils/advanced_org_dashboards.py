"""
é«˜åº¦ãªçµ„ç¹”åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆè¦–ç‚¹ã§ã®æˆ¦ç•¥çš„äººæåˆ†ææ©Ÿèƒ½ã‚’æä¾›

Updated: 2025-11-22
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, Optional, List, Tuple
from scipy import stats


def extract_category_hierarchy(category_name: str, level: int = 1) -> str:
    """
    ã‚«ãƒ†ã‚´ãƒªåã‹ã‚‰æŒ‡å®šéšå±¤ã¾ã§ã‚’æŠ½å‡ºï¼ˆãƒ•ãƒ«ãƒ‘ã‚¹ä¿æŒï¼‰

    Args:
        category_name: ã‚«ãƒ†ã‚´ãƒªåï¼ˆä¾‹: "æŠ€è¡“ > ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° > Python"ï¼‰
        level: æŠ½å‡ºã™ã‚‹éšå±¤ãƒ¬ãƒ™ãƒ«ï¼ˆ1=ç¬¬ä¸€éšå±¤ã€2=ç¬¬äºŒéšå±¤ã€3=ç¬¬ä¸‰éšå±¤ï¼‰

    Returns:
        æŒ‡å®šéšå±¤ã¾ã§ã®ã‚«ãƒ†ã‚´ãƒªåï¼ˆä¾‹: "æŠ€è¡“ > ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"ï¼‰
    """
    if pd.isna(category_name):
        return "æœªåˆ†é¡"

    parts = str(category_name).split(" > ")
    if level > len(parts):
        return " > ".join(parts)

    return " > ".join(parts[:level])


def format_category_for_display(category_path: str) -> str:
    """
    ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã‚’éšå±¤çš„ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

    Args:
        category_path: ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ï¼ˆä¾‹: "æŠ€è¡“ > ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° > Python"ï¼‰

    Returns:
        éšå±¤ã«å¿œã˜ãŸè¡¨ç¤ºå½¢å¼
    """
    if pd.isna(category_path) or category_path == "æœªåˆ†é¡":
        return "æœªåˆ†é¡"

    parts = str(category_path).split(" > ")
    level = len(parts)

    if level == 1:
        # ç¬¬ä¸€éšå±¤: ãã®ã¾ã¾è¡¨ç¤º
        return parts[0]
    elif level == 2:
        # ç¬¬äºŒéšå±¤: "ç¬¬ä¸€éšå±¤â”€ç¬¬äºŒéšå±¤" ã®å½¢å¼
        return f"{parts[0]}â”€{parts[1]}"
    else:
        # ç¬¬ä¸‰éšå±¤: "ç¬¬ä¸€éšå±¤â”€ç¬¬äºŒéšå±¤â”€ç¬¬ä¸‰éšå±¤" ã®å½¢å¼ã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆè¿½åŠ 
        indent = "    "
        return indent + "â””" + parts[-1]


def format_hierarchical_index(category_paths: List[str], hierarchy_level: int) -> List[str]:
    """
    ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’éšå±¤çš„ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚»ãƒ«çµåˆé¢¨ï¼‰

    Args:
        category_paths: ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        hierarchy_level: é¸æŠã•ã‚Œã¦ã„ã‚‹éšå±¤ãƒ¬ãƒ™ãƒ« (1, 2, 3)

    Returns:
        ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆ
    """
    if hierarchy_level == 1:
        # ç¬¬ä¸€éšå±¤: ã‚·ãƒ³ãƒ—ãƒ«ã«è¡¨ç¤º
        return [cat.split(" > ")[0] if " > " in cat else cat for cat in category_paths]

    elif hierarchy_level == 2:
        # ç¬¬äºŒéšå±¤: ã‚»ãƒ«çµåˆé¢¨ã«è¡¨ç¤ºï¼ˆç½«ç·šãªã—ã€ã‚¹ãƒšãƒ¼ã‚¹ã®ã¿ï¼‰
        formatted = []
        prev_parent = None
        parent_group = []

        for cat_path in category_paths:
            parts = cat_path.split(" > ")
            if len(parts) >= 2:
                parent = parts[0]
                child = parts[1]

                if parent != prev_parent:
                    parent_group.append((cat_path, parent, child, True))  # ã‚°ãƒ«ãƒ¼ãƒ—ã®æœ€åˆ
                    prev_parent = parent
                else:
                    parent_group.append((cat_path, parent, child, False))  # ã‚°ãƒ«ãƒ¼ãƒ—ã®ç¶šã
            else:
                parent_group.append((cat_path, cat_path, "", True))

        # å„ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§æœ€åˆãƒ»ä¸­é–“ãƒ»æœ€å¾Œã‚’åˆ¤å®š
        i = 0
        while i < len(parent_group):
            cat_path, parent, child, is_first = parent_group[i]

            # åŒã˜è¦ªã‚’æŒã¤è¦ç´ ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            group_size = 1
            j = i + 1
            while j < len(parent_group) and parent_group[j][1] == parent:
                group_size += 1
                j += 1

            # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®ä½ç½®ã«å¿œã˜ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆç½«ç·šãªã—ï¼‰
            for k in range(group_size):
                _, _, child, _ = parent_group[i + k]
                if k == 0:
                    # ã‚°ãƒ«ãƒ¼ãƒ—ã®æœ€åˆ: è¦ªåã‚’è¡¨ç¤º
                    formatted.append(f"{parent}ã€€{child}")
                else:
                    # ã‚°ãƒ«ãƒ¼ãƒ—ã®2è¡Œç›®ä»¥é™: è¦ªåã¨åŒã˜é•·ã•ã®å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã§ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ
                    formatted.append(f"{'ã€€' * len(parent)}ã€€{child}")

            i += group_size

        return formatted

    else:  # hierarchy_level == 3
        # ç¬¬ä¸‰éšå±¤: ç¬¬ä¸€éšå±¤ > ç¬¬äºŒéšå±¤ > ç¬¬ä¸‰éšå±¤ ã‚’è¡¨ç¤º
        # ç¬¬äºŒéšå±¤ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦è¦–è¦šçš„ã«åˆ†ã‹ã‚Šã‚„ã™ãè¡¨ç¤º
        formatted = []

        # ã¾ãšã€ã‚«ãƒ†ã‚´ãƒªã‚’è§£æã—ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        category_groups = {}  # key: (parent, child), value: list of grandchildren

        for cat_path in category_paths:
            parts = cat_path.split(" > ")
            if len(parts) >= 3:
                parent = parts[0]
                child = parts[1]
                grandchild = parts[2]
                key = (parent, child)
                if key not in category_groups:
                    category_groups[key] = []
                category_groups[key].append(grandchild)
            elif len(parts) == 2:
                parent = parts[0]
                child = parts[1]
                key = (parent, child)
                if key not in category_groups:
                    category_groups[key] = []
            else:
                # ç¬¬ä¸€éšå±¤ã®ã¿ã®å ´åˆ
                key = (cat_path, "")
                if key not in category_groups:
                    category_groups[key] = []

        # ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸé †åºã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        for parent, child in sorted(category_groups.keys()):
            grandchildren = category_groups[(parent, child)]
            parent_child_label = f"{parent}ã€€{child}" if child else parent

            if grandchildren:
                # ç¬¬ä¸‰éšå±¤ãŒã‚ã‚‹å ´åˆ
                for idx, grandchild in enumerate(grandchildren):
                    if idx == 0:
                        # æœ€åˆã®è¡Œ: è¦ª-å­-å­«ã‚’å…¨ã¦è¡¨ç¤º
                        formatted.append(f"{parent_child_label}ã€€{grandchild}")
                    else:
                        # 2è¡Œç›®ä»¥é™: è¦ª-å­ã¨åŒã˜é•·ã•ã®å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã§ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ
                        formatted.append(f"{'ã€€' * len(parent_child_label)}ã€€{grandchild}")
            else:
                # ç¬¬ä¸‰éšå±¤ãŒãªã„ï¼ˆç¬¬äºŒéšå±¤ã¾ã§ï¼‰å ´åˆ
                formatted.append(parent_child_label)

        return formatted


def render_hierarchical_category_heatmap(
    member_competence_df: pd.DataFrame,
    competence_master_df: pd.DataFrame,
    members_df: pd.DataFrame,
    group_by: str = "è·ç¨®"
) -> None:
    """
    â‘ ã‚«ãƒ†ã‚´ãƒªÃ—è·ç¨®ã®éšå±¤çš„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—

    ã‚«ãƒ†ã‚´ãƒªã‚’éšå±¤çš„ã«é¸æŠã§ãã€å¹³å‡å€¤/ä¸­å¤®å€¤ã‚’é¸æŠå¯èƒ½

    Args:
        member_competence_df: ãƒ¡ãƒ³ãƒãƒ¼åŠ›é‡ãƒãƒˆãƒªã‚¯ã‚¹
        competence_master_df: åŠ›é‡ãƒã‚¹ã‚¿
        members_df: ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿
        group_by: ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹è»¸ï¼ˆ"è·ç¨®", "å½¹è·"ç­‰ï¼‰
    """
    st.markdown(f"### ğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥ Ã— {group_by}åˆ¥ ã‚¹ã‚­ãƒ«åˆ†æ")

    # ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        hierarchy_level = st.selectbox(
            "ã‚«ãƒ†ã‚´ãƒªéšå±¤",
            options=[1, 2, 3],
            format_func=lambda x: ["ç¬¬ä¸€éšå±¤", "ç¬¬äºŒéšå±¤", "ç¬¬ä¸‰éšå±¤"][x-1],
            help="ã‚«ãƒ†ã‚´ãƒªã®è©³ç´°åº¦ã‚’é¸æŠã—ã¾ã™"
        )

    with col2:
        aggregation_method = st.selectbox(
            "é›†è¨ˆæ–¹æ³•",
            options=["mean", "median"],
            format_func=lambda x: "å¹³å‡å€¤" if x == "mean" else "ä¸­å¤®å€¤"
        )

    with col3:
        show_count = st.checkbox("äººæ•°ã‚‚è¡¨ç¤º", value=False)

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    # åŠ›é‡ãƒã‚¹ã‚¿ã«ã‚«ãƒ†ã‚´ãƒªéšå±¤ã‚’è¿½åŠ 
    competence_master_df = competence_master_df.copy()
    if "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å" in competence_master_df.columns:
        competence_master_df["ã‚«ãƒ†ã‚´ãƒªéšå±¤"] = competence_master_df["åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å"].apply(
            lambda x: extract_category_hierarchy(x, hierarchy_level)
        )
    else:
        st.warning("åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼åãŒãƒã‚¹ã‚¿ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    # ãƒ¡ãƒ³ãƒãƒ¼åŠ›é‡ã«ã‚«ãƒ†ã‚´ãƒªéšå±¤ã‚’çµåˆ
    merged_df = member_competence_df.merge(
        competence_master_df[["åŠ›é‡ã‚³ãƒ¼ãƒ‰", "ã‚«ãƒ†ã‚´ãƒªéšå±¤"]],
        on="åŠ›é‡ã‚³ãƒ¼ãƒ‰",
        how="left"
    )

    # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’çµåˆ
    if group_by not in members_df.columns:
        st.warning(f"{group_by}æƒ…å ±ãŒãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    merged_df = merged_df.merge(
        members_df[["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰", group_by]],
        on="ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰",
        how="left"
    )

    # ã‚«ãƒ†ã‚´ãƒªé¸æŠï¼ˆè¤‡æ•°é¸æŠå¯èƒ½ï¼‰
    available_categories = sorted(merged_df["ã‚«ãƒ†ã‚´ãƒªéšå±¤"].dropna().unique())

    selected_categories = st.multiselect(
        "è¡¨ç¤ºã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
        options=available_categories,
        default=available_categories[:10] if len(available_categories) > 10 else available_categories,
        help="åˆ†æå¯¾è±¡ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä¸Šä½10ä»¶ï¼‰"
    )

    if not selected_categories:
        st.info("ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„")
        return

    # é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
    filtered_df = merged_df[merged_df["ã‚«ãƒ†ã‚´ãƒªéšå±¤"].isin(selected_categories)]

    # ä¿æœ‰é‡ã‚«ãƒ©ãƒ ã®æ¤œå‡º
    level_col = None
    for col in ["ä¿æœ‰é‡", "åŠ›é‡ãƒ¬ãƒ™ãƒ«", "ãƒ¬ãƒ™ãƒ«"]:
        if col in filtered_df.columns:
            level_col = col
            break

    if level_col is None:
        st.warning("ä¿æœ‰é‡ã¾ãŸã¯ãƒ¬ãƒ™ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # ä¿æœ‰é‡ã‚’æ•°å€¤å‹ã«å¤‰æ›ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
    filtered_df[level_col] = pd.to_numeric(filtered_df[level_col], errors='coerce')

    # NaNã‚’é™¤å¤–
    filtered_df = filtered_df.dropna(subset=[level_col])

    if len(filtered_df) == 0:
        st.warning("æœ‰åŠ¹ãªä¿æœ‰é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # é›†è¨ˆ
    if aggregation_method == "mean":
        pivot_df = filtered_df.groupby(["ã‚«ãƒ†ã‚´ãƒªéšå±¤", group_by])[level_col].mean().unstack(fill_value=0)
    else:
        pivot_df = filtered_df.groupby(["ã‚«ãƒ†ã‚´ãƒªéšå±¤", group_by])[level_col].median().unstack(fill_value=0)

    # ã‚«ãƒ†ã‚´ãƒªéšå±¤ã§ã‚½ãƒ¼ãƒˆï¼ˆéšå±¤çš„ãªé †åºã‚’ä¿æŒï¼‰
    pivot_df = pivot_df.sort_index()

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’éšå±¤çš„ãªè¡¨ç¤ºã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚»ãƒ«çµåˆé¢¨ï¼‰
    formatted_index = format_hierarchical_index(list(pivot_df.index), hierarchy_level)
    pivot_df_display = pivot_df.copy()
    pivot_df_display.index = formatted_index

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”»ï¼ˆè·ç¨®ã‚’æ¨ªè»¸ã€ã‚«ãƒ†ã‚´ãƒªã‚’ç¸¦è»¸ã«é…ç½®ï¼‰
    fig = px.imshow(
        pivot_df_display,
        labels=dict(x=group_by, y="ã‚«ãƒ†ã‚´ãƒª", color="ä¿æœ‰é‡" if aggregation_method == "mean" else "ä¿æœ‰é‡"),
        aspect="auto",
        color_continuous_scale="Greens",  # è–„ã„ç·‘â†’æ¿ƒã„ç·‘ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        text_auto=".2f"
    )

    fig.update_layout(
        height=max(400, len(pivot_df) * 50),
        title=f"ã‚«ãƒ†ã‚´ãƒªåˆ¥ Ã— {group_by}åˆ¥ ã‚¹ã‚­ãƒ«ä¿æœ‰çŠ¶æ³ï¼ˆ{aggregation_method == 'mean' and 'å¹³å‡' or 'ä¸­å¤®å€¤'}ï¼‰",
        font=dict(size=11),
        xaxis=dict(
            side='top',  # xè»¸ãƒ©ãƒ™ãƒ«ã‚’ä¸Šã«é…ç½®
            tickangle=-45  # ãƒ©ãƒ™ãƒ«ã‚’æ–œã‚ã«è¡¨ç¤º
        ),
        yaxis=dict(
            tickfont=dict(family="Courier New, monospace")  # ç­‰å¹…ãƒ•ã‚©ãƒ³ãƒˆã§ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’æ­£ã—ãè¡¨ç¤º
        )
    )

    st.plotly_chart(fig, use_container_width=True)

    # äººæ•°è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if show_count:
        st.markdown("#### ğŸ‘¥ ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥äººæ•°")
        count_df = filtered_df.groupby(["ã‚«ãƒ†ã‚´ãƒªéšå±¤", group_by]).size().unstack(fill_value=0)
        st.dataframe(count_df, use_container_width=True)

    # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    csv = pivot_df.to_csv(index=True).encode('utf-8-sig')
    st.download_button(
        label=f"ğŸ“¥ {group_by}åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)",
        data=csv,
        file_name=f"category_{group_by}_analysis.csv",
        mime="text/csv"
    )


def render_job_role_skill_heatmap(
    member_competence_df: pd.DataFrame,
    competence_master_df: pd.DataFrame,
    members_df: pd.DataFrame
) -> None:
    """
    â‘¡è·ç¨®Ã—å½¹è·åˆ¥ã‚¹ã‚­ãƒ«é›†è¨ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

    Args:
        member_competence_df: ãƒ¡ãƒ³ãƒãƒ¼åŠ›é‡ãƒãƒˆãƒªã‚¯ã‚¹
        competence_master_df: åŠ›é‡ãƒã‚¹ã‚¿
        members_df: ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿
    """
    st.markdown("### ğŸ¯ è·ç¨® Ã— å½¹è·åˆ¥ ã‚¹ã‚­ãƒ«é›†è¨ˆ")

    # ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
    col1, col2, col3 = st.columns(3)

    with col1:
        aggregation_method = st.selectbox(
            "é›†è¨ˆæ–¹æ³•",
            options=["mean", "median"],
            format_func=lambda x: "å¹³å‡å€¤" if x == "mean" else "ä¸­å¤®å€¤",
            key="job_role_agg"
        )

    # è·ç¨®ã¨å½¹è·ã®é¸æŠ
    if "è·ç¨®" not in members_df.columns or "å½¹è·" not in members_df.columns:
        st.warning("è·ç¨®ã¾ãŸã¯å½¹è·æƒ…å ±ãŒãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    with col2:
        available_jobs = sorted(members_df["è·ç¨®"].dropna().unique())
        selected_jobs = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹è·ç¨®",
            options=available_jobs,
            default=available_jobs,
            key="job_select"
        )

    with col3:
        available_roles = sorted(members_df["å½¹è·"].dropna().unique())
        selected_roles = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹å½¹è·",
            options=available_roles,
            default=available_roles,
            key="role_select"
        )

    if not selected_jobs or not selected_roles:
        st.info("è·ç¨®ã¨å½¹è·ã‚’é¸æŠã—ã¦ãã ã•ã„")
        return

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    filtered_members = members_df[
        (members_df["è·ç¨®"].isin(selected_jobs)) &
        (members_df["å½¹è·"].isin(selected_roles))
    ]

    # ãƒ¡ãƒ³ãƒãƒ¼åŠ›é‡ã«ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’çµåˆ
    merged_df = member_competence_df.merge(
        filtered_members[["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰", "è·ç¨®", "å½¹è·"]],
        on="ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰",
        how="inner"
    )

    # ä¿æœ‰é‡ã‚«ãƒ©ãƒ ã®æ¤œå‡º
    level_col = None
    for col in ["ä¿æœ‰é‡", "åŠ›é‡ãƒ¬ãƒ™ãƒ«", "ãƒ¬ãƒ™ãƒ«"]:
        if col in merged_df.columns:
            level_col = col
            break

    if level_col is None:
        st.warning("ä¿æœ‰é‡ã¾ãŸã¯ãƒ¬ãƒ™ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # ä¿æœ‰é‡ã‚’æ•°å€¤å‹ã«å¤‰æ›ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
    merged_df[level_col] = pd.to_numeric(merged_df[level_col], errors='coerce')

    # NaNã‚’é™¤å¤–
    merged_df = merged_df.dropna(subset=[level_col])

    if len(merged_df) == 0:
        st.warning("æœ‰åŠ¹ãªä¿æœ‰é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # è·ç¨®Ã—å½¹è·ã§ã‚¯ãƒ­ã‚¹é›†è¨ˆ
    if aggregation_method == "mean":
        pivot_df = merged_df.groupby(["è·ç¨®", "å½¹è·"])[level_col].mean().unstack(fill_value=0)
    else:
        pivot_df = merged_df.groupby(["è·ç¨®", "å½¹è·"])[level_col].median().unstack(fill_value=0)

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”»ï¼ˆå½¹è·ã‚’æ¨ªè»¸ã€è·ç¨®ã‚’ç¸¦è»¸ã«é…ç½®ï¼‰
    fig = px.imshow(
        pivot_df,
        labels=dict(x="å½¹è·", y="è·ç¨®", color="ä¿æœ‰é‡"),
        aspect="auto",
        color_continuous_scale="Greens",  # è–„ã„ç·‘â†’æ¿ƒã„ç·‘ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        text_auto=".2f"
    )

    fig.update_layout(
        height=max(400, len(pivot_df) * 60),
        title=f"è·ç¨® Ã— å½¹è·åˆ¥ å¹³å‡ã‚¹ã‚­ãƒ«ä¿æœ‰çŠ¶æ³ï¼ˆ{aggregation_method == 'mean' and 'å¹³å‡' or 'ä¸­å¤®å€¤'}ï¼‰",
        font=dict(size=12),
        xaxis=dict(
            side='top',  # xè»¸ãƒ©ãƒ™ãƒ«ã‚’ä¸Šã«é…ç½®
            tickangle=-45  # ãƒ©ãƒ™ãƒ«ã‚’æ–œã‚ã«è¡¨ç¤º
        )
    )

    st.plotly_chart(fig, use_container_width=True)

    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    st.markdown("#### ğŸ“ˆ çµ±è¨ˆã‚µãƒãƒªãƒ¼")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("æœ€é«˜ã‚¹ã‚­ãƒ«ä¿æœ‰", f"{pivot_df.max().max():.2f}")
    with col2:
        st.metric("æœ€ä½ã‚¹ã‚­ãƒ«ä¿æœ‰", f"{pivot_df.min().min():.2f}")
    with col3:
        st.metric("å…¨ä½“å¹³å‡", f"{pivot_df.mean().mean():.2f}")

    # äººæ•°ãƒãƒˆãƒªã‚¯ã‚¹
    st.markdown("#### ğŸ‘¥ è·ç¨® Ã— å½¹è·åˆ¥ äººæ•°")
    count_df = merged_df.groupby(["è·ç¨®", "å½¹è·"]).size().unstack(fill_value=0)
    st.dataframe(count_df, use_container_width=True)


def render_skill_portfolio_analysis(
    member_competence_df: pd.DataFrame,
    competence_master_df: pd.DataFrame,
    members_df: pd.DataFrame
) -> None:
    """
    â‘¢ã‚¹ã‚­ãƒ«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

    çµ„ç¹”ã®ã‚¹ã‚­ãƒ«å¤šæ§˜æ€§ã€é›†ä¸­åº¦ã€ãƒãƒ©ãƒ³ã‚¹ã‚’åˆ†æ
    """
    st.markdown("### ğŸ’¼ ã‚¹ã‚­ãƒ«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æ")
    st.markdown("""
    **ç›®çš„**: çµ„ç¹”ã®ã‚¹ã‚­ãƒ«ä¿æœ‰ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã€ãƒªã‚¹ã‚¯ã‚’ç‰¹å®šã—ã¾ã™
    - ğŸ”´ **é«˜ãƒªã‚¹ã‚¯**: ç‰¹å®šã‚¹ã‚­ãƒ«ã«ä¾å­˜ï¼ˆä¿æœ‰è€…ãŒå°‘ãªã„ï¼‰
    - ğŸŸ¡ **ä¸­ãƒªã‚¹ã‚¯**: ã‚¹ã‚­ãƒ«ååœ¨ã‚ã‚Š
    - ğŸŸ¢ **ä½ãƒªã‚¹ã‚¯**: ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª
    """)

    # ã‚¹ã‚­ãƒ«ä¿æœ‰è€…æ•°ã®åˆ†å¸ƒåˆ†æ
    skill_holders = member_competence_df.groupby("åŠ›é‡ã‚³ãƒ¼ãƒ‰").size().reset_index(name="ä¿æœ‰è€…æ•°")

    # åŠ›é‡ãƒã‚¹ã‚¿ã‹ã‚‰å¿…è¦ãªã‚«ãƒ©ãƒ ã‚’å–å¾—ï¼ˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼‰
    master_cols = ["åŠ›é‡ã‚³ãƒ¼ãƒ‰", "åŠ›é‡å"]
    if "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å" in competence_master_df.columns:
        master_cols.append("åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å")

    skill_holders = skill_holders.merge(
        competence_master_df[master_cols],
        on="åŠ›é‡ã‚³ãƒ¼ãƒ‰",
        how="left"
    )

    # ãƒªã‚¹ã‚¯åˆ†é¡
    total_members = len(members_df)
    skill_holders["ä¿æœ‰ç‡"] = skill_holders["ä¿æœ‰è€…æ•°"] / total_members

    def classify_risk(holder_count):
        if holder_count == 1:
            return "ğŸ”´ é«˜ãƒªã‚¹ã‚¯ï¼ˆ1åã®ã¿ï¼‰"
        elif holder_count <= 3:
            return "ğŸŸ  ä¸­é«˜ãƒªã‚¹ã‚¯ï¼ˆ2-3åï¼‰"
        elif holder_count <= 5:
            return "ğŸŸ¡ ä¸­ãƒªã‚¹ã‚¯ï¼ˆ4-5åï¼‰"
        else:
            return "ğŸŸ¢ ä½ãƒªã‚¹ã‚¯ï¼ˆ6åä»¥ä¸Šï¼‰"

    skill_holders["ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"] = skill_holders["ä¿æœ‰è€…æ•°"].apply(classify_risk)

    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®é †åºã‚’å®šç¾©ï¼ˆé«˜ãƒªã‚¹ã‚¯â†’ä½ãƒªã‚¹ã‚¯ã®é †ï¼‰
    risk_order = [
        "ğŸ”´ é«˜ãƒªã‚¹ã‚¯ï¼ˆ1åã®ã¿ï¼‰",
        "ğŸŸ  ä¸­é«˜ãƒªã‚¹ã‚¯ï¼ˆ2-3åï¼‰",
        "ğŸŸ¡ ä¸­ãƒªã‚¹ã‚¯ï¼ˆ4-5åï¼‰",
        "ğŸŸ¢ ä½ãƒªã‚¹ã‚¯ï¼ˆ6åä»¥ä¸Šï¼‰"
    ]

    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã«å¤‰æ›ï¼ˆé †åºä»˜ãï¼‰
    skill_holders["ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"] = pd.Categorical(
        skill_holders["ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"],
        categories=risk_order,
        ordered=True
    )

    # ãƒªã‚¹ã‚¯åˆ†å¸ƒ
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ğŸ¯ ã‚¹ã‚­ãƒ«ãƒªã‚¹ã‚¯åˆ†å¸ƒ")
        risk_dist = skill_holders["ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"].value_counts().reset_index()
        risk_dist.columns = ["ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«", "ã‚¹ã‚­ãƒ«æ•°"]

        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®é †åºã«å¾“ã£ã¦ã‚½ãƒ¼ãƒˆ
        risk_dist["ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"] = pd.Categorical(
            risk_dist["ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"],
            categories=risk_order,
            ordered=True
        )
        risk_dist = risk_dist.sort_values("ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«")

        # è‰²ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆé †åºã«å¯¾å¿œï¼‰
        color_map = {
            "ğŸ”´ é«˜ãƒªã‚¹ã‚¯ï¼ˆ1åã®ã¿ï¼‰": "#d62728",      # èµ¤
            "ğŸŸ  ä¸­é«˜ãƒªã‚¹ã‚¯ï¼ˆ2-3åï¼‰": "#ff7f0e",      # ã‚ªãƒ¬ãƒ³ã‚¸
            "ğŸŸ¡ ä¸­ãƒªã‚¹ã‚¯ï¼ˆ4-5åï¼‰": "#ffbb78",        # é»„
            "ğŸŸ¢ ä½ãƒªã‚¹ã‚¯ï¼ˆ6åä»¥ä¸Šï¼‰": "#2ca02c"       # ç·‘
        }

        fig = px.pie(
            risk_dist,
            values="ã‚¹ã‚­ãƒ«æ•°",
            names="ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«",
            title="ã‚¹ã‚­ãƒ«ä¿æœ‰ãƒªã‚¹ã‚¯åˆ†å¸ƒ",
            color="ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«",
            color_discrete_map=color_map
        )
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.markdown("#### ğŸ“Š ä¿æœ‰è€…æ•°åˆ†å¸ƒ")
        fig = px.histogram(
            skill_holders,
            x="ä¿æœ‰è€…æ•°",
            nbins=20,
            title="ã‚¹ã‚­ãƒ«ä¿æœ‰è€…æ•°ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ",
            labels={"ä¿æœ‰è€…æ•°": "ä¿æœ‰è€…æ•°", "count": "ã‚¹ã‚­ãƒ«æ•°"}
        )
        st.plotly_chart(fig, use_container_width=True)

    # é«˜ãƒªã‚¹ã‚¯ã‚¹ã‚­ãƒ«ä¸€è¦§
    st.markdown("#### âš ï¸ é«˜ãƒªã‚¹ã‚¯ã‚¹ã‚­ãƒ«ï¼ˆä¿æœ‰è€…3åä»¥ä¸‹ï¼‰")
    high_risk_skills = skill_holders[skill_holders["ä¿æœ‰è€…æ•°"] <= 3].sort_values("ä¿æœ‰è€…æ•°")

    if len(high_risk_skills) > 0:
        # è¡¨ç¤ºã™ã‚‹ã‚«ãƒ©ãƒ ã‚’å‹•çš„ã«æ±ºå®š
        display_cols = ["åŠ›é‡å"]
        if "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å" in high_risk_skills.columns:
            display_cols.append("åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å")
        display_cols.extend(["ä¿æœ‰è€…æ•°", "ä¿æœ‰ç‡", "ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"])

        st.dataframe(
            high_risk_skills[display_cols],
            use_container_width=True,
            height=300
        )

        st.warning(f"âš ï¸ {len(high_risk_skills)}ä»¶ã®ã‚¹ã‚­ãƒ«ãŒé«˜ãƒªã‚¹ã‚¯çŠ¶æ…‹ã§ã™ã€‚å„ªå…ˆçš„ã«è‚²æˆè¨ˆç”»ã‚’ç«‹æ¡ˆã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
    else:
        st.success("âœ… é«˜ãƒªã‚¹ã‚¯ã‚¹ã‚­ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")

    # ã‚¹ã‚­ãƒ«ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†ä¸­åº¦åˆ†æ
    if "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å" in skill_holders.columns:
        st.markdown("#### ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¹ã‚­ãƒ«é›†ä¸­åº¦")

        category_summary = skill_holders.groupby("åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å").agg({
            "ä¿æœ‰è€…æ•°": ["mean", "min", "max", "std"]
        }).reset_index()
        category_summary.columns = ["ã‚«ãƒ†ã‚´ãƒª", "å¹³å‡ä¿æœ‰è€…æ•°", "æœ€å°ä¿æœ‰è€…æ•°", "æœ€å¤§ä¿æœ‰è€…æ•°", "æ¨™æº–åå·®"]
        category_summary["å¤‰å‹•ä¿‚æ•° (CV)"] = category_summary["æ¨™æº–åå·®"] / category_summary["å¹³å‡ä¿æœ‰è€…æ•°"]
        category_summary = category_summary.sort_values("å¤‰å‹•ä¿‚æ•° (CV)", ascending=False)

        st.dataframe(category_summary, use_container_width=True)
        st.caption("ğŸ’¡ å¤‰å‹•ä¿‚æ•°(CV)ãŒé«˜ã„ã‚«ãƒ†ã‚´ãƒªã¯ã€ã‚¹ã‚­ãƒ«é–“ã®ä¿æœ‰è€…æ•°ã®ã°ã‚‰ã¤ããŒå¤§ããã€ãƒªã‚¹ã‚¯ãŒé«˜ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")


def render_talent_risk_dashboard(
    member_competence_df: pd.DataFrame,
    competence_master_df: pd.DataFrame,
    members_df: pd.DataFrame
) -> None:
    """
    â‘£äººæãƒªã‚¹ã‚¯åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

    ã‚­ãƒ¼ãƒ‘ãƒ¼ã‚½ãƒ³ãƒªã‚¹ã‚¯ã€ã‚¹ã‚­ãƒ«ä¾å­˜åº¦ã‚’åˆ†æ
    """
    st.markdown("### ğŸš¨ äººæãƒªã‚¹ã‚¯åˆ†æ")

    # èª¬æ˜ã‚’æ”¹å–„
    st.info("""
    **ğŸ“Œ ã“ã®åˆ†æã®ç›®çš„**
    ç‰¹å®šãƒ¡ãƒ³ãƒãƒ¼ã¸ã®ã‚¹ã‚­ãƒ«é›†ä¸­ãƒªã‚¹ã‚¯ã‚’ç‰¹å®šã—ã€çµ„ç¹”ã®è„†å¼±æ€§ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚
    - ã‚­ãƒ¼ãƒ‘ãƒ¼ã‚½ãƒ³ã®è­˜åˆ¥ï¼ˆã‚¹ã‚­ãƒ«ä¿æœ‰æ•°ãŒå¤šã„ãƒ¡ãƒ³ãƒãƒ¼ï¼‰
    - ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¹ã‚­ãƒ«ä¿æœ‰è€…ã®ç‰¹å®šï¼ˆãã®ãƒ¡ãƒ³ãƒãƒ¼ã—ã‹æŒã£ã¦ã„ãªã„ã‚¹ã‚­ãƒ«ï¼‰
    - ã‚¹ã‚­ãƒ«åˆ†å¸ƒã®åã‚Šåˆ†æ
    """)

    # ãƒ¡ãƒ³ãƒãƒ¼åˆ¥ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°
    member_skill_counts = member_competence_df.groupby("ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰").size().reset_index(name="ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°")

    # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã®çµåˆï¼ˆã‚«ãƒ©ãƒ å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼‰
    member_cols = ["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"]
    optional_cols = {"ãƒ¡ãƒ³ãƒãƒ¼å": "ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰", "è·ç¨®": None, "å½¹è·": None}  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤

    for col, fallback in optional_cols.items():
        if col in members_df.columns:
            member_cols.append(col)
        elif fallback:
            # ãƒ¡ãƒ³ãƒãƒ¼åãŒãªã„å ´åˆã¯ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã§ä»£ç”¨
            if col == "ãƒ¡ãƒ³ãƒãƒ¼å":
                members_df = members_df.copy()
                members_df["ãƒ¡ãƒ³ãƒãƒ¼å"] = members_df["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"]
                member_cols.append("ãƒ¡ãƒ³ãƒãƒ¼å")

    member_skill_counts = member_skill_counts.merge(
        members_df[member_cols],
        on="ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰",
        how="left"
    )

    # ãƒ¡ãƒ³ãƒãƒ¼åã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã®å¯¾å¿œ
    if "ãƒ¡ãƒ³ãƒãƒ¼å" not in member_skill_counts.columns:
        member_skill_counts["ãƒ¡ãƒ³ãƒãƒ¼å"] = member_skill_counts["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"]

    # ãƒ‘ãƒ¬ãƒ¼ãƒˆåˆ†æã‚’å…ˆã«è¨ˆç®—
    top_20_pct_count = max(1, int(len(member_skill_counts) * 0.2))
    top_20_pct_skills = member_skill_counts.nlargest(top_20_pct_count, "ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°")["ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°"].sum()
    total_skills = member_skill_counts["ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°"].sum()
    pareto_ratio = (top_20_pct_skills / total_skills) * 100 if total_skills > 0 else 0

    # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¸Šéƒ¨ã«è¡¨ç¤º
    st.markdown("---")
    st.markdown("#### ğŸ“Š çµ„ç¹”å…¨ä½“ã®ã‚¹ã‚­ãƒ«ä¿æœ‰çŠ¶æ³")

    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)

    with metric_col1:
        st.metric(
            label="å¹³å‡ã‚¹ã‚­ãƒ«æ•°/äºº",
            value=f"{member_skill_counts['ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°'].mean():.1f}",
            help="1äººã‚ãŸã‚Šã®å¹³å‡ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°"
        )

    with metric_col2:
        st.metric(
            label="ä¸­å¤®å€¤",
            value=f"{member_skill_counts['ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°'].median():.0f}",
            help="ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°ã®ä¸­å¤®å€¤"
        )

    with metric_col3:
        st.metric(
            label="æœ€å¤§ã‚¹ã‚­ãƒ«æ•°",
            value=f"{member_skill_counts['ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°'].max()}",
            help="æœ€ã‚‚ã‚¹ã‚­ãƒ«ã‚’å¤šãä¿æœ‰ã—ã¦ã„ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã®ã‚¹ã‚­ãƒ«æ•°"
        )

    with metric_col4:
        alert_icon = "ğŸ”´" if pareto_ratio > 50 else "ğŸŸ¡" if pareto_ratio > 40 else "ğŸŸ¢"
        st.metric(
            label="ãƒ‘ãƒ¬ãƒ¼ãƒˆæ¯”ç‡",
            value=f"{alert_icon} {pareto_ratio:.1f}%",
            help="ä¸Šä½20%ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒä¿æœ‰ã™ã‚‹ã‚¹ã‚­ãƒ«ã®å‰²åˆï¼ˆé«˜ã„ã»ã©é›†ä¸­ãƒªã‚¹ã‚¯ã‚ã‚Šï¼‰"
        )

    # ä¸Šä½ã‚¹ã‚­ãƒ«ä¿æœ‰è€…
    st.markdown("---")
    st.markdown("#### ğŸŒŸ ãƒˆãƒƒãƒ—ã‚¹ã‚­ãƒ«ä¿æœ‰è€…ï¼ˆã‚­ãƒ¼ãƒ‘ãƒ¼ã‚½ãƒ³ï¼‰")

    top_members = member_skill_counts.nlargest(10, "ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°")

    # ã‚°ãƒ©ãƒ•ã‚’æ”¹å–„
    fig = px.bar(
        top_members,
        y="ãƒ¡ãƒ³ãƒãƒ¼å",  # æ¨ªæ£’ã‚°ãƒ©ãƒ•ã«å¤‰æ›´
        x="ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°",
        color="ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°",
        color_continuous_scale="Blues",
        text="ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°",
        orientation='h'  # æ¨ªå‘ã
    )

    fig.update_traces(
        texttemplate='%{text}ä»¶',
        textposition='outside',
        textfont_size=12
    )

    fig.update_layout(
        height=450,
        showlegend=False,
        xaxis_title="ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°",
        yaxis_title="",
        yaxis={'categoryorder':'total ascending'},  # å€¤ã®æ˜‡é †ã§ã‚½ãƒ¼ãƒˆ
        font=dict(size=11),
        margin=dict(l=20, r=20, t=20, b=20)
    )

    st.plotly_chart(fig, use_container_width=True)

    if pareto_ratio > 50:
        st.warning(f"âš ï¸ ä¸Šä½20%ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒå…¨ä½“ã®{pareto_ratio:.1f}%ã®ã‚¹ã‚­ãƒ«ã‚’ä¿æœ‰ã—ã¦ã„ã¾ã™ã€‚ç‰¹å®šãƒ¡ãƒ³ãƒãƒ¼ã¸ã®ä¾å­˜åº¦ãŒé«˜ã„çŠ¶æ…‹ã§ã™ã€‚")
    elif pareto_ratio > 40:
        st.info(f"ğŸ’¡ ä¸Šä½20%ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒå…¨ä½“ã®{pareto_ratio:.1f}%ã®ã‚¹ã‚­ãƒ«ã‚’ä¿æœ‰ã—ã¦ã„ã¾ã™ã€‚ã‚„ã‚„é›†ä¸­å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    else:
        st.success(f"âœ… ã‚¹ã‚­ãƒ«ãŒæ¯”è¼ƒçš„åˆ†æ•£ã•ã‚Œã¦ã„ã¾ã™ï¼ˆä¸Šä½20%ã§{pareto_ratio:.1f}%ï¼‰ã€‚")

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¹ã‚­ãƒ«åˆ†æï¼ˆãã®ãƒ¡ãƒ³ãƒãƒ¼ã—ã‹æŒã£ã¦ã„ãªã„ã‚¹ã‚­ãƒ«ï¼‰
    st.markdown("#### ğŸ¯ ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¹ã‚­ãƒ«ä¿æœ‰è€…ï¼ˆé›¢è·ãƒªã‚¹ã‚¯é«˜ï¼‰")

    skill_holder_counts = member_competence_df.groupby("åŠ›é‡ã‚³ãƒ¼ãƒ‰")["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"].nunique().reset_index(name="ä¿æœ‰è€…æ•°")
    unique_skills = skill_holder_counts[skill_holder_counts["ä¿æœ‰è€…æ•°"] == 1]["åŠ›é‡ã‚³ãƒ¼ãƒ‰"].tolist()

    if unique_skills:
        unique_skill_holders = member_competence_df[
            member_competence_df["åŠ›é‡ã‚³ãƒ¼ãƒ‰"].isin(unique_skills)
        ].merge(
            members_df[member_cols],  # æ—¢ã«æ§‹ç¯‰ã—ãŸmember_colsã‚’ä½¿ç”¨
            on="ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰",
            how="left"
        ).merge(
            competence_master_df[["åŠ›é‡ã‚³ãƒ¼ãƒ‰", "åŠ›é‡å"]],
            on="åŠ›é‡ã‚³ãƒ¼ãƒ‰",
            how="left"
        )

        # ãƒ¡ãƒ³ãƒãƒ¼åã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã®å¯¾å¿œ
        if "ãƒ¡ãƒ³ãƒãƒ¼å" not in unique_skill_holders.columns:
            unique_skill_holders["ãƒ¡ãƒ³ãƒãƒ¼å"] = unique_skill_holders["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"]

        # groupbyã®ã‚«ãƒ©ãƒ ã‚’å‹•çš„ã«æ§‹ç¯‰
        groupby_cols = ["ãƒ¡ãƒ³ãƒãƒ¼å"]
        if "è·ç¨®" in unique_skill_holders.columns:
            groupby_cols.append("è·ç¨®")
        if "å½¹è·" in unique_skill_holders.columns:
            groupby_cols.append("å½¹è·")

        unique_summary = unique_skill_holders.groupby(groupby_cols).agg({
            "åŠ›é‡ã‚³ãƒ¼ãƒ‰": "count"
        }).reset_index()

        # ã‚«ãƒ©ãƒ åã‚’è¨­å®š
        new_cols = groupby_cols + ["ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¹ã‚­ãƒ«æ•°"]
        unique_summary.columns = new_cols
        unique_summary = unique_summary.sort_values("ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¹ã‚­ãƒ«æ•°", ascending=False)

        st.dataframe(unique_summary, use_container_width=True, height=300)

        st.error(f"âš ï¸ {len(unique_summary)}åã®ãƒ¡ãƒ³ãƒãƒ¼ãŒçµ„ç¹”ã§å”¯ä¸€ã®ã‚¹ã‚­ãƒ«ã‚’ä¿æœ‰ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¡ãƒ³ãƒãƒ¼ã®é›¢è·ã¯çµ„ç¹”ã«é‡å¤§ãªå½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚")

        # è©³ç´°è¡¨ç¤º
        with st.expander("ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¹ã‚­ãƒ«è©³ç´°ã‚’è¡¨ç¤º"):
            # è¡¨ç¤ºã‚«ãƒ©ãƒ ã‚’å‹•çš„ã«æ§‹ç¯‰
            detail_cols = ["ãƒ¡ãƒ³ãƒãƒ¼å"]
            if "è·ç¨®" in unique_skill_holders.columns:
                detail_cols.append("è·ç¨®")
            if "åŠ›é‡å" in unique_skill_holders.columns:
                detail_cols.append("åŠ›é‡å")

            st.dataframe(
                unique_skill_holders[detail_cols],
                use_container_width=True
            )
    else:
        st.success("âœ… å…¨ã¦ã®ã‚¹ã‚­ãƒ«ãŒè¤‡æ•°åã§å…±æœ‰ã•ã‚Œã¦ã„ã¾ã™")

    # ã‚¹ã‚­ãƒ«åˆ†å¸ƒã®åã‚Šåˆ†æ
    st.markdown("#### ğŸ“Š ã‚¹ã‚­ãƒ«åˆ†å¸ƒã®ä¸å‡è¡¡åº¦")

    # ã‚¸ãƒ‹ä¿‚æ•°ã®è¨ˆç®—ï¼ˆã‚¹ã‚­ãƒ«ä¿æœ‰ã®ä¸å¹³ç­‰åº¦ï¼‰
    skill_counts_sorted = member_skill_counts["ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°"].sort_values().values
    n = len(skill_counts_sorted)
    index = np.arange(1, n + 1)
    gini = (2 * np.sum(index * skill_counts_sorted)) / (n * np.sum(skill_counts_sorted)) - (n + 1) / n

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ã‚¸ãƒ‹ä¿‚æ•°", f"{gini:.3f}", help="0ã«è¿‘ã„ã»ã©å‡ç­‰ã€1ã«è¿‘ã„ã»ã©ä¸å‡ç­‰")
    with col2:
        skewness = stats.skew(member_skill_counts["ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°"])
        st.metric("æ­ªåº¦", f"{skewness:.2f}", help="æ­£ã®å€¤ã¯ä¸€éƒ¨ã®ãƒ¡ãƒ³ãƒãƒ¼ã«ã‚¹ã‚­ãƒ«ãŒé›†ä¸­")
    with col3:
        cv = member_skill_counts["ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°"].std() / member_skill_counts["ä¿æœ‰ã‚¹ã‚­ãƒ«æ•°"].mean()
        st.metric("å¤‰å‹•ä¿‚æ•°", f"{cv:.2f}", help="ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°ã®ã°ã‚‰ã¤ãåº¦")

    if gini > 0.4:
        st.warning("âš ï¸ ã‚¹ã‚­ãƒ«ãŒä¸€éƒ¨ã®ãƒ¡ãƒ³ãƒãƒ¼ã«é›†ä¸­ã—ã¦ã„ã¾ã™ã€‚çµ„ç¹”å…¨ä½“ã§ã®ã‚¹ã‚­ãƒ«å…±æœ‰ãƒ»è‚²æˆã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
    elif gini < 0.2:
        st.success("âœ… ã‚¹ã‚­ãƒ«ãŒå‡ç­‰ã«åˆ†æ•£ã—ã¦ã„ã¾ã™ã€‚")
    else:
        st.info("â„¹ï¸ ã‚¹ã‚­ãƒ«åˆ†å¸ƒã¯æ¨™æº–çš„ã§ã™ã€‚")


def render_benchmark_dashboard(
    member_competence_df: pd.DataFrame,
    competence_master_df: pd.DataFrame,
    members_df: pd.DataFrame
) -> None:
    """
    â‘¤çµ„ç¹”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ï¼†ç«¶åˆæ¯”è¼ƒãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

    æ¥­ç•Œæ¨™æº–ã‚„ç†æƒ³çŠ¶æ…‹ã¨æ¯”è¼ƒ
    """
    st.markdown("### ğŸ“Š çµ„ç¹”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°")
    st.markdown("""
    **åˆ†æç›®çš„**: çµ„ç¹”ã®ã‚¹ã‚­ãƒ«æˆç†Ÿåº¦ã‚’è©•ä¾¡ã—ã€æ”¹å–„é ˜åŸŸã‚’ç‰¹å®š
    """)

    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹æ³¨æ„æ›¸ã
    st.info("""
    â„¹ï¸ **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦**

    ã€Œæ¥­ç•Œå¹³å‡ã€ã¨ã€Œãƒˆãƒƒãƒ—ä¼æ¥­ã€ã®æ•°å€¤ã¯**å‚è€ƒå€¤**ã¨ã—ã¦è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
    å®Ÿéš›ã®æ¥­ç•Œãƒ‡ãƒ¼ã‚¿ã‚„è‡ªç¤¾ã®ç›®æ¨™å€¤ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ­£ç¢ºãªåˆ†æãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

    **ç¾åœ¨ã®å‚è€ƒå€¤ï¼š**
    - æ¥­ç•Œå¹³å‡: å¹³å‡ã‚¹ã‚­ãƒ«æ•° 8.5ä»¶/äººã€ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ 65%
    - ãƒˆãƒƒãƒ—ä¼æ¥­: å¹³å‡ã‚¹ã‚­ãƒ«æ•° 12.0ä»¶/äººã€ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ 85%
    """)

    # åŸºæœ¬çµ±è¨ˆ
    total_members = len(members_df)
    total_skills_available = len(competence_master_df)
    total_skill_acquisitions = len(member_competence_df)
    avg_skills_per_member = total_skill_acquisitions / total_members if total_members > 0 else 0
    coverage_rate = (member_competence_df["åŠ›é‡ã‚³ãƒ¼ãƒ‰"].nunique() / total_skills_available) * 100

    # å„æŒ‡æ¨™ã‚’å®‰å…¨ã«è¨ˆç®—
    try:
        diversity_index = calculate_diversity_index(member_competence_df)
    except Exception as e:
        diversity_index = 0.0
        st.warning(f"ã‚¹ã‚­ãƒ«å¤šæ§˜æ€§æŒ‡æ•°ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    try:
        t_shaped_ratio = calculate_t_shaped_ratio(member_competence_df, competence_master_df)
    except Exception as e:
        t_shaped_ratio = 0.0
        st.warning(f"Tå­—å‹äººææ¯”ç‡ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ï¼ˆå‚è€ƒå€¤ - ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼‰
    # NOTE: å®Ÿéš›ã®é‹ç”¨ã§ã¯ã€ä»¥ä¸‹ã®æ–¹æ³•ã§ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼š
    # 1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆYAML/JSONï¼‰ã‹ã‚‰èª­ã¿è¾¼ã¿
    # 2. å¤–éƒ¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯APIã‹ã‚‰å–å¾—
    # 3. UIä¸Šã§ç·¨é›†å¯èƒ½ãªã‚µã‚¤ãƒ‰ãƒãƒ¼å…¥åŠ›æ¬„ã‚’è¿½åŠ 
    benchmark_data = {
        "ç¾åœ¨ã®çµ„ç¹”": {
            "å¹³å‡ã‚¹ã‚­ãƒ«æ•°/äºº": avg_skills_per_member,
            "ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡": coverage_rate,
            "ã‚¹ã‚­ãƒ«å¤šæ§˜æ€§æŒ‡æ•°": diversity_index,
            "Tå­—å‹äººææ¯”ç‡": t_shaped_ratio
        },
        "æ¥­ç•Œå¹³å‡": {
            "å¹³å‡ã‚¹ã‚­ãƒ«æ•°/äºº": 8.5,
            "ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡": 65.0,
            "ã‚¹ã‚­ãƒ«å¤šæ§˜æ€§æŒ‡æ•°": 0.75,
            "Tå­—å‹äººææ¯”ç‡": 35.0
        },
        "ãƒˆãƒƒãƒ—ä¼æ¥­": {
            "å¹³å‡ã‚¹ã‚­ãƒ«æ•°/äºº": 12.0,
            "ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡": 85.0,
            "ã‚¹ã‚­ãƒ«å¤šæ§˜æ€§æŒ‡æ•°": 0.85,
            "Tå­—å‹äººææ¯”ç‡": 50.0
        }
    }

    df_benchmark = pd.DataFrame(benchmark_data).T

    # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
    st.markdown("#### ğŸ¯ ç·åˆã‚¹ã‚³ã‚¢æ¯”è¼ƒ")

    categories = list(df_benchmark.columns)

    fig = go.Figure()

    for org_name in df_benchmark.index:
        fig.add_trace(go.Scatterpolar(
            r=df_benchmark.loc[org_name].values,
            theta=categories,
            fill='toself',
            name=org_name
        ))

    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
        showlegend=True,
        height=500,
        title="çµ„ç¹”ã‚¹ã‚­ãƒ«æˆç†Ÿåº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"
    )

    st.plotly_chart(fig, use_container_width=True)

    # è©³ç´°æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«
    st.markdown("#### ğŸ“‹ è©³ç´°æ¯”è¼ƒ")

    comparison_df = df_benchmark.copy()
    comparison_df["vs æ¥­ç•Œå¹³å‡"] = ((comparison_df.loc["ç¾åœ¨ã®çµ„ç¹”"] / comparison_df.loc["æ¥­ç•Œå¹³å‡"] - 1) * 100).round(1)
    comparison_df["vs ãƒˆãƒƒãƒ—ä¼æ¥­"] = ((comparison_df.loc["ç¾åœ¨ã®çµ„ç¹”"] / comparison_df.loc["ãƒˆãƒƒãƒ—ä¼æ¥­"] - 1) * 100).round(1)

    st.dataframe(comparison_df.T, use_container_width=True)

    # æ”¹å–„æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("#### ğŸ’¡ æ”¹å–„æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")

    actions = []

    if avg_skills_per_member < 8.5:
        actions.append("ğŸ“š **ã‚¹ã‚­ãƒ«è‚²æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å¼·åŒ–**: å¹³å‡ã‚¹ã‚­ãƒ«æ•°ãŒæ¥­ç•Œå¹³å‡ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™")

    if coverage_rate < 65:
        actions.append("ğŸ¯ **ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸ã®æ‹¡å¤§**: çµ„ç¹”ã¨ã—ã¦ä¿æœ‰ã™ã¹ãã‚¹ã‚­ãƒ«ã®ç¯„å›²ã‚’åºƒã’ã¾ã—ã‚‡ã†")

    diversity = calculate_diversity_index(member_competence_df)
    if diversity < 0.75:
        actions.append("ğŸŒˆ **ã‚¹ã‚­ãƒ«å¤šæ§˜æ€§ã®å‘ä¸Š**: ç‰¹å®šã‚¹ã‚­ãƒ«ã¸ã®åã‚Šã‚’æ˜¯æ­£ã—ã¾ã—ã‚‡ã†")

    t_shaped = calculate_t_shaped_ratio(member_competence_df, competence_master_df)
    if t_shaped < 35:
        actions.append("ğŸ”° **Tå­—å‹äººæã®è‚²æˆ**: å°‚é–€æ€§ã¨å¹…åºƒã„çŸ¥è­˜ã‚’æŒã¤äººæã‚’å¢—ã‚„ã—ã¾ã—ã‚‡ã†")

    if actions:
        for action in actions:
            st.markdown(f"- {action}")
    else:
        st.success("âœ… å…¨ã¦ã®æŒ‡æ¨™ã§æ¥­ç•Œå¹³å‡ä»¥ä¸Šã‚’é”æˆã—ã¦ã„ã¾ã™ï¼")


def calculate_diversity_index(member_competence_df: pd.DataFrame) -> float:
    """
    ã‚¹ã‚­ãƒ«å¤šæ§˜æ€§æŒ‡æ•°ã‚’è¨ˆç®—ï¼ˆShannon Entropyï¼‰
    """
    skill_counts = member_competence_df["åŠ›é‡ã‚³ãƒ¼ãƒ‰"].value_counts()
    proportions = skill_counts / skill_counts.sum()
    entropy = -np.sum(proportions * np.log(proportions + 1e-10))
    max_entropy = np.log(len(skill_counts))
    return (entropy / max_entropy) * 100 if max_entropy > 0 else 0


def calculate_t_shaped_ratio(member_competence_df: pd.DataFrame, competence_master_df: pd.DataFrame) -> float:
    """
    Tå­—å‹äººææ¯”ç‡ã‚’è¨ˆç®—

    Tå­—å‹ = 1ã¤ä»¥ä¸Šã®æ·±ã„å°‚é–€æ€§ï¼ˆãƒ¬ãƒ™ãƒ«4ä»¥ä¸Šï¼‰ + å¹…åºƒã„çŸ¥è­˜ï¼ˆ3ã‚«ãƒ†ã‚´ãƒªä»¥ä¸Šï¼‰
    """
    # ä¿æœ‰é‡ã‚«ãƒ©ãƒ ã®æ¤œå‡º
    level_col = None
    for col in ["ä¿æœ‰é‡", "åŠ›é‡ãƒ¬ãƒ™ãƒ«", "ãƒ¬ãƒ™ãƒ«"]:
        if col in member_competence_df.columns:
            level_col = col
            break

    if level_col is None:
        return 0.0

    # åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼åã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è¨ˆç®—ä¸å¯
    if "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å" not in competence_master_df.columns:
        return 0.0

    # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’çµåˆ
    merged = member_competence_df.merge(
        competence_master_df[["åŠ›é‡ã‚³ãƒ¼ãƒ‰", "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å"]],
        on="åŠ›é‡ã‚³ãƒ¼ãƒ‰",
        how="left"
    )

    # ãƒãƒ¼ã‚¸å¾Œã«åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼åãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è¨ˆç®—ä¸å¯
    if "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å" not in merged.columns:
        return 0.0

    # ä¿æœ‰é‡ã‚’æ•°å€¤å‹ã«å¤‰æ›
    merged[level_col] = pd.to_numeric(merged[level_col], errors='coerce')

    t_shaped_count = 0
    total_members = merged["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"].nunique()

    for member_code in merged["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"].unique():
        member_data = merged[merged["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"] == member_code]

        # æ·±ã„å°‚é–€æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¬ãƒ™ãƒ«4ä»¥ä¸Šã®ã‚¹ã‚­ãƒ«ãŒã‚ã‚‹ã‹ï¼‰
        has_deep_skill = False
        try:
            valid_levels = member_data[level_col].dropna()
            if len(valid_levels) > 0 and (valid_levels >= 4).any():
                has_deep_skill = True
        except:
            pass

        # å¹…åºƒã„çŸ¥è­˜ãƒã‚§ãƒƒã‚¯ï¼ˆ3ã‚«ãƒ†ã‚´ãƒªä»¥ä¸Šï¼‰
        try:
            category_count = member_data["åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å"].dropna().nunique()
            has_broad_knowledge = category_count >= 3
        except:
            has_broad_knowledge = False

        if has_deep_skill and has_broad_knowledge:
            t_shaped_count += 1

    return (t_shaped_count / total_members * 100) if total_members > 0 else 0.0


def render_enhanced_skill_gap_analysis(
    gap_df: pd.DataFrame,
    member_competence_df: pd.DataFrame,
    competence_master_df: pd.DataFrame,
    members_df: pd.DataFrame,
    percentile_used: float = 0.2
) -> None:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆå…¼äººäº‹ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆè¦–ç‚¹ã§ã®é«˜åº¦ãªã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—åˆ†æ

    Args:
        gap_df: ã‚®ãƒ£ãƒƒãƒ—DataFrame
        member_competence_df: ãƒ¡ãƒ³ãƒãƒ¼ç¿’å¾—åŠ›é‡ãƒ‡ãƒ¼ã‚¿
        competence_master_df: åŠ›é‡ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿
        members_df: ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿
        percentile_used: ä½¿ç”¨ã—ãŸãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
    """

    st.markdown("### ğŸ¯ é«˜åº¦ãªã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—åˆ†æ")

    # åˆ†ææ¦‚è¦èª¬æ˜
    st.info("""
    ğŸ“Œ **ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ Ã— HRæˆ¦ç•¥ã®çµ±åˆåˆ†æ**

    ã“ã®åˆ†æã§ã¯ã€å˜ãªã‚‹ã‚®ãƒ£ãƒƒãƒ—ã®ç‰¹å®šã«ã¨ã©ã¾ã‚‰ãšã€ä»¥ä¸‹ã®é«˜åº¦ãªè¦–ç‚¹ã§çµ„ç¹”ã®ã‚¹ã‚­ãƒ«é–‹ç™ºæˆ¦ç•¥ã‚’æ”¯æ´ã—ã¾ã™ï¼š
    - **å¤šæ¬¡å…ƒã‚¹ã‚­ãƒ«å„ªå…ˆåº¦åˆ†æ**: ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã€ç¿’å¾—é›£æ˜“åº¦ã€ç·Šæ€¥æ€§ã‚’ç·åˆè©•ä¾¡
    - **ã‚¹ã‚­ãƒ«é–‹ç™ºROIæ¨å®š**: æŠ•è³‡å¯¾åŠ¹æœã‚’å¯è¦–åŒ–ã—ã€äºˆç®—é…åˆ†ã‚’æœ€é©åŒ–
    - **ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜**: æ©Ÿæ¢°å­¦ç¿’çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ
    - **äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°**: ã‚¹ã‚­ãƒ«ç¿’å¾—ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã¨çµ„ç¹”æˆç†Ÿåº¦ã®å°†æ¥äºˆæ¸¬
    """)

    st.markdown("---")

    # ============================================
    # 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆKPIãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼‰
    # ============================================
    st.markdown("#### ğŸ“Š ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼")

    total_gaps = len(gap_df)
    critical_gaps = len(gap_df[gap_df["ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—ç‡"] >= 0.5])
    medium_gaps = len(gap_df[(gap_df["ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—ç‡"] >= 0.3) & (gap_df["ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—ç‡"] < 0.5)])
    avg_gap_rate = gap_df["ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—ç‡"].mean()
    total_training_need = gap_df["ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—"].sum() * len(members_df)

    metric_col1, metric_col2, metric_col3, metric_col4, metric_col5 = st.columns(5)

    with metric_col1:
        st.metric(
            label="ç·ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—æ•°",
            value=f"{total_gaps}ä»¶",
            help="ç›®æ¨™ã¨ç¾çŠ¶ã®å·®ãŒã‚ã‚‹ã‚¹ã‚­ãƒ«ã®ç·æ•°"
        )

    with metric_col2:
        st.metric(
            label="ğŸ”´ é‡å¤§ã‚®ãƒ£ãƒƒãƒ—",
            value=f"{critical_gaps}ä»¶",
            delta=f"{critical_gaps/total_gaps*100:.1f}%" if total_gaps > 0 else "0%",
            delta_color="inverse",
            help="ã‚®ãƒ£ãƒƒãƒ—ç‡50%ä»¥ä¸Šã®ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªã‚¹ã‚­ãƒ«"
        )

    with metric_col3:
        st.metric(
            label="ğŸŸ¡ ä¸­ç¨‹åº¦ã‚®ãƒ£ãƒƒãƒ—",
            value=f"{medium_gaps}ä»¶",
            help="ã‚®ãƒ£ãƒƒãƒ—ç‡30-50%ã®è¨ˆç”»çš„å¯¾å¿œãŒå¿…è¦ãªã‚¹ã‚­ãƒ«"
        )

    with metric_col4:
        st.metric(
            label="å¹³å‡ã‚®ãƒ£ãƒƒãƒ—ç‡",
            value=f"{avg_gap_rate*100:.1f}%",
            delta=f"{(avg_gap_rate - 0.3)*100:.1f}%" if avg_gap_rate > 0 else "0%",
            delta_color="inverse",
            help="å…¨ã‚¹ã‚­ãƒ«ã®å¹³å‡ã‚®ãƒ£ãƒƒãƒ—ç‡ï¼ˆ30%æœªæº€ãŒå¥å…¨ï¼‰"
        )

    with metric_col5:
        st.metric(
            label="æ¨å®šè‚²æˆäººæ•°",
            value=f"{int(total_training_need):,}äºº",
            help="ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«å¿…è¦ãªå»¶ã¹è‚²æˆäººæ•°"
        )

    st.markdown("---")

    # ============================================
    # 2. å¤šæ¬¡å…ƒã‚¹ã‚­ãƒ«å„ªå…ˆåº¦ãƒãƒˆãƒªã‚¯ã‚¹
    # ============================================
    st.markdown("#### ğŸ¯ å¤šæ¬¡å…ƒã‚¹ã‚­ãƒ«å„ªå…ˆåº¦åˆ†æï¼ˆå„ªå…ˆåº¦ãƒãƒˆãƒªã‚¯ã‚¹ï¼‰")

    st.markdown("""
    **åˆ†ææ‰‹æ³•**: å„ã‚¹ã‚­ãƒ«ã‚’3ã¤ã®è»¸ã§è©•ä¾¡ã—ã€æŠ•è³‡å„ªå…ˆåº¦ã‚’ç§‘å­¦çš„ã«åˆ¤å®š
    - **Xè»¸ï¼ˆãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆï¼‰**: ç›®æ¨™ä¿æœ‰ç‡ãŒé«˜ã„ã»ã©ã€çµ„ç¹”æˆ¦ç•¥ä¸Šé‡è¦
    - **Yè»¸ï¼ˆç·Šæ€¥æ€§ï¼‰**: ã‚®ãƒ£ãƒƒãƒ—ç‡ãŒå¤§ãã„ã»ã©ã€å³åº§ã®å¯¾å¿œãŒå¿…è¦
    - **ãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼ˆç¿’å¾—é›£æ˜“åº¦ï¼‰**: ãƒ¬ãƒ™ãƒ«ã‚®ãƒ£ãƒƒãƒ—ãŒå¤§ãã„ã»ã©ã€è‚²æˆã«æ™‚é–“ã¨ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹
    """)

    # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
    gap_analysis_df = gap_df.copy()

    # ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ: ç›®æ¨™ä¿æœ‰ç‡ï¼ˆ0-100ã«æ­£è¦åŒ–ï¼‰
    gap_analysis_df["ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ"] = gap_analysis_df["ç›®æ¨™ä¿æœ‰ç‡"] * 100

    # ç·Šæ€¥æ€§: ã‚®ãƒ£ãƒƒãƒ—ç‡ï¼ˆ0-100ã«æ­£è¦åŒ–ï¼‰
    gap_analysis_df["ç·Šæ€¥æ€§"] = gap_analysis_df["ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—ç‡"] * 100

    # ç¿’å¾—é›£æ˜“åº¦: ãƒ¬ãƒ™ãƒ«ã‚®ãƒ£ãƒƒãƒ—ï¼ˆçµ¶å¯¾å€¤ã‚’ä½¿ç”¨ã€0-5ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    gap_analysis_df["ç¿’å¾—é›£æ˜“åº¦"] = gap_analysis_df["ãƒ¬ãƒ™ãƒ«ã‚®ãƒ£ãƒƒãƒ—"].abs()

    # ç·åˆå„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿ä»˜ãå¹³å‡: ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ40%, ç·Šæ€¥æ€§40%, ç¿’å¾—é›£æ˜“åº¦ã®é€†æ•°20%ï¼‰
    gap_analysis_df["å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢"] = (
        gap_analysis_df["ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ"] * 0.4 +
        gap_analysis_df["ç·Šæ€¥æ€§"] * 0.4 +
        (100 - gap_analysis_df["ç¿’å¾—é›£æ˜“åº¦"] * 10) * 0.2  # é›£æ˜“åº¦ãŒä½ã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
    )

    # å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
    def categorize_priority(row):
        if row["å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢"] >= 70:
            return "ğŸ”´ æœ€å„ªå…ˆï¼ˆStrategic Focusï¼‰"
        elif row["å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢"] >= 50:
            return "ğŸŸ  é«˜å„ªå…ˆåº¦ï¼ˆHigh Priorityï¼‰"
        elif row["å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢"] >= 30:
            return "ğŸŸ¡ ä¸­å„ªå…ˆåº¦ï¼ˆMedium Priorityï¼‰"
        else:
            return "ğŸŸ¢ ä½å„ªå…ˆåº¦ï¼ˆLow Priorityï¼‰"

    gap_analysis_df["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"] = gap_analysis_df.apply(categorize_priority, axis=1)

    # ãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
    fig = px.scatter(
        gap_analysis_df.head(50),  # ä¸Šä½50ã‚¹ã‚­ãƒ«ã‚’è¡¨ç¤º
        x="ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ",
        y="ç·Šæ€¥æ€§",
        size="ç¿’å¾—é›£æ˜“åº¦",
        color="å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª",
        hover_name="åŠ›é‡å",
        hover_data={
            "ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ": ":.1f",
            "ç·Šæ€¥æ€§": ":.1f",
            "ç¿’å¾—é›£æ˜“åº¦": ":.2f",
            "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢": ":.1f",
            "ç¾åœ¨ä¿æœ‰ç‡": ":.1%",
            "ç›®æ¨™ä¿æœ‰ç‡": ":.1%"
        },
        title="ã‚¹ã‚­ãƒ«æŠ•è³‡å„ªå…ˆåº¦ãƒãƒˆãƒªã‚¯ã‚¹ï¼ˆãƒãƒ–ãƒ«ãƒãƒ£ãƒ¼ãƒˆï¼‰",
        color_discrete_map={
            "ğŸ”´ æœ€å„ªå…ˆï¼ˆStrategic Focusï¼‰": "#d62728",
            "ğŸŸ  é«˜å„ªå…ˆåº¦ï¼ˆHigh Priorityï¼‰": "#ff7f0e",
            "ğŸŸ¡ ä¸­å„ªå…ˆåº¦ï¼ˆMedium Priorityï¼‰": "#ffbb78",
            "ğŸŸ¢ ä½å„ªå…ˆåº¦ï¼ˆLow Priorityï¼‰": "#2ca02c"
        }
    )

    fig.update_layout(
        height=600,
        xaxis_title="ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆï¼ˆç›®æ¨™ä¿æœ‰ç‡ï¼‰",
        yaxis_title="ç·Šæ€¥æ€§ï¼ˆã‚®ãƒ£ãƒƒãƒ—ç‡ï¼‰",
        showlegend=True
    )

    # å³ä¸Šã®è±¡é™ã‚’å¼·èª¿ï¼ˆé«˜ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆÃ—é«˜ç·Šæ€¥æ€§ï¼‰
    fig.add_shape(
        type="rect",
        x0=60, y0=60, x1=100, y1=100,
        line=dict(color="red", width=2, dash="dash"),
        fillcolor="rgba(255,0,0,0.1)"
    )

    fig.add_annotation(
        x=80, y=95,
        text="<b>æˆ¦ç•¥çš„æœ€å„ªå…ˆã‚¨ãƒªã‚¢</b>",
        showarrow=False,
        font=dict(size=12, color="red")
    )

    st.plotly_chart(fig, use_container_width=True)

    # å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚µãƒãƒªãƒ¼
    priority_summary = gap_analysis_df["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"].value_counts().reset_index()
    priority_summary.columns = ["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª", "ã‚¹ã‚­ãƒ«æ•°"]

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("**å„ªå…ˆåº¦åˆ†å¸ƒ**")
        st.dataframe(priority_summary, use_container_width=True, hide_index=True)

    with col2:
        # å††ã‚°ãƒ©ãƒ•
        fig_pie = px.pie(
            priority_summary,
            values="ã‚¹ã‚­ãƒ«æ•°",
            names="å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª",
            title="å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†å¸ƒ",
            color="å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª",
            color_discrete_map={
                "ğŸ”´ æœ€å„ªå…ˆï¼ˆStrategic Focusï¼‰": "#d62728",
                "ğŸŸ  é«˜å„ªå…ˆåº¦ï¼ˆHigh Priorityï¼‰": "#ff7f0e",
                "ğŸŸ¡ ä¸­å„ªå…ˆåº¦ï¼ˆMedium Priorityï¼‰": "#ffbb78",
                "ğŸŸ¢ ä½å„ªå…ˆåº¦ï¼ˆLow Priorityï¼‰": "#2ca02c"
            }
        )
        fig_pie.update_layout(height=300)
        st.plotly_chart(fig_pie, use_container_width=True)

    st.markdown("---")

    # ============================================
    # 3. ã‚¹ã‚­ãƒ«é–‹ç™ºROIæ¨å®š
    # ============================================
    st.markdown("#### ğŸ’° ã‚¹ã‚­ãƒ«é–‹ç™ºROIæ¨å®šï¼ˆæŠ•è³‡å¯¾åŠ¹æœåˆ†æï¼‰")

    st.markdown("""
    **åˆ†æç›®çš„**: é™ã‚‰ã‚ŒãŸäºˆç®—ã¨æ™‚é–“ã‚’ã©ã®ã‚¹ã‚­ãƒ«é–‹ç™ºã«æŠ•è³‡ã™ã¹ãã‹ã‚’å®šé‡çš„ã«åˆ¤æ–­

    **å‰ææ¡ä»¶**ï¼ˆã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼‰:
    - 1ã‚¹ã‚­ãƒ«ç¿’å¾—ã®å¹³å‡ã‚³ã‚¹ãƒˆ: ç ”ä¿®è²» + æ™‚é–“ã‚³ã‚¹ãƒˆ
    - ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚‹ç¿’å¾—æœŸé–“ã®é•ã„
    - ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã«ã‚ˆã‚‹ä¾¡å€¤ã®é‡ã¿ä»˜ã‘
    """)

    # ROIè¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆUIã§èª¿æ•´å¯èƒ½ï¼‰
    col1, col2, col3 = st.columns(3)

    with col1:
        training_cost_per_skill = st.number_input(
            "1ã‚¹ã‚­ãƒ«ç¿’å¾—ã‚³ã‚¹ãƒˆï¼ˆä¸‡å††ï¼‰",
            min_value=1,
            max_value=100,
            value=20,
            step=5,
            help="ç ”ä¿®è²»ã€æ•™æè²»ã€æ™‚é–“ã‚³ã‚¹ãƒˆã‚’å«ã‚€"
        )

    with col2:
        months_per_level = st.number_input(
            "ãƒ¬ãƒ™ãƒ«1ç¿’å¾—ã«å¿…è¦ãªæœˆæ•°",
            min_value=1,
            max_value=12,
            value=3,
            step=1,
            help="å¹³å‡çš„ãªã‚¹ã‚­ãƒ«ç¿’å¾—æœŸé–“"
        )

    with col3:
        business_value_multiplier = st.number_input(
            "ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ä¿‚æ•°",
            min_value=1.0,
            max_value=10.0,
            value=3.0,
            step=0.5,
            help="ã‚¹ã‚­ãƒ«ç¿’å¾—ã«ã‚ˆã‚‹çµ„ç¹”ã¸ã®ä¾¡å€¤è²¢çŒ®åº¦"
        )

    # ROIè¨ˆç®—
    roi_df = gap_analysis_df.copy()

    # å¿…è¦ãªè‚²æˆäººæ•°
    roi_df["è‚²æˆå¿…è¦äººæ•°"] = (roi_df["ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—"] * len(members_df)).round(0).astype(int)

    # ç·æŠ•è³‡ã‚³ã‚¹ãƒˆï¼ˆä¸‡å††ï¼‰
    roi_df["ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ"] = roi_df["è‚²æˆå¿…è¦äººæ•°"] * training_cost_per_skill

    # ç¿’å¾—æœŸé–“ï¼ˆæœˆï¼‰
    roi_df["æ¨å®šç¿’å¾—æœŸé–“"] = (roi_df["ç¿’å¾—é›£æ˜“åº¦"] * months_per_level).round(1)

    # ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ï¼ˆä¸‡å††ï¼‰- ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã«åŸºã¥ã
    roi_df["æ¨å®šãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤"] = (
        roi_df["ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ"] *
        roi_df["è‚²æˆå¿…è¦äººæ•°"] *
        training_cost_per_skill *
        business_value_multiplier
    )

    # ROI = (ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ - æŠ•è³‡ã‚³ã‚¹ãƒˆ) / æŠ•è³‡ã‚³ã‚¹ãƒˆ Ã— 100
    roi_df["ROIç‡"] = (
        (roi_df["æ¨å®šãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤"] - roi_df["ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ"]) /
        roi_df["ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ"] * 100
    ).round(1)

    # ROIä¸Šä½10ã‚¹ã‚­ãƒ«ã‚’è¡¨ç¤º
    roi_top = roi_df.nlargest(10, "ROIç‡")[[
        "åŠ›é‡å", "è‚²æˆå¿…è¦äººæ•°", "ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ", "æ¨å®šãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤",
        "ROIç‡", "æ¨å®šç¿’å¾—æœŸé–“", "å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"
    ]].copy()

    st.markdown("##### ğŸ† ROIä¸Šä½10ã‚¹ã‚­ãƒ«ï¼ˆæœ€ã‚‚æŠ•è³‡åŠ¹æœãŒé«˜ã„ã‚¹ã‚­ãƒ«ï¼‰")

    # ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°
    def highlight_roi(row):
        colors = [''] * len(row)
        roi_idx = row.index.get_loc("ROIç‡")

        if row["ROIç‡"] >= 200:
            colors[roi_idx] = 'background-color: #d4edda; font-weight: bold'
        elif row["ROIç‡"] >= 100:
            colors[roi_idx] = 'background-color: #fff3cd'

        return colors

    styled_roi = roi_top.style.apply(highlight_roi, axis=1).format({
        "ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ": "{:,.0f}ä¸‡å††",
        "æ¨å®šãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤": "{:,.0f}ä¸‡å††",
        "ROIç‡": "{:.1f}%",
        "æ¨å®šç¿’å¾—æœŸé–“": "{:.1f}ãƒ¶æœˆ"
    })

    st.dataframe(styled_roi, use_container_width=True, hide_index=True)

    st.caption("ğŸŸ¢ ç·‘èƒŒæ™¯: é«˜ROIï¼ˆ200%ä»¥ä¸Šï¼‰ | ğŸŸ¡ é»„èƒŒæ™¯: ä¸­ROIï¼ˆ100%ä»¥ä¸Šï¼‰")

    # ROIå¯è¦–åŒ–
    fig_roi = px.bar(
        roi_top,
        x="ROIç‡",
        y="åŠ›é‡å",
        color="å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª",
        orientation='h',
        title="ROIä¸Šä½ã‚¹ã‚­ãƒ«ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
        labels={"ROIç‡": "ROIç‡ (%)", "åŠ›é‡å": ""},
        color_discrete_map={
            "ğŸ”´ æœ€å„ªå…ˆï¼ˆStrategic Focusï¼‰": "#d62728",
            "ğŸŸ  é«˜å„ªå…ˆåº¦ï¼ˆHigh Priorityï¼‰": "#ff7f0e",
            "ğŸŸ¡ ä¸­å„ªå…ˆåº¦ï¼ˆMedium Priorityï¼‰": "#ffbb78",
            "ğŸŸ¢ ä½å„ªå…ˆåº¦ï¼ˆLow Priorityï¼‰": "#2ca02c"
        }
    )

    fig_roi.update_layout(
        height=400,
        yaxis={'categoryorder':'total ascending'}
    )

    st.plotly_chart(fig_roi, use_container_width=True)

    # æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    st.markdown("##### ğŸ’¡ æŠ•è³‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")

    total_investment = roi_df["ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ"].sum()
    total_value = roi_df["æ¨å®šãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤"].sum()
    overall_roi = ((total_value - total_investment) / total_investment * 100) if total_investment > 0 else 0

    sim_col1, sim_col2, sim_col3 = st.columns(3)

    with sim_col1:
        st.metric(
            "å…¨ã‚®ãƒ£ãƒƒãƒ—è§£æ¶ˆã®ç·æŠ•è³‡é¡",
            f"{total_investment:,.0f}ä¸‡å††",
            help="å…¨ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«å¿…è¦ãªç·ã‚³ã‚¹ãƒˆ"
        )

    with sim_col2:
        st.metric(
            "æ¨å®šç·ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤",
            f"{total_value:,.0f}ä¸‡å††",
            help="å…¨ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã‚’è§£æ¶ˆã—ãŸå ´åˆã®çµ„ç¹”ä¾¡å€¤å‘ä¸Š"
        )

    with sim_col3:
        st.metric(
            "å…¨ä½“ROI",
            f"{overall_roi:.1f}%",
            delta=f"{overall_roi - 100:.1f}%" if overall_roi > 0 else "0%",
            help="å…¨ä½“çš„ãªæŠ•è³‡å¯¾åŠ¹æœ"
        )

    st.markdown("---")

    # ============================================
    # 4. ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æï¼‰
    # ============================================
    st.markdown("#### ğŸ”¬ ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜")

    st.markdown("""
    **åˆ†ææ‰‹æ³•**: K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šã€é¡ä¼¼ã—ãŸã‚®ãƒ£ãƒƒãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤ã‚¹ã‚­ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–

    ã“ã‚Œã«ã‚ˆã‚Šã€å€‹åˆ¥ã‚¹ã‚­ãƒ«ã§ã¯ãªãã€Œã‚¹ã‚­ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã€å˜ä½ã§ã®æˆ¦ç•¥çš„è‚²æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’è¨­è¨ˆã§ãã¾ã™ã€‚
    """)

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
    from sklearn.preprocessing import StandardScaler
    from sklearn.cluster import KMeans

    # ç‰¹å¾´é‡: ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã€ç·Šæ€¥æ€§ã€ç¿’å¾—é›£æ˜“åº¦
    cluster_features = gap_analysis_df[[
        "ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ", "ç·Šæ€¥æ€§", "ç¿’å¾—é›£æ˜“åº¦"
    ]].fillna(0)

    # æ¨™æº–åŒ–
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(cluster_features)

    # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆ4ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼‰
    n_clusters = 4
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    gap_analysis_df["ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼"] = kmeans.fit_predict(features_scaled)

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ©ãƒ™ãƒ«ä»˜ã‘
    cluster_labels = {
        0: "ğŸ¯ æˆ¦ç•¥çš„é‡è¦ã‚¹ã‚­ãƒ«ç¾¤",
        1: "âš¡ ç·Šæ€¥å¯¾å¿œã‚¹ã‚­ãƒ«ç¾¤",
        2: "ğŸ“š åŸºç¤è‚²æˆã‚¹ã‚­ãƒ«ç¾¤",
        3: "ğŸ”„ é•·æœŸè‚²æˆã‚¹ã‚­ãƒ«ç¾¤"
    }

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ç‰¹æ€§ã‚’åˆ†æã—ã¦é©åˆ‡ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘
    cluster_characteristics = []
    for cluster_id in range(n_clusters):
        cluster_data = gap_analysis_df[gap_analysis_df["ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼"] == cluster_id]
        avg_impact = cluster_data["ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ"].mean()
        avg_urgency = cluster_data["ç·Šæ€¥æ€§"].mean()
        avg_difficulty = cluster_data["ç¿’å¾—é›£æ˜“åº¦"].mean()

        # ç‰¹æ€§ã«åŸºã¥ã„ã¦ãƒ©ãƒ™ãƒ«ã‚’æ±ºå®š
        if avg_impact > 60 and avg_urgency > 60:
            label = "ğŸ¯ æˆ¦ç•¥çš„é‡è¦ã‚¹ã‚­ãƒ«ç¾¤"
        elif avg_urgency > 60:
            label = "âš¡ ç·Šæ€¥å¯¾å¿œã‚¹ã‚­ãƒ«ç¾¤"
        elif avg_difficulty < 2:
            label = "ğŸ“š åŸºç¤è‚²æˆã‚¹ã‚­ãƒ«ç¾¤"
        else:
            label = "ğŸ”„ é•·æœŸè‚²æˆã‚¹ã‚­ãƒ«ç¾¤"

        cluster_characteristics.append({
            "ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼": label,
            "ã‚¹ã‚­ãƒ«æ•°": len(cluster_data),
            "å¹³å‡ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ": f"{avg_impact:.1f}",
            "å¹³å‡ç·Šæ€¥æ€§": f"{avg_urgency:.1f}",
            "å¹³å‡ç¿’å¾—é›£æ˜“åº¦": f"{avg_difficulty:.2f}",
            "æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ": _get_cluster_recommendation(avg_impact, avg_urgency, avg_difficulty)
        })

        # ãƒ©ãƒ™ãƒ«ã‚’æ›´æ–°
        gap_analysis_df.loc[gap_analysis_df["ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼"] == cluster_id, "ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ©ãƒ™ãƒ«"] = label

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ç‰¹æ€§è¡¨ç¤º
    cluster_df = pd.DataFrame(cluster_characteristics)

    st.markdown("##### ğŸ“‹ ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æçµæœ")
    st.dataframe(cluster_df, use_container_width=True, hide_index=True)

    # 3Dæ•£å¸ƒå›³ï¼ˆã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ï¼‰
    fig_3d = px.scatter_3d(
        gap_analysis_df.head(100),
        x="ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ",
        y="ç·Šæ€¥æ€§",
        z="ç¿’å¾—é›£æ˜“åº¦",
        color="ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ©ãƒ™ãƒ«",
        hover_name="åŠ›é‡å",
        title="ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ— 3D ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¯è¦–åŒ–",
        labels={
            "ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ": "ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ",
            "ç·Šæ€¥æ€§": "ç·Šæ€¥æ€§",
            "ç¿’å¾—é›£æ˜“åº¦": "ç¿’å¾—é›£æ˜“åº¦"
        }
    )

    fig_3d.update_layout(height=600)
    st.plotly_chart(fig_3d, use_container_width=True)

    st.markdown("---")

    # ============================================
    # 5. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆ
    # ============================================
    st.markdown("#### ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³")

    st.markdown("""
    **HRæˆ¦ç•¥ã¸ã®è½ã¨ã—è¾¼ã¿**: åˆ†æçµæœã‚’å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«å¤‰æ›
    """)

    # æœ€å„ªå…ˆã‚¹ã‚­ãƒ«TOP5ã®è©³ç´°ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
    top_priority_skills = roi_df.nlargest(5, "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢")

    for idx, (_, skill) in enumerate(top_priority_skills.iterrows(), 1):
        with st.expander(f"ğŸ¯ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ {idx}: {skill['åŠ›é‡å']}", expanded=(idx == 1)):
            st.markdown(f"**å„ªå…ˆåº¦**: {skill['å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª']} ï¼ˆã‚¹ã‚³ã‚¢: {skill['å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢']:.1f}/100ï¼‰")

            action_col1, action_col2, action_col3 = st.columns(3)

            with action_col1:
                st.metric("ç¾åœ¨ä¿æœ‰ç‡", f"{skill['ç¾åœ¨ä¿æœ‰ç‡']*100:.1f}%")
                st.metric("ç›®æ¨™ä¿æœ‰ç‡", f"{skill['ç›®æ¨™ä¿æœ‰ç‡']*100:.1f}%")

            with action_col2:
                st.metric("ã‚®ãƒ£ãƒƒãƒ—ç‡", f"{skill['ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—ç‡']*100:.1f}%")
                st.metric("è‚²æˆå¿…è¦äººæ•°", f"{int(skill['è‚²æˆå¿…è¦äººæ•°'])}äºº")

            with action_col3:
                st.metric("æ¨å®šæŠ•è³‡é¡", f"{skill['ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ']:.0f}ä¸‡å††")
                st.metric("ROI", f"{skill['ROIç‡']:.1f}%")

            st.markdown("---")

            # å…·ä½“çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
            st.markdown("##### ğŸ“Œ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")

            actions = _generate_action_recommendations(skill, members_df)

            for action in actions:
                st.markdown(f"- {action}")

            st.markdown("---")

            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
            st.markdown("##### â±ï¸ å®Ÿæ–½ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")

            timeline = _generate_timeline(skill)

            for phase, desc in timeline.items():
                st.markdown(f"**{phase}**: {desc}")

    st.markdown("---")

    # ============================================
    # 6. ã‚¹ã‚­ãƒ«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ææ¡ˆ
    # ============================================
    st.markdown("#### ğŸ¨ ã‚¹ã‚­ãƒ«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ææ¡ˆ")

    st.markdown("""
    **çµ„ç¹”å…¨ä½“ã®è¦–ç‚¹**: å€‹åˆ¥ã‚¹ã‚­ãƒ«ã§ã¯ãªãã€çµ„ç¹”ã®ã‚¹ã‚­ãƒ«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã‚’æœ€é©åŒ–
    """)

    # ç¾åœ¨ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªçŠ¶æ…‹
    current_strategic = len(gap_analysis_df[gap_analysis_df["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"] == "ğŸ”´ æœ€å„ªå…ˆï¼ˆStrategic Focusï¼‰"])
    current_high = len(gap_analysis_df[gap_analysis_df["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"] == "ğŸŸ  é«˜å„ªå…ˆåº¦ï¼ˆHigh Priorityï¼‰"])
    current_medium = len(gap_analysis_df[gap_analysis_df["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"] == "ğŸŸ¡ ä¸­å„ªå…ˆåº¦ï¼ˆMedium Priorityï¼‰"])
    current_low = len(gap_analysis_df[gap_analysis_df["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"] == "ğŸŸ¢ ä½å„ªå…ˆåº¦ï¼ˆLow Priorityï¼‰"])

    # ç†æƒ³çš„ãªé…åˆ†ï¼ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰
    ideal_strategic = int(total_gaps * 0.2)
    ideal_high = int(total_gaps * 0.3)
    ideal_medium = int(total_gaps * 0.3)
    ideal_low = int(total_gaps * 0.2)

    portfolio_comparison = pd.DataFrame({
        "å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª": [
            "ğŸ”´ æœ€å„ªå…ˆ",
            "ğŸŸ  é«˜å„ªå…ˆåº¦",
            "ğŸŸ¡ ä¸­å„ªå…ˆåº¦",
            "ğŸŸ¢ ä½å„ªå…ˆåº¦"
        ],
        "ç¾çŠ¶": [current_strategic, current_high, current_medium, current_low],
        "ç†æƒ³": [ideal_strategic, ideal_high, ideal_medium, ideal_low],
        "å·®åˆ†": [
            current_strategic - ideal_strategic,
            current_high - ideal_high,
            current_medium - ideal_medium,
            current_low - ideal_low
        ]
    })

    # æ¯”è¼ƒã‚°ãƒ©ãƒ•
    fig_portfolio = go.Figure()

    fig_portfolio.add_trace(go.Bar(
        name="ç¾çŠ¶",
        x=portfolio_comparison["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"],
        y=portfolio_comparison["ç¾çŠ¶"],
        marker_color='lightblue'
    ))

    fig_portfolio.add_trace(go.Bar(
        name="ç†æƒ³ï¼ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰",
        x=portfolio_comparison["å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª"],
        y=portfolio_comparison["ç†æƒ³"],
        marker_color='lightgreen'
    ))

    fig_portfolio.update_layout(
        title="ã‚¹ã‚­ãƒ«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª: ç¾çŠ¶ vs ç†æƒ³é…åˆ†",
        xaxis_title="",
        yaxis_title="ã‚¹ã‚­ãƒ«æ•°",
        barmode='group',
        height=400
    )

    st.plotly_chart(fig_portfolio, use_container_width=True)

    # æ”¹å–„ææ¡ˆ
    st.markdown("##### ğŸ’¡ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã®ææ¡ˆ")

    if current_strategic > ideal_strategic:
        st.warning(
            f"âš ï¸ **æœ€å„ªå…ˆã‚¹ã‚­ãƒ«ãŒå¤šã™ãã¾ã™** ({current_strategic - ideal_strategic}ä»¶è¶…é)\n\n"
            "ä¸€åº¦ã«å¤šãã®ã‚¹ã‚­ãƒ«ã‚’æœ€å„ªå…ˆã«ã™ã‚‹ã¨ã€ãƒªã‚½ãƒ¼ã‚¹ãŒåˆ†æ•£ã—ã¾ã™ã€‚"
            "æœ€ã‚‚é‡è¦ãª20%ã«çµã‚Šè¾¼ã¿ã€æ®µéšçš„ã«å–ã‚Šçµ„ã‚€ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
        )
    elif current_strategic < ideal_strategic:
        st.info(
            f"â„¹ï¸ **æœ€å„ªå…ˆã‚¹ã‚­ãƒ«ã®æ˜ç¢ºåŒ–ãŒå¿…è¦** ({ideal_strategic - current_strategic}ä»¶ä¸è¶³)\n\n"
            "çµ„ç¹”æˆ¦ç•¥ä¸Šã€æœ€å„ªå…ˆã§å–ã‚Šçµ„ã‚€ã¹ãã‚¹ã‚­ãƒ«ã‚’æ˜ç¢ºã«å®šç¾©ã™ã‚‹ã“ã¨ã§ã€æŠ•è³‡åŠ¹æœãŒå‘ä¸Šã—ã¾ã™ã€‚"
        )
    else:
        st.success("âœ… æœ€å„ªå…ˆã‚¹ã‚­ãƒ«ã®æ•°ã¯é©åˆ‡ã§ã™")

    # ç·åˆæ¨å¥¨äº‹é …
    st.markdown("##### ğŸŒŸ ç·åˆæ¨å¥¨äº‹é …")

    st.markdown(f"""
    **ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæˆ¦ç•¥çš„æè¨€**:

    1. **å³åº§ã«ç€æ‰‹ã™ã¹ãã‚¹ã‚­ãƒ«**:
       - {top_priority_skills.iloc[0]['åŠ›é‡å']}ã‚’ç­†é ­ã«ã€æœ€å„ªå…ˆã‚¹ã‚­ãƒ«{current_strategic}ä»¶ã«é›†ä¸­æŠ•è³‡
       - æ¨å®šæŠ•è³‡é¡: {top_priority_skills.head(5)['ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ'].sum():,.0f}ä¸‡å††
       - æœŸå¾…ROI: {top_priority_skills.head(5)['ROIç‡'].mean():.1f}%

    2. **6ãƒ¶æœˆä»¥å†…ã®ç›®æ¨™**:
       - æœ€å„ªå…ˆã‚¹ã‚­ãƒ«ã®å¹³å‡ä¿æœ‰ç‡ã‚’ç¾çŠ¶ã‹ã‚‰20%æ”¹å–„
       - ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚®ãƒ£ãƒƒãƒ—ï¼ˆã‚®ãƒ£ãƒƒãƒ—ç‡50%ä»¥ä¸Šï¼‰ã‚’{critical_gaps}ä»¶ã‹ã‚‰åŠæ¸›

    3. **1å¹´å¾Œã®ç›®æ¨™**:
       - å¹³å‡ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ç‡ã‚’{avg_gap_rate*100:.1f}%ã‹ã‚‰20%æœªæº€ã«å‰Šæ¸›
       - ä¸Šä½{int(percentile_used*100)}%ãƒ¡ãƒ³ãƒãƒ¼ã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã‚’çµ„ç¹”å…¨ä½“ã®æ¨™æº–ã«

    4. **æŠ•è³‡é…åˆ†ã®æ¨å¥¨**:
       - æœ€å„ªå…ˆã‚¹ã‚­ãƒ«: äºˆç®—ã®50%
       - é«˜å„ªå…ˆåº¦ã‚¹ã‚­ãƒ«: äºˆç®—ã®30%
       - ä¸­å„ªå…ˆåº¦ã‚¹ã‚­ãƒ«: äºˆç®—ã®15%
       - ä½å„ªå…ˆåº¦ã‚¹ã‚­ãƒ«: äºˆç®—ã®5%ï¼ˆæ©Ÿä¼šå­¦ç¿’ï¼‰
    """)

    # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    st.markdown("---")
    st.markdown("### ğŸ’¾ åˆ†æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

    export_df = roi_df[[
        "åŠ›é‡å", "ç¾åœ¨ä¿æœ‰ç‡", "ç›®æ¨™ä¿æœ‰ç‡", "ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—ç‡",
        "ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ", "ç·Šæ€¥æ€§", "ç¿’å¾—é›£æ˜“åº¦", "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢", "å„ªå…ˆåº¦ã‚«ãƒ†ã‚´ãƒª",
        "è‚²æˆå¿…è¦äººæ•°", "ç·æŠ•è³‡ã‚³ã‚¹ãƒˆ", "ROIç‡", "æ¨å®šç¿’å¾—æœŸé–“", "ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ©ãƒ™ãƒ«"
    ]].copy()

    csv = export_df.to_csv(index=False, encoding='utf-8-sig')

    st.download_button(
        label="ğŸ“¥ è©³ç´°åˆ†æçµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv,
        file_name="enhanced_skill_gap_analysis.csv",
        mime="text/csv"
    )


def _get_cluster_recommendation(impact: float, urgency: float, difficulty: float) -> str:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã”ã¨ã®æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”Ÿæˆ"""
    if impact > 60 and urgency > 60:
        return "é›†ä¸­æŠ•è³‡ãƒ»å³æ™‚å®Ÿè¡Œãƒ—ãƒ­ã‚°ãƒ©ãƒ "
    elif urgency > 60:
        return "çŸ­æœŸé›†ä¸­ãƒ–ãƒ¼ãƒˆã‚­ãƒ£ãƒ³ãƒ—å½¢å¼"
    elif difficulty < 2:
        return "eãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»è‡ªå·±å­¦ç¿’æ”¯æ´"
    else:
        return "ä¸­é•·æœŸOJTãƒ»ãƒ¡ãƒ³ã‚¿ãƒ¼åˆ¶åº¦"


def _generate_action_recommendations(skill: pd.Series, members_df: pd.DataFrame) -> List[str]:
    """ã‚¹ã‚­ãƒ«ã”ã¨ã®å…·ä½“çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¨å¥¨ã‚’ç”Ÿæˆ"""
    actions = []

    gap_rate = skill["ä¿æœ‰ç‡ã‚®ãƒ£ãƒƒãƒ—ç‡"]
    training_need = int(skill["è‚²æˆå¿…è¦äººæ•°"])

    # è‚²æˆæ–¹æ³•ã®æ¨å¥¨
    if skill["ç¿’å¾—é›£æ˜“åº¦"] < 2:
        actions.append(f"ğŸ“š **è‚²æˆæ–¹æ³•**: eãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§è‡ªå·±å­¦ç¿’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æä¾›ï¼ˆã‚³ã‚¹ãƒˆåŠ¹ç‡â—ï¼‰")
    elif skill["ç¿’å¾—é›£æ˜“åº¦"] < 3.5:
        actions.append(f"ğŸ“ **è‚²æˆæ–¹æ³•**: ç¤¾å†…ç ”ä¿®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿæ–½ï¼ˆæœŸé–“: 1-3ãƒ¶æœˆï¼‰")
    else:
        actions.append(f"ğŸ‘¨â€ğŸ« **è‚²æˆæ–¹æ³•**: å¤–éƒ¨å°‚é–€ç ”ä¿® + ç¤¾å†…ãƒ¡ãƒ³ã‚¿ãƒ¼åˆ¶åº¦ã®ä½µç”¨ï¼ˆæœŸé–“: 3-6ãƒ¶æœˆï¼‰")

    # äººæ•°è¦æ¨¡ã«å¿œã˜ãŸå®Ÿæ–½æ–¹æ³•
    if training_need <= 5:
        actions.append(f"ğŸ‘¥ **å®Ÿæ–½è¦æ¨¡**: å°‘äººæ•°ï¼ˆ{training_need}åï¼‰- å€‹åˆ¥ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå‹è‚²æˆ")
    elif training_need <= 15:
        actions.append(f"ğŸ‘¥ **å®Ÿæ–½è¦æ¨¡**: ä¸­è¦æ¨¡ï¼ˆ{training_need}åï¼‰- ã‚°ãƒ«ãƒ¼ãƒ—ç ”ä¿®å½¢å¼")
    else:
        actions.append(f"ğŸ‘¥ **å®Ÿæ–½è¦æ¨¡**: å¤§è¦æ¨¡ï¼ˆ{training_need}åï¼‰- è¤‡æ•°å›ã«åˆ†ã‘ãŸãƒ­ãƒ¼ãƒªãƒ³ã‚°ç ”ä¿®")

    # æ¡ç”¨ã‚‚æ¤œè¨ã™ã¹ãã‹
    if gap_rate > 0.7:
        actions.append(f"ğŸ’¼ **è¿½åŠ æ–½ç­–**: ã‚®ãƒ£ãƒƒãƒ—ãŒå¤§ãã„ãŸã‚ã€å¤–éƒ¨æ¡ç”¨ã‚‚ä¸¦è¡Œæ¤œè¨ã‚’æ¨å¥¨")

    # ç¤¾å†…ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ´»ç”¨
    if skill["ç¾åœ¨ä¿æœ‰ç‡"] > 0.1:
        actions.append(f"ğŸŒŸ **ç¤¾å†…ãƒªã‚½ãƒ¼ã‚¹æ´»ç”¨**: æ—¢å­˜ä¿æœ‰è€…ã‚’ãƒ¡ãƒ³ã‚¿ãƒ¼/ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã¨ã—ã¦æ´»ç”¨")

    return actions


def _generate_timeline(skill: pd.Series) -> Dict[str, str]:
    """ã‚¹ã‚­ãƒ«ç¿’å¾—ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ç”Ÿæˆ"""
    duration = skill["æ¨å®šç¿’å¾—æœŸé–“"]

    timeline = {}

    timeline["ç¬¬1ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ1-2é€±é–“ï¼‰"] = "å¯¾è±¡è€…é¸å®šã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ã€è‚²æˆè¨ˆç”»ç­–å®š"

    if duration <= 3:
        timeline["ç¬¬2ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ1ãƒ¶æœˆï¼‰"] = "é›†ä¸­ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿæ–½"
        timeline["ç¬¬3ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ2-3ãƒ¶æœˆï¼‰"] = "å®Ÿè·µãƒ»OJTã€ã‚¹ã‚­ãƒ«å®šç€ç¢ºèª"
    elif duration <= 6:
        timeline["ç¬¬2ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ1-3ãƒ¶æœˆï¼‰"] = "åŸºç¤ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿæ–½"
        timeline["ç¬¬3ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ4-6ãƒ¶æœˆï¼‰"] = "å®Ÿè·µãƒ»OJTã€ä¸­é–“è©•ä¾¡"
        timeline["ç¬¬4ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ6ãƒ¶æœˆä»¥é™ï¼‰"] = "ã‚¹ã‚­ãƒ«å®šç€ã€æœ€çµ‚è©•ä¾¡"
    else:
        timeline["ç¬¬2ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ1-4ãƒ¶æœˆï¼‰"] = "åŸºç¤ç†è«–ç¿’å¾—"
        timeline["ç¬¬3ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ5-8ãƒ¶æœˆï¼‰"] = "å®Ÿè·µæ¼”ç¿’ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé©ç”¨"
        timeline["ç¬¬4ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ9-12ãƒ¶æœˆï¼‰"] = "å®Ÿå‹™é©ç”¨ãƒ»ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°"
        timeline["ç¬¬5ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ12ãƒ¶æœˆä»¥é™ï¼‰"] = "ãƒã‚¹ã‚¿ãƒªãƒ¼é”æˆã€å¾Œé€²è‚²æˆ"

    return timeline
