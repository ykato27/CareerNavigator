"""
SEMå°‚ç”¨æ¨è–¦ã‚¨ãƒ³ã‚¸ãƒ³

NMFã‚’ä½¿ç”¨ã›ãšã€æ§‹é€ æ–¹ç¨‹å¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚° (SEM) ã®ã¿ã§æ¨è–¦ã‚’è¡Œã„ã¾ã™ã€‚
åŠ›é‡ï¼ˆã‚¹ã‚­ãƒ«ã€è³‡æ ¼ã€æ•™è‚²ï¼‰ã®æ§‹é€ ã‚’SEMã§åˆ†æã—ã€
ãƒ¡ãƒ³ãƒãƒ¼ã®ç¾åœ¨ã®ç¿’å¾—çŠ¶æ³ã‹ã‚‰æ¬¡ã«å–ã‚‹ã¹ãåŠ›é‡ã‚’æ¨è–¦ã—ã¾ã™ã€‚
"""

import logging
import pandas as pd
import numpy as np
from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass

from skillnote_recommendation.ml.skill_domain_sem_model import SkillDomainSEMModel
from skillnote_recommendation.core.models import Recommendation

logger = logging.getLogger(__name__)


@dataclass
class SEMRecommendation:
    """SEMæ¨è–¦çµæœ"""

    competence_code: str
    competence_name: str
    competence_type: str
    category: str
    domain: str
    sem_score: float  # SEMã‚¹ã‚³ã‚¢ï¼ˆ0-1ï¼‰
    current_level: str  # ãƒ¡ãƒ³ãƒãƒ¼ã®ç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«ï¼ˆæœªç¿’å¾—/åˆç´š/ä¸­ç´š/ä¸Šç´šï¼‰
    target_level: str  # æ¨è–¦ã•ã‚Œã‚‹ç›®æ¨™ãƒ¬ãƒ™ãƒ«
    path_coefficient: float  # ãƒ‘ã‚¹ä¿‚æ•°
    is_significant: bool  # çµ±è¨ˆçš„ã«æœ‰æ„ã‹
    reason: str  # æ¨è–¦ç†ç”±


class SEMOnlyRecommender:
    """
    SEMå°‚ç”¨æ¨è–¦ã‚¨ãƒ³ã‚¸ãƒ³

    æ§‹é€ æ–¹ç¨‹å¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆSEMï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€
    åŠ›é‡ï¼ˆã‚¹ã‚­ãƒ«ã€è³‡æ ¼ã€æ•™è‚²ï¼‰ã®ç¿’å¾—æ§‹é€ ã‚’åˆ†æã—ã€
    ãƒ¡ãƒ³ãƒãƒ¼ã®ç¾åœ¨ã®ç¿’å¾—çŠ¶æ³ã‹ã‚‰æ¬¡ã«å–ã‚‹ã¹ãåŠ›é‡ã‚’æ¨è–¦ã—ã¾ã™ã€‚

    ä½¿ç”¨ä¾‹:
        recommender = SEMOnlyRecommender(
            member_competence_df=member_competence,
            competence_master_df=competence_master,
            member_master_df=member_master
        )

        # ãƒ¡ãƒ³ãƒãƒ¼ã®æ¨è–¦ã‚’å–å¾—
        recommendations = recommender.recommend(
            member_code="M001",
            top_n=10
        )
    """

    def __init__(
        self,
        member_competence_df: pd.DataFrame,
        competence_master_df: pd.DataFrame,
        member_master_df: pd.DataFrame,
        num_domain_categories: int = 8,
        confidence_level: float = 0.95,
    ):
        """
        åˆæœŸåŒ–

        Args:
            member_competence_df: ãƒ¡ãƒ³ãƒãƒ¼ç¿’å¾—åŠ›é‡ãƒ‡ãƒ¼ã‚¿
            competence_master_df: åŠ›é‡ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿
            member_master_df: ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿
            num_domain_categories: ã‚¹ã‚­ãƒ«é ˜åŸŸã®åˆ†é¡æ•°ï¼ˆ5ï½10æ¨å¥¨ï¼‰
            confidence_level: ä¿¡é ¼åŒºé–“ã®ãƒ¬ãƒ™ãƒ«ï¼ˆ0.95 = 95%ï¼‰
        """
        self.member_competence_df = member_competence_df.copy()
        self.competence_master_df = competence_master_df.copy()
        self.member_master_df = member_master_df.copy()

        # SEMãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        logger.info("Initializing SkillDomainSEMModel...")
        self.sem_model = SkillDomainSEMModel(
            member_competence_df=member_competence_df,
            competence_master_df=competence_master_df,
            num_domain_categories=num_domain_categories,
            confidence_level=confidence_level,
        )

        logger.info(
            f"SEMOnlyRecommender initialized with {len(self.sem_model.get_all_domains())} domains"
        )

    def recommend(
        self,
        member_code: str,
        top_n: int = 10,
        competence_type: Optional[List[str]] = None,
        domain_filter: Optional[str] = None,
        min_significance: bool = True,
    ) -> List[SEMRecommendation]:
        """
        ãƒ¡ãƒ³ãƒãƒ¼ã¸ã®åŠ›é‡æ¨è–¦ã‚’å®Ÿè¡Œ

        Args:
            member_code: ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰
            top_n: ä¸Šä½Nä»¶ã‚’è¿”ã™
            competence_type: åŠ›é‡ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆSKILL, EDUCATION, LICENSEï¼‰
            domain_filter: é ˜åŸŸãƒ•ã‚£ãƒ«ã‚¿
            min_significance: çµ±è¨ˆçš„ã«æœ‰æ„ãªãƒ‘ã‚¹ä¿‚æ•°ã®ã¿ã‚’ä½¿ç”¨

        Returns:
            SEMRecommendationã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        # ãƒ¡ãƒ³ãƒãƒ¼ã®ç¾åœ¨ã®ç¿’å¾—åŠ›é‡ã‚’å–å¾—
        member_competences = self._get_member_competences(member_code)
        member_competence_codes = set(member_competences['åŠ›é‡ã‚³ãƒ¼ãƒ‰'].values)

        # å…¨ã¦ã®æœªç¿’å¾—åŠ›é‡ã‚’å–å¾—
        all_competences = self.competence_master_df.copy()

        # æ—¢ã«ç¿’å¾—æ¸ˆã¿ã®åŠ›é‡ã‚’é™¤å¤–
        unacquired_competences = all_competences[
            ~all_competences['åŠ›é‡ã‚³ãƒ¼ãƒ‰'].isin(member_competence_codes)
        ]

        # åŠ›é‡ã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if competence_type:
            before_filter = len(unacquired_competences)
            unacquired_competences = unacquired_competences[
                unacquired_competences['åŠ›é‡ã‚¿ã‚¤ãƒ—'].isin(competence_type)
            ]
            after_filter = len(unacquired_competences)
            logger.info(f"åŠ›é‡ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿: {before_filter}ä»¶ â†’ {after_filter}ä»¶ï¼ˆã‚¿ã‚¤ãƒ—: {competence_type}ï¼‰")

        logger.info(f"æœªç¿’å¾—åŠ›é‡æ•°ï¼ˆãƒ•ã‚£ãƒ«ã‚¿å¾Œï¼‰: {len(unacquired_competences)}ä»¶")

        # å„æœªç¿’å¾—åŠ›é‡ã«å¯¾ã—ã¦SEMã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        recommendations = []
        skipped_by_significance = 0
        skipped_by_domain = 0

        for _, comp_row in unacquired_competences.iterrows():
            competence_code = comp_row['åŠ›é‡ã‚³ãƒ¼ãƒ‰']

            # SEMã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            sem_score = self.sem_model.calculate_sem_score(
                member_code=member_code,
                skill_code=competence_code
            )

            # é ˜åŸŸã‚’å–å¾—
            domain = self.sem_model._find_skill_domain(competence_code)

            # é ˜åŸŸãƒ•ã‚£ãƒ«ã‚¿
            if domain_filter and domain != domain_filter:
                skipped_by_domain += 1
                continue

            # ãƒ¡ãƒ³ãƒãƒ¼ã®ç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—
            current_level = self._get_level_name(
                self.sem_model._estimate_current_level(member_code, domain or "ãã®ä»–")
            )

            # æ¨è–¦ç†ç”±ã‚’ç”Ÿæˆ
            reason = self._generate_recommendation_reason(
                member_code=member_code,
                competence_code=competence_code,
                domain=domain,
                sem_score=sem_score,
                current_level=current_level,
            )

            # ãƒ‘ã‚¹ä¿‚æ•°æƒ…å ±ã‚’å–å¾—
            path_info = self._get_path_info(domain, current_level)

            # æœ‰æ„æ€§ãƒ•ã‚£ãƒ«ã‚¿
            if min_significance and path_info and not path_info.get('is_significant', False):
                skipped_by_significance += 1
                continue

            recommendation = SEMRecommendation(
                competence_code=competence_code,
                competence_name=comp_row.get('åŠ›é‡å', competence_code),
                competence_type=comp_row.get('åŠ›é‡ã‚¿ã‚¤ãƒ—', ''),
                category=comp_row.get('åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å', ''),
                domain=domain or 'ãã®ä»–',
                sem_score=sem_score,
                current_level=current_level,
                target_level=self._get_next_level(current_level),
                path_coefficient=path_info.get('coefficient', 0.0) if path_info else 0.0,
                is_significant=path_info.get('is_significant', False) if path_info else False,
                reason=reason,
            )

            recommendations.append(recommendation)

        logger.info(f"æ¨è–¦å€™è£œæ•°ï¼ˆãƒ•ã‚£ãƒ«ã‚¿å¾Œï¼‰: {len(recommendations)}ä»¶")
        if skipped_by_domain > 0:
            logger.info(f"  - é ˜åŸŸãƒ•ã‚£ãƒ«ã‚¿ã§ã‚¹ã‚­ãƒƒãƒ—: {skipped_by_domain}ä»¶")
        if skipped_by_significance > 0:
            logger.info(f"  - æœ‰æ„æ€§ãƒ•ã‚£ãƒ«ã‚¿ã§ã‚¹ã‚­ãƒƒãƒ—: {skipped_by_significance}ä»¶ï¼ˆmin_significance={min_significance}ï¼‰")

        # SEMã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        recommendations.sort(key=lambda x: x.sem_score, reverse=True)

        # ä¸Šä½Nä»¶ã‚’è¿”ã™
        final_recommendations = recommendations[:top_n]
        logger.info(f"æœ€çµ‚æ¨è–¦æ•°: {len(final_recommendations)}ä»¶ï¼ˆtop_n={top_n}ï¼‰")

        return final_recommendations

    def get_member_profile(self, member_code: str) -> Dict[str, Any]:
        """
        ãƒ¡ãƒ³ãƒãƒ¼ã®é ˜åŸŸåˆ¥ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—

        Args:
            member_code: ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰

        Returns:
            {
                'domains': {é ˜åŸŸå: {æ½œåœ¨å¤‰æ•°å: ã‚¹ã‚³ã‚¢}},
                'overall_scores': {é ˜åŸŸå: å¹³å‡ã‚¹ã‚³ã‚¢},
                'acquired_competences': ãƒ¡ãƒ³ãƒãƒ¼ãŒæŒã£ã¦ã„ã‚‹åŠ›é‡ã®ãƒªã‚¹ãƒˆ,
                'total_competences_count': ç¿’å¾—ã—ã¦ã„ã‚‹åŠ›é‡ã®ç·æ•°,
            }
        """
        # é ˜åŸŸåˆ¥ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
        domain_profile = self.sem_model.get_member_domain_profile(member_code)

        # å„é ˜åŸŸã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        overall_scores = {}
        for domain, factor_scores in domain_profile.items():
            if factor_scores:
                overall_scores[domain] = np.mean(list(factor_scores.values()))
            else:
                overall_scores[domain] = 0.0

        # ç¿’å¾—ã—ã¦ã„ã‚‹åŠ›é‡ã‚’å–å¾—
        member_competences = self._get_member_competences(member_code)

        # åŠ›é‡ãƒã‚¹ã‚¿ã¨ãƒãƒ¼ã‚¸ã—ã¦è©³ç´°æƒ…å ±ã‚’å–å¾—
        acquired_competences = pd.merge(
            member_competences,
            self.competence_master_df,
            on='åŠ›é‡ã‚³ãƒ¼ãƒ‰',
            how='left'
        )

        return {
            'domains': domain_profile,
            'overall_scores': overall_scores,
            'acquired_competences': acquired_competences,
            'total_competences_count': len(member_competences),
        }

    def get_competence_gaps(
        self,
        member_code: str,
        domain: Optional[str] = None
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        ãƒ¡ãƒ³ãƒãƒ¼ã®åŠ›é‡ã‚®ãƒ£ãƒƒãƒ—ã‚’é ˜åŸŸåˆ¥ã«å–å¾—

        Args:
            member_code: ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰
            domain: é ˜åŸŸåï¼ˆæŒ‡å®šã—ãŸå ´åˆã€ãã®é ˜åŸŸã®ã¿è¿”ã™ï¼‰

        Returns:
            {
                'é ˜åŸŸå': [
                    {
                        'competence_code': åŠ›é‡ã‚³ãƒ¼ãƒ‰,
                        'competence_name': åŠ›é‡å,
                        'competence_type': åŠ›é‡ã‚¿ã‚¤ãƒ—,
                        'is_acquired': ç¿’å¾—æ¸ˆã¿ã‹ã©ã†ã‹,
                        'level': ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒ¬ãƒ™ãƒ«ï¼ˆç¿’å¾—ã—ã¦ã„ã‚‹å ´åˆï¼‰,
                    }
                ]
            }
        """
        # ãƒ¡ãƒ³ãƒãƒ¼ã®ç¿’å¾—åŠ›é‡
        member_competences = self._get_member_competences(member_code)
        member_competence_codes = set(member_competences['åŠ›é‡ã‚³ãƒ¼ãƒ‰'].values)

        # é ˜åŸŸåˆ¥ã«ã‚®ãƒ£ãƒƒãƒ—ã‚’æ•´ç†
        gaps_by_domain = {}

        domains = [domain] if domain else self.sem_model.get_all_domains()

        for domain_name in domains:
            domain_struct = self.sem_model.domain_structures.get(domain_name)
            if not domain_struct:
                continue

            # ã“ã®é ˜åŸŸã®å…¨ã‚¹ã‚­ãƒ«ã‚’å–å¾—
            domain_skills = []
            for latent_factor in domain_struct.latent_factors:
                domain_skills.extend(latent_factor.observed_skills)

            # ã‚¹ã‚­ãƒ«ã”ã¨ã«ã‚®ãƒ£ãƒƒãƒ—æƒ…å ±ã‚’ä½œæˆ
            gap_info = []
            for skill_code in domain_skills:
                is_acquired = skill_code in member_competence_codes

                # ã‚¹ã‚­ãƒ«æƒ…å ±ã‚’å–å¾—
                skill_info = self.competence_master_df[
                    self.competence_master_df['åŠ›é‡ã‚³ãƒ¼ãƒ‰'] == skill_code
                ]

                if len(skill_info) == 0:
                    continue

                skill_row = skill_info.iloc[0]

                # ç¿’å¾—ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—
                level = None
                if is_acquired:
                    member_skill = member_competences[
                        member_competences['åŠ›é‡ã‚³ãƒ¼ãƒ‰'] == skill_code
                    ]
                    if len(member_skill) > 0:
                        level = member_skill.iloc[0].get('æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«', 0)

                gap_info.append({
                    'competence_code': skill_code,
                    'competence_name': skill_row.get('åŠ›é‡å', skill_code),
                    'competence_type': skill_row.get('åŠ›é‡ã‚¿ã‚¤ãƒ—', ''),
                    'category': skill_row.get('åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å', ''),
                    'is_acquired': is_acquired,
                    'level': level,
                })

            gaps_by_domain[domain_name] = gap_info

        return gaps_by_domain

    def get_all_domains(self) -> List[str]:
        """å…¨é ˜åŸŸåã‚’å–å¾—"""
        return self.sem_model.get_all_domains()

    def get_domain_info(self, domain_name: str) -> Dict[str, Any]:
        """é ˜åŸŸã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        return self.sem_model.get_domain_info(domain_name)

    def get_model_fit_indices(self, domain_name: str) -> Dict[str, float]:
        """
        ãƒ¢ãƒ‡ãƒ«é©åˆåº¦æŒ‡æ¨™ã‚’å–å¾—

        Returns:
            Dict containing:
            - avg_path_coefficient: å¹³å‡ãƒ‘ã‚¹ä¿‚æ•°
            - significant_paths: æœ‰æ„ãªãƒ‘ã‚¹æ•°
            - total_paths: ç·ãƒ‘ã‚¹æ•°
            - avg_loading: å¹³å‡å› å­è² è·é‡
            - avg_effect_size: å¹³å‡åŠ¹æœã‚µã‚¤ã‚ºï¼ˆCohen's dï¼‰
            - variance_explained: èª¬æ˜åˆ†æ•£ï¼ˆRÂ²ï¼‰
            - gfi: é©åˆåº¦æŒ‡æ¨™ï¼ˆGFIï¼‰
            - nfi: è¦æº–é©åˆåº¦æŒ‡æ¨™ï¼ˆNFIï¼‰
        """
        return self.sem_model.get_model_fit_indices(domain_name)

    def visualize_domain_network(
        self,
        domain_name: str,
        layout: str = "spring",
        show_all_edges: bool = False,
        min_coefficient: float = 0.0
    ):
        """
        é ˜åŸŸã®ã‚¹ã‚­ãƒ«ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒ—ãƒ­ãƒƒãƒˆ

        Args:
            domain_name: é ˜åŸŸå
            layout: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ‰‹æ³• ("spring", "circular", "hierarchical")
            show_all_edges: ã™ã¹ã¦ã®ã‚¨ãƒƒã‚¸ã‚’è¡¨ç¤ºï¼ˆæœ‰æ„ã§ãªã„ã‚‚ã®ã‚‚å«ã‚€ï¼‰
            min_coefficient: è¡¨ç¤ºã™ã‚‹æœ€å°ãƒ‘ã‚¹ä¿‚æ•°ï¼ˆçµ¶å¯¾å€¤ï¼‰
        """
        return self.sem_model.visualize_domain_network(
            domain_name=domain_name,
            layout=layout,
            show_all_edges=show_all_edges,
            min_coefficient=min_coefficient
        )

    def _get_member_competences(self, member_code: str) -> pd.DataFrame:
        """ãƒ¡ãƒ³ãƒãƒ¼ã®ç¿’å¾—åŠ›é‡ã‚’å–å¾—"""
        return self.member_competence_df[
            self.member_competence_df['ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰'] == member_code
        ].copy()

    def _get_level_name(self, level: int) -> str:
        """ãƒ¬ãƒ™ãƒ«ç•ªå·ã‚’ãƒ¬ãƒ™ãƒ«åã«å¤‰æ›"""
        level_names = {
            -1: "æœªç¿’å¾—",
            0: "åˆç´š",
            1: "ä¸­ç´š",
            2: "ä¸Šç´š",
        }
        return level_names.get(level, "æœªç¿’å¾—")

    def _get_next_level(self, current_level: str) -> str:
        """æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—"""
        level_progression = {
            "æœªç¿’å¾—": "åˆç´š",
            "åˆç´š": "ä¸­ç´š",
            "ä¸­ç´š": "ä¸Šç´š",
            "ä¸Šç´š": "ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ",
        }
        return level_progression.get(current_level, "åˆç´š")

    def _get_path_info(self, domain: Optional[str], current_level: str) -> Optional[Dict[str, Any]]:
        """ãƒ‘ã‚¹ä¿‚æ•°æƒ…å ±ã‚’å–å¾—"""
        if not domain:
            return None

        domain_struct = self.sem_model.domain_structures.get(domain)
        if not domain_struct:
            return None

        # ç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«ã«å¯¾å¿œã™ã‚‹ãƒ‘ã‚¹ä¿‚æ•°ã‚’å–å¾—
        level_map = {"åˆç´š": 0, "ä¸­ç´š": 1, "ä¸Šç´š": 2}
        level_idx = level_map.get(current_level, -1)

        if level_idx < 0 or level_idx >= len(domain_struct.latent_factors) - 1:
            return None

        current_factor = domain_struct.latent_factors[level_idx]

        for path_coef in domain_struct.path_coefficients:
            if path_coef.from_factor == current_factor.factor_name:
                return {
                    'coefficient': path_coef.coefficient,
                    'is_significant': path_coef.is_significant,
                    'p_value': path_coef.p_value,
                    't_value': path_coef.t_value,
                }

        return None

    def _generate_recommendation_reason(
        self,
        member_code: str,
        competence_code: str,
        domain: Optional[str],
        sem_score: float,
        current_level: str,
    ) -> str:
        """æ¨è–¦ç†ç”±ã‚’ç”Ÿæˆ"""
        if not domain:
            return f"SEMã‚¹ã‚³ã‚¢: {sem_score:.2f}"

        # é ˜åŸŸæƒ…å ±ã‚’å–å¾—
        domain_info = self.sem_model.get_domain_info(domain)

        # ãƒ¡ãƒ³ãƒãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        member_profile = self.sem_model.get_member_domain_profile(member_code)
        domain_scores = member_profile.get(domain, {})

        avg_score = np.mean(list(domain_scores.values())) if domain_scores else 0.0

        # èª¬æ˜æ–‡ã‚’ç”Ÿæˆ
        reason_parts = []

        if current_level == "æœªç¿’å¾—":
            reason_parts.append(
                f"{domain}é ˜åŸŸã®åŸºç¤ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã«æ¨è–¦ã—ã¾ã™ã€‚"
            )
        elif current_level == "åˆç´š":
            reason_parts.append(
                f"{domain}é ˜åŸŸã§åˆç´šãƒ¬ãƒ™ãƒ«ã‚’é”æˆæ¸ˆã¿ã§ã™ã€‚"
                f"æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ä¸­ç´šãƒ¬ãƒ™ãƒ«ã®ã“ã®åŠ›é‡ã‚’æ¨è–¦ã—ã¾ã™ã€‚"
            )
        elif current_level == "ä¸­ç´š":
            reason_parts.append(
                f"{domain}é ˜åŸŸã§ä¸­ç´šãƒ¬ãƒ™ãƒ«ã‚’é”æˆæ¸ˆã¿ã§ã™ã€‚"
                f"ä¸Šç´šãƒ¬ãƒ™ãƒ«ã‚’ç›®æŒ‡ã—ã¦ã“ã®åŠ›é‡ã‚’æ¨è–¦ã—ã¾ã™ã€‚"
            )
        else:
            reason_parts.append(
                f"{domain}é ˜åŸŸã§ä¸Šç´šãƒ¬ãƒ™ãƒ«ã‚’é”æˆæ¸ˆã¿ã§ã™ã€‚"
                f"ã•ã‚‰ãªã‚‹å°‚é–€æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã“ã®åŠ›é‡ã‚’æ¨è–¦ã—ã¾ã™ã€‚"
            )

        reason_parts.append(f"\nSEMã‚¹ã‚³ã‚¢: {sem_score:.2f}")
        reason_parts.append(f"é ˜åŸŸç¿’å¾—åº¦: {avg_score*100:.0f}%")

        return " ".join(reason_parts)

    def get_recommendation_reasoning(
        self,
        member_code: str,
        competence_code: str
    ) -> Optional[Dict[str, Any]]:
        """
        æ¨è–¦ç†ç”±ã‚’è©³ç´°ã«åˆ†æ

        æŒ‡å®šã•ã‚ŒãŸåŠ›é‡ãŒãªãœæ¨è–¦ã•ã‚ŒãŸã‹ã‚’ã€
        ç¿’å¾—æ¸ˆã¿åŠ›é‡ã‹ã‚‰ã®å½±éŸ¿çµŒè·¯ã¨ã¨ã‚‚ã«è¿”ã—ã¾ã™ã€‚

        Args:
            member_code: ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰
            competence_code: æ¨è–¦ã•ã‚ŒãŸåŠ›é‡ã‚³ãƒ¼ãƒ‰

        Returns:
            æ¨è–¦ç†ç”±ã®è©³ç´°æƒ…å ±ï¼ˆã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰ã€ã¾ãŸã¯ None
        """
        # åŠ›é‡æƒ…å ±ã‚’å–å¾—
        competence_info = self.competence_master_df[
            self.competence_master_df['åŠ›é‡ã‚³ãƒ¼ãƒ‰'] == competence_code
        ]

        if competence_info.empty:
            logger.warning(f"Competence {competence_code} not found")
            return None

        competence_row = competence_info.iloc[0]
        target_domain = competence_row.get('åŠ›é‡ãƒ‰ãƒ¡ã‚¤ãƒ³')

        if not target_domain or target_domain not in self.sem_model.domain_structures:
            logger.warning(f"Domain {target_domain} not found for competence {competence_code}")
            return None

        # ãƒ¡ãƒ³ãƒãƒ¼ã®ç¿’å¾—æ¸ˆã¿åŠ›é‡ã‚’å–å¾—
        acquired_competences = self._get_member_competences(member_code)

        # å½±éŸ¿çµŒè·¯ã‚’åˆ†æ
        influences = []
        total_influence = 0.0

        domain_struct = self.sem_model.domain_structures[target_domain]

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåŠ›é‡ãŒã©ã®æ½œåœ¨å¤‰æ•°ã«å±ã™ã‚‹ã‹ã‚’æ¢ã™
        target_latent_factor = None
        target_loading = 0.0

        for latent_factor in domain_struct.latent_factors:
            if competence_code in latent_factor.observed_skills:
                target_latent_factor = latent_factor
                target_loading = latent_factor.factor_loadings.get(competence_code, 0.5)
                break

        if not target_latent_factor:
            logger.warning(f"Target competence {competence_code} not found in domain structure")
            return None

        # ç¿’å¾—æ¸ˆã¿åŠ›é‡ã‹ã‚‰ã®å½±éŸ¿ã‚’è¨ˆç®—
        for _, acq_row in acquired_competences.iterrows():
            acq_code = acq_row['åŠ›é‡ã‚³ãƒ¼ãƒ‰']
            acq_level = acq_row.get('æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«', 0.5)

            # ã“ã®ç¿’å¾—æ¸ˆã¿åŠ›é‡ãŒã©ã®æ½œåœ¨å¤‰æ•°ã«å±ã™ã‚‹ã‹ã‚’æ¢ã™
            source_latent_factor = None
            source_loading = 0.0

            for latent_factor in domain_struct.latent_factors:
                if acq_code in latent_factor.observed_skills:
                    source_latent_factor = latent_factor
                    source_loading = latent_factor.factor_loadings.get(acq_code, 0.5)
                    break

            if not source_latent_factor:
                continue

            # ãƒ‘ã‚¹ä¿‚æ•°ã‚’æ¢ã™
            path_coefficient = 0.0
            is_significant = False
            p_value = 1.0

            for path_coeff in domain_struct.path_coefficients:
                if (path_coeff.from_factor == source_latent_factor.factor_name and
                    path_coeff.to_factor == target_latent_factor.factor_name):
                    path_coefficient = path_coeff.coefficient
                    is_significant = path_coeff.is_significant
                    p_value = path_coeff.p_value
                    break

            if path_coefficient != 0.0:
                # å½±éŸ¿åº¦ã‚’è¨ˆç®—: ãƒ‘ã‚¹ä¿‚æ•° Ã— ç¿’å¾—ãƒ¬ãƒ™ãƒ« Ã— source_loading Ã— target_loading
                influence = path_coefficient * acq_level * source_loading * target_loading
                total_influence += abs(influence)

                acq_info = self.competence_master_df[
                    self.competence_master_df['åŠ›é‡ã‚³ãƒ¼ãƒ‰'] == acq_code
                ]

                influences.append({
                    'source_code': acq_code,
                    'source_name': acq_info.iloc[0]['åŠ›é‡å'] if not acq_info.empty else acq_code,
                    'source_type': acq_info.iloc[0].get('åŠ›é‡ã‚¿ã‚¤ãƒ—', 'UNKNOWN') if not acq_info.empty else 'UNKNOWN',
                    'source_level': acq_level,
                    'source_loading': source_loading,
                    'target_loading': target_loading,
                    'path_coefficient': path_coefficient,
                    'influence': influence,
                    'is_significant': is_significant,
                    'p_value': p_value,
                    'source_latent': source_latent_factor.factor_name,
                    'target_latent': target_latent_factor.factor_name,
                })

        # å½±éŸ¿åº¦ã®å¤§ãã„é †ã«ã‚½ãƒ¼ãƒˆ
        influences.sort(key=lambda x: abs(x['influence']), reverse=True)

        return {
            'target_code': competence_code,
            'target_name': competence_row['åŠ›é‡å'],
            'target_type': competence_row.get('åŠ›é‡ã‚¿ã‚¤ãƒ—', 'UNKNOWN'),
            'target_domain': target_domain,
            'target_latent': target_latent_factor.factor_name,
            'target_loading': target_loading,
            'influences': influences,
            'total_influence': total_influence,
            'num_sources': len(influences),
        }

    def visualize_recommendation_reasoning(
        self,
        member_code: str,
        competence_code: str,
        top_n: int = 5
    ):
        """
        æ¨è–¦ç†ç”±ã‚’ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–

        Args:
            member_code: ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰
            competence_code: æ¨è–¦ã•ã‚ŒãŸåŠ›é‡ã‚³ãƒ¼ãƒ‰
            top_n: è¡¨ç¤ºã™ã‚‹å½±éŸ¿çµŒè·¯ã®æ•°ï¼ˆä¸Šä½Nä»¶ï¼‰

        Returns:
            Plotly Figureã€ã¾ãŸã¯ None
        """
        try:
            import networkx as nx
            import plotly.graph_objects as go
        except ImportError:
            logger.warning("networkx and plotly are required for visualization")
            return None

        reasoning = self.get_recommendation_reasoning(member_code, competence_code)

        if not reasoning or not reasoning['influences']:
            logger.warning(f"No reasoning data for {competence_code}")
            return None

        # ä¸Šä½Nä»¶ã®å½±éŸ¿ã®ã¿ã‚’ä½¿ç”¨
        top_influences = reasoning['influences'][:top_n]

        # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        G = nx.DiGraph()

        # ãƒãƒ¼ãƒ‰è¿½åŠ 
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåŠ›é‡
        G.add_node(
            reasoning['target_code'],
            label=reasoning['target_name'],
            competence_type=reasoning['target_type'],
            node_type='target'
        )

        # å½±éŸ¿å…ƒã®åŠ›é‡
        for inf in top_influences:
            G.add_node(
                inf['source_code'],
                label=inf['source_name'],
                competence_type=inf['source_type'],
                node_type='source',
                level=inf['source_level']
            )

            # ã‚¨ãƒƒã‚¸è¿½åŠ 
            G.add_edge(
                inf['source_code'],
                reasoning['target_code'],
                weight=abs(inf['influence']),
                influence=inf['influence'],
                path_coefficient=inf['path_coefficient'],
                is_significant=inf['is_significant'],
                p_value=inf['p_value']
            )

        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨ˆç®—ï¼ˆéšå±¤çš„ï¼‰
        # ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ã‚’å·¦ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ãƒ‰ã‚’å³ã«é…ç½®
        pos = {}
        source_nodes = [inf['source_code'] for inf in top_influences]
        target_node = reasoning['target_code']

        # ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ã‚’ç¸¦ã«ä¸¦ã¹ã‚‹
        for i, node in enumerate(source_nodes):
            pos[node] = (0, i)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ãƒ‰ã‚’å³å´ã®ä¸­å¤®ã«é…ç½®
        pos[target_node] = (1, (len(source_nodes) - 1) / 2)

        # ã‚¨ãƒƒã‚¸ã‚’æç”»
        edge_traces = []
        for edge_data in top_influences:
            source = edge_data['source_code']
            target = reasoning['target_code']

            x0, y0 = pos[source]
            x1, y1 = pos[target]

            # å½±éŸ¿åº¦ã«å¿œã˜ã¦ã‚¨ãƒƒã‚¸ã®å¤ªã•ã‚’å¤‰æ›´
            width = abs(edge_data['influence']) * 10 + 1

            # æœ‰æ„æ€§ã«å¿œã˜ã¦è‰²ã‚’å¤‰æ›´
            color = "#2E7D32" if edge_data['is_significant'] else "#BDBDBD"

            edge_trace = go.Scatter(
                x=[x0, x1, None],
                y=[y0, y1, None],
                mode="lines",
                line=dict(width=width, color=color),
                hoverinfo="text",
                hovertext=f"å½±éŸ¿åº¦: {edge_data['influence']:.3f}<br>"
                         f"ãƒ‘ã‚¹ä¿‚æ•°: {edge_data['path_coefficient']:.3f}<br>"
                         f"ç¿’å¾—ãƒ¬ãƒ™ãƒ«: {edge_data['source_level']:.2f}<br>"
                         f"på€¤: {edge_data['p_value']:.4f}<br>"
                         f"æœ‰æ„: {'Yes' if edge_data['is_significant'] else 'No'}",
                showlegend=False,
            )
            edge_traces.append(edge_trace)

        # ãƒãƒ¼ãƒ‰ã‚’æç”»
        node_x_source, node_y_source, node_text_source, node_hover_source = [], [], [], []
        node_x_target, node_y_target, node_text_target, node_hover_target = [], [], [], []

        # åŠ›é‡ã‚¿ã‚¤ãƒ—ã”ã¨ã®è‰²
        type_colors = {
            'SKILL': '#1f77b4',
            'EDUCATION': '#ff7f0e',
            'LICENSE': '#2ca02c',
            'UNKNOWN': '#7f7f7f',
        }

        # ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰
        for inf in top_influences:
            node = inf['source_code']
            x, y = pos[node]
            node_x_source.append(x)
            node_y_source.append(y)

            # ãƒãƒ¼ãƒ‰ãƒ†ã‚­ã‚¹ãƒˆ
            label = inf['source_name']
            display_label = label if len(label) <= 20 else label[:17] + "..."
            node_text_source.append(display_label)

            # ãƒ›ãƒãƒ¼æƒ…å ±
            hover_text = f"<b>{label}</b><br>"
            hover_text += f"åŠ›é‡ã‚¿ã‚¤ãƒ—: {inf['source_type']}<br>"
            hover_text += f"ç¿’å¾—ãƒ¬ãƒ™ãƒ«: {inf['source_level']:.2f}<br>"
            hover_text += f"ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {inf['source_loading']:.3f}<br>"
            hover_text += f"â†’ å½±éŸ¿åº¦: {inf['influence']:.3f}"
            node_hover_source.append(hover_text)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ãƒ‰
        x, y = pos[target_node]
        node_x_target.append(x)
        node_y_target.append(y)

        label = reasoning['target_name']
        display_label = label if len(label) <= 20 else label[:17] + "..."
        node_text_target.append(display_label)

        hover_text = f"<b>{label}</b><br>"
        hover_text += f"åŠ›é‡ã‚¿ã‚¤ãƒ—: {reasoning['target_type']}<br>"
        hover_text += f"ã€æ¨è–¦å¯¾è±¡ã€‘<br>"
        hover_text += f"ç·å½±éŸ¿åº¦: {reasoning['total_influence']:.3f}<br>"
        hover_text += f"å½±éŸ¿å…ƒ: {len(top_influences)}å€‹ã®ç¿’å¾—æ¸ˆã¿åŠ›é‡"
        node_hover_target.append(hover_text)

        # ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ã®ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆç¿’å¾—æ¸ˆã¿ï¼‰
        source_trace = go.Scatter(
            x=node_x_source,
            y=node_y_source,
            mode="markers+text",
            text=node_text_source,
            textposition="middle left",
            hoverinfo="text",
            hovertext=node_hover_source,
            marker=dict(
                size=20,
                color='#4CAF50',  # ç·‘ï¼ˆç¿’å¾—æ¸ˆã¿ï¼‰
                line_width=2,
                line_color="#ffffff",
                symbol='circle'
            ),
            name='ç¿’å¾—æ¸ˆã¿åŠ›é‡'
        )

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ãƒ‰ã®ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆæ¨è–¦ï¼‰
        target_trace = go.Scatter(
            x=node_x_target,
            y=node_y_target,
            mode="markers+text",
            text=node_text_target,
            textposition="middle right",
            hoverinfo="text",
            hovertext=node_hover_target,
            marker=dict(
                size=30,
                color='#FF5722',  # ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆæ¨è–¦ï¼‰
                line_width=3,
                line_color="#ffffff",
                symbol='star'
            ),
            name='æ¨è–¦åŠ›é‡'
        )

        # Figureã‚’ä½œæˆ
        fig_data = edge_traces + [source_trace, target_trace]
        fig = go.Figure(data=fig_data)

        fig.update_layout(
            title=f"ğŸ“Š æ¨è–¦ç†ç”±: {reasoning['target_name']}",
            showlegend=True,
            hovermode="closest",
            margin=dict(b=20, l=120, r=120, t=60),
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            height=max(400, len(top_influences) * 80),
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )

        # ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆ
        fig.add_annotation(
            text="çŸ¢å°ã®å¤ªã• = å½±éŸ¿åº¦ã®å¤§ãã•ã€ç·‘ã®çŸ¢å° = çµ±è¨ˆçš„ã«æœ‰æ„",
            xref="paper", yref="paper",
            x=0.5, y=-0.05,
            showarrow=False,
            font=dict(size=10, color="gray"),
            xanchor='center'
        )

        return fig
