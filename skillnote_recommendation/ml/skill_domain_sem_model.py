"""
ã‚¹ã‚­ãƒ«é ˜åŸŸæ½œåœ¨å¤‰æ•°SEMãƒ¢ãƒ‡ãƒ«ï¼ˆæ­£ã—ã„SEMå®Ÿè£…ç‰ˆï¼‰

æ§‹é€ æ–¹ç¨‹å¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆSEMï¼‰ã®ç†è«–ã«åŸºã¥ã„ãŸå®Ÿè£…ï¼š
1. æ¸¬å®šãƒ¢ãƒ‡ãƒ«ï¼ˆMeasurement Modelï¼‰: ã‚¹ã‚­ãƒ« â†’ æ½œåœ¨å¤‰æ•°
2. æ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼ˆStructural Modelï¼‰: æ½œåœ¨å¤‰æ•° â†’ æ½œåœ¨å¤‰æ•°
3. çµ±è¨ˆçš„æ¨å®šã¨æœ‰æ„æ€§æ¤œå®š

å‚è€ƒæ–‡çŒ®:
- Kline, R. B. (2015). Principles and Practice of Structural Equation Modeling
- Bollen, K. A. (1989). Structural Equations with Latent Variables
"""

import logging
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from collections import defaultdict
import scipy.stats as stats

try:
    import networkx as nx
    import plotly.graph_objects as go
    HAS_VISUALIZATION = True
except ImportError:
    HAS_VISUALIZATION = False

logger = logging.getLogger(__name__)


@dataclass
class LatentFactor:
    """æ½œåœ¨å¤‰æ•°ã®å®šç¾©"""

    factor_name: str  # ä¾‹ï¼šã€Œåˆç´šãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€
    domain_category: str  # ä¾‹ï¼šã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€
    level: int  # 0:åˆç´š, 1:ä¸­ç´š, 2:ä¸Šç´š
    observed_skills: List[str] = field(default_factory=list)  # ã“ã®æ½œåœ¨å¤‰æ•°ã«å¯¾å¿œã™ã‚‹ã‚¹ã‚­ãƒ«
    factor_loadings: Dict[str, float] = field(default_factory=dict)  # ã‚¹ã‚­ãƒ«ã®ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    factor_variance: float = 0.0  # æ½œåœ¨å¤‰æ•°ã®åˆ†æ•£


@dataclass
class PathCoefficient:
    """ãƒ‘ã‚¹ä¿‚æ•°ï¼ˆæ§‹é€ ãƒ¢ãƒ‡ãƒ«ã®å› æœåŠ¹æœï¼‰"""

    from_factor: str  # å…ƒã®ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
    to_factor: str  # å…ˆã®ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
    coefficient: float  # ãƒ‘ã‚¹ä¿‚æ•°ï¼ˆæ¨™æº–åŒ–ï¼‰
    std_error: float  # æ¨™æº–èª¤å·®
    t_value: float  # tå€¤
    p_value: float  # på€¤
    ci_lower: float  # ä¿¡é ¼åŒºé–“ä¸‹é™
    ci_upper: float  # ä¿¡é ¼åŒºé–“ä¸Šé™
    is_significant: bool  # p < 0.05ã‹


@dataclass
class MeasurementModel:
    """æ¸¬å®šãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¹ã‚­ãƒ« â†’ æ½œåœ¨å¤‰æ•°ï¼‰"""

    factor_name: str
    factor_loadings: Dict[str, float]  # {ã‚¹ã‚­ãƒ«ã‚³ãƒ¼ãƒ‰: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°}
    measurement_error_variance: Dict[str, float]  # {ã‚¹ã‚­ãƒ«ã‚³ãƒ¼ãƒ‰: æ¸¬å®šèª¤å·®åˆ†æ•£}
    factor_variance: float  # æ½œåœ¨å¤‰æ•°ã®åˆ†æ•£
    item_reliability: float  # ã‚¢ã‚¤ãƒ†ãƒ ä¿¡é ¼æ€§ï¼ˆCronbach's alphaï¼‰


@dataclass
class DomainStructure:
    """ã‚¹ã‚­ãƒ«é ˜åŸŸã®æ§‹é€ å®šç¾©"""

    domain_name: str
    latent_factors: List[LatentFactor] = field(default_factory=list)
    measurement_models: Dict[str, MeasurementModel] = field(default_factory=dict)
    path_coefficients: List[PathCoefficient] = field(default_factory=list)
    model_fit_indices: Dict[str, float] = field(default_factory=dict)  # GFI, RMSEAç­‰


class SkillDomainSEMModel:
    """
    æ­£ã—ã„SEMå®Ÿè£…ï¼šã‚¹ã‚­ãƒ«é ˜åŸŸæ½œåœ¨å¤‰æ•°ãƒ¢ãƒ‡ãƒ«

    ã€ç†è«–çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‘
    1. æ¸¬å®šãƒ¢ãƒ‡ãƒ«: è¦³æ¸¬ã‚¹ã‚­ãƒ« â†’ æ½œåœ¨æ®µéšå¤‰æ•°ï¼ˆåˆç´š/ä¸­ç´š/ä¸Šç´šï¼‰
    2. æ§‹é€ ãƒ¢ãƒ‡ãƒ«: æ½œåœ¨å¤‰æ•°é–“ã®å› æœé–¢ä¿‚ï¼ˆåˆç´šâ†’ä¸­ç´šâ†’ä¸Šç´šï¼‰
    3. çµ±è¨ˆçš„æ¤œå®š: ãƒ‘ã‚¹ä¿‚æ•°ã®æœ‰æ„æ€§ã€ãƒ¢ãƒ‡ãƒ«é©åˆåº¦

    ã€ä½¿ç”¨æ–¹æ³•ã€‘
    model = SkillDomainSEMModel(member_competence_df, competence_master_df)
    sem_score = model.calculate_sem_score("M001", "C001")
    """

    def __init__(
        self,
        member_competence_df: pd.DataFrame,
        competence_master_df: pd.DataFrame,
        num_domain_categories: int = 8,
        confidence_level: float = 0.95,
    ):
        """
        åˆæœŸåŒ–

        Args:
            member_competence_df: ãƒ¡ãƒ³ãƒãƒ¼ç¿’å¾—åŠ›é‡ãƒ‡ãƒ¼ã‚¿
            competence_master_df: åŠ›é‡ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿
            num_domain_categories: ã‚¹ã‚­ãƒ«é ˜åŸŸã®åˆ†é¡æ•°ï¼ˆ5ï½10æ¨å¥¨ï¼‰
            confidence_level: ä¿¡é ¼åŒºé–“ã®ãƒ¬ãƒ™ãƒ«ï¼ˆ0.95 = 95%ï¼‰
        """
        self.member_competence_df = member_competence_df.copy()
        self.competence_master_df = competence_master_df.copy()
        self.num_domain_categories = num_domain_categories
        self.confidence_level = confidence_level

        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        self._validate_data()

        # ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å¤‰æ•°ã‚¹ã‚³ã‚¢ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆå…ˆã«åˆæœŸåŒ–ï¼‰
        self.member_latent_scores: Dict[str, Dict[str, float]] = {}

        # ã‚¹ã‚­ãƒ«é ˜åŸŸã‚’åˆ†é¡
        self.domain_structures: Dict[str, DomainStructure] = {}
        self._build_domain_structures()

        # ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å¤‰æ•°ã‚¹ã‚³ã‚¢ã‚’æ¨å®š
        self._estimate_member_latent_scores()

        logger.info(
            f"SkillDomainSEMModel initialized with {len(self.domain_structures)} domains"
        )

    def _validate_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        required_cols_competence = ["åŠ›é‡ã‚³ãƒ¼ãƒ‰", "åŠ›é‡å", "åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å"]
        missing_cols = [
            col
            for col in required_cols_competence
            if col not in self.competence_master_df.columns
        ]
        if missing_cols:
            raise ValueError(f"competence_master_dfã«å¿…è¦ãªã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {missing_cols}")

        required_cols_member = ["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰", "åŠ›é‡ã‚³ãƒ¼ãƒ‰", "æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«"]
        missing_cols = [
            col
            for col in required_cols_member
            if col not in self.member_competence_df.columns
        ]
        if missing_cols:
            raise ValueError(f"member_competence_dfã«å¿…è¦ãªã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {missing_cols}")

        # æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«ãŒ0-5ã®ç¯„å›²å†…ã‹ç¢ºèª
        if not (
            (self.member_competence_df["æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«"] >= 0)
            & (self.member_competence_df["æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«"] <= 5)
        ).all():
            logger.warning("ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ãŒ0-5ã®ç¯„å›²å¤–ã§ã™")

    def _build_domain_structures(self):
        """ã‚¹ã‚­ãƒ«é ˜åŸŸã®æ§‹é€ ã‚’æ§‹ç¯‰"""
        # åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é›†ç´„
        domain_mapping = self._aggregate_categories()

        # å„é ˜åŸŸã«å¯¾ã—ã¦æ§‹é€ ã‚’è¨­å®š
        for domain_name, skills in domain_mapping.items():
            domain_struct = self._create_domain_structure(domain_name, skills)
            self.domain_structures[domain_name] = domain_struct
            logger.debug(f"Created domain structure for: {domain_name}")

        # æ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼ˆæ½œåœ¨å¤‰æ•°é–“ï¼‰ã‚’æ¨å®š
        self._estimate_structural_model()

    def _aggregate_categories(self) -> Dict[str, List[str]]:
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ã‚¹ã‚­ãƒ«é ˜åŸŸã«é›†ç´„"""
        domain_mapping = defaultdict(list)

        for _, row in self.competence_master_df.iterrows():
            skill_code = row.get("åŠ›é‡ã‚³ãƒ¼ãƒ‰")
            category = row.get("åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å", "ãã®ä»–")

            if pd.isna(category) or not str(category).strip():
                domain = "ãã®ä»–"
            else:
                # æœ€åˆã®ã€Œ>ã€ã¾ã§ã‚’é ˜åŸŸåã¨ã™ã‚‹
                parts = str(category).split(">")
                domain = parts[0].strip() if parts else "ãã®ä»–"

            if skill_code not in domain_mapping[domain]:
                domain_mapping[domain].append(skill_code)

        # é ˜åŸŸæ•°ã®åˆ¶é™
        if len(domain_mapping) > self.num_domain_categories:
            sorted_domains = sorted(
                domain_mapping.items(), key=lambda x: len(x[1]), reverse=True
            )
            limited_domains = {}
            other_skills = []

            for i, (domain, skills) in enumerate(sorted_domains):
                if i < self.num_domain_categories - 1:
                    limited_domains[domain] = skills
                else:
                    other_skills.extend(skills)

            if other_skills:
                limited_domains["ãã®ä»–"] = other_skills

            domain_mapping = limited_domains

        logger.info(f"Aggregated into {len(domain_mapping)} domains")
        return dict(domain_mapping)

    def _create_domain_structure(
        self, domain_name: str, skill_codes: List[str]
    ) -> DomainStructure:
        """
        ã‚¹ã‚­ãƒ«é ˜åŸŸã®æ§‹é€ ã‚’ä½œæˆï¼ˆæ¸¬å®šãƒ¢ãƒ‡ãƒ«ï¼‰

        ã‚¹ã‚­ãƒ«ã‚’ãƒ¬ãƒ™ãƒ«å¸¯åˆ¥ã«åˆ†é¡ã—ã€å„æ½œåœ¨å¤‰æ•°ã«å¯¾å¿œã•ã›ã‚‹
        """
        domain_struct = DomainStructure(domain_name=domain_name)

        # ã‚¹ã‚­ãƒ«ã‚’ãƒ¬ãƒ™ãƒ«å¸¯ã§åˆ†é¡ï¼ˆæ¸¬å®šãƒ¢ãƒ‡ãƒ«ã®åŸºç›¤ï¼‰
        skill_level_map = self._classify_skills_by_level(skill_codes)

        levels = [
            (0, "åˆç´š", skill_level_map.get("low", [])),
            (1, "ä¸­ç´š", skill_level_map.get("mid", [])),
            (2, "ä¸Šç´š", skill_level_map.get("high", [])),
        ]

        # å„æ½œåœ¨å¤‰æ•°ã¨æ¸¬å®šãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰
        for level_id, level_name, level_skills in levels:
            factor_name = f"{domain_name}_{level_name}"

            # æ¸¬å®šãƒ¢ãƒ‡ãƒ«ã‚’æ¨å®š
            measurement_model = self._estimate_measurement_model(
                factor_name, level_skills
            )

            # æ½œåœ¨å¤‰æ•°ã‚’ä½œæˆ
            latent_factor = LatentFactor(
                factor_name=factor_name,
                domain_category=domain_name,
                level=level_id,
                observed_skills=level_skills if level_skills else [skill_codes[0]],
                factor_loadings=measurement_model.factor_loadings,
                factor_variance=measurement_model.factor_variance,
            )
            domain_struct.latent_factors.append(latent_factor)
            domain_struct.measurement_models[factor_name] = measurement_model

        return domain_struct

    def _classify_skills_by_level(self, skill_codes: List[str]) -> Dict[str, List[str]]:
        """
        ã‚¹ã‚­ãƒ«ã‚’ãƒ¬ãƒ™ãƒ«å¸¯åˆ¥ã«åˆ†é¡

        ãƒ¡ãƒ³ãƒãƒ¼ã®ç¿’å¾—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å„ã‚¹ã‚­ãƒ«ã®å…¸å‹çš„ãªãƒ¬ãƒ™ãƒ«ã‚’æ¨å®š
        """
        # ã‚¹ã‚­ãƒ«ã”ã¨ã®å¹³å‡ç¿’å¾—ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        skill_avg_levels = {}

        for skill_code in skill_codes:
            skill_data = self.member_competence_df[
                self.member_competence_df["åŠ›é‡ã‚³ãƒ¼ãƒ‰"] == skill_code
            ]
            if len(skill_data) > 0:
                avg_level = skill_data["æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«"].mean()
            else:
                avg_level = 2.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            skill_avg_levels[skill_code] = avg_level

        # ãƒ¬ãƒ™ãƒ«å¸¯ã§åˆ†é¡ï¼ˆ0-2: åˆç´š, 2-4: ä¸­ç´š, 4-5: ä¸Šç´šï¼‰
        low_skills = [
            code for code, level in skill_avg_levels.items() if level <= 2
        ]
        mid_skills = [
            code for code, level in skill_avg_levels.items() if 2 < level <= 4
        ]
        high_skills = [
            code for code, level in skill_avg_levels.items() if level > 4
        ]

        # ã‚¹ã‚­ãƒ«ãŒåã‚‰ãªã„ã‚ˆã†èª¿æ•´
        if not low_skills and skill_codes:
            low_skills = [skill_codes[0]]
        if not mid_skills and skill_codes:
            mid_skills = [skill_codes[len(skill_codes) // 2]]
        if not high_skills and skill_codes:
            high_skills = [skill_codes[-1]]

        return {"low": low_skills, "mid": mid_skills, "high": high_skills}

    def _estimate_measurement_model(
        self, factor_name: str, observed_skills: List[str]
    ) -> MeasurementModel:
        """
        æ¸¬å®šãƒ¢ãƒ‡ãƒ«ã‚’æ¨å®šï¼ˆã‚¹ã‚­ãƒ« â†’ æ½œåœ¨å¤‰æ•°ï¼‰

        ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆå› å­è² è·é‡ï¼‰ã‚’è¨ˆç®—
        """
        if not observed_skills:
            # ã‚¹ã‚­ãƒ«ãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼
            return MeasurementModel(
                factor_name=factor_name,
                factor_loadings={},
                measurement_error_variance={},
                factor_variance=1.0,
                item_reliability=0.0,
            )

        # ãƒ¡ãƒ³ãƒãƒ¼ã®ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        skill_data = self.member_competence_df[
            self.member_competence_df["åŠ›é‡ã‚³ãƒ¼ãƒ‰"].isin(observed_skills)
        ]

        if len(skill_data) == 0:
            return MeasurementModel(
                factor_name=factor_name,
                factor_loadings={skill: 0.7 for skill in observed_skills},
                measurement_error_variance={skill: 0.51 for skill in observed_skills},
                factor_variance=1.0,
                item_reliability=0.0,
            )

        # æ­£è¦åŒ–ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ï¼ˆ0-1ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        skill_data = skill_data.copy()
        skill_data["normalized_level"] = skill_data["æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«"] / 5.0

        # ã‚¹ã‚­ãƒ«ã”ã¨ã®ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¨ˆç®—ï¼ˆç›¸é–¢ä¿‚æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
        factor_loadings = {}
        measurement_error_variance = {}

        for skill_code in observed_skills:
            skill_levels = skill_data[
                skill_data["åŠ›é‡ã‚³ãƒ¼ãƒ‰"] == skill_code
            ]["normalized_level"].values

            if len(skill_levels) > 1:
                # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° = ã‚¹ã‚­ãƒ«åˆ†æ•£ã®å¹³æ–¹æ ¹ï¼ˆç°¡æ˜“æ¨å®šï¼‰
                loading = np.std(skill_levels) if np.std(skill_levels) > 0 else 0.7
                loading = min(max(loading, 0.3), 0.95)  # 0.3-0.95ã®ç¯„å›²ã«æ­£è¦åŒ–
            else:
                loading = 0.7  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

            error_variance = 1.0 - loading**2

            factor_loadings[skill_code] = loading
            measurement_error_variance[skill_code] = error_variance

        # æ½œåœ¨å¤‰æ•°ã®åˆ†æ•£ï¼ˆå›ºå®š=1.0ï¼‰
        factor_variance = 1.0

        # ä¿¡é ¼æ€§ï¼ˆCronbach's alphaç°¡æ˜“æ¨å®šï¼‰
        if len(factor_loadings) > 1:
            item_reliability = (
                (len(factor_loadings) * np.mean(list(factor_loadings.values())))
                / (1 + (len(factor_loadings) - 1) * 0.5)
                if len(factor_loadings) > 1
                else 0.0
            )
        else:
            item_reliability = 0.0

        return MeasurementModel(
            factor_name=factor_name,
            factor_loadings=factor_loadings,
            measurement_error_variance=measurement_error_variance,
            factor_variance=factor_variance,
            item_reliability=item_reliability,
        )

    def _estimate_member_latent_scores(self):
        """
        ãƒ¡ãƒ³ãƒãƒ¼ã®æ½œåœ¨å¤‰æ•°ã‚¹ã‚³ã‚¢ã‚’æ¨å®šï¼ˆå› å­ã‚¹ã‚³ã‚¢æ³•ï¼‰

        è¦³æ¸¬ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ« Ã— ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§æ½œåœ¨å¤‰æ•°ã‚’æ¨å®š
        """
        member_ids = self.member_competence_df["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"].unique()

        for member_id in member_ids:
            member_data = self.member_competence_df[
                self.member_competence_df["ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰"] == member_id
            ]
            member_scores = {}

            # å„æ½œåœ¨å¤‰æ•°ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            for domain_name, domain_struct in self.domain_structures.items():
                for latent_factor in domain_struct.latent_factors:
                    # ã“ã®æ½œåœ¨å¤‰æ•°ã«å¯¾å¿œã™ã‚‹ã‚¹ã‚­ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    factor_skills = member_data[
                        member_data["åŠ›é‡ã‚³ãƒ¼ãƒ‰"].isin(latent_factor.observed_skills)
                    ]

                    if len(factor_skills) > 0 and latent_factor.factor_loadings:
                        # å› å­ã‚¹ã‚³ã‚¢æ³•ï¼šã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ« Ã— ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
                        weighted_score = 0.0
                        total_loading = 0.0

                        for _, row in factor_skills.iterrows():
                            skill_code = row["åŠ›é‡ã‚³ãƒ¼ãƒ‰"]
                            skill_level = row["æ­£è¦åŒ–ãƒ¬ãƒ™ãƒ«"] / 5.0  # 0-1ã«æ­£è¦åŒ–

                            loading = latent_factor.factor_loadings.get(
                                skill_code, 0.7
                            )
                            weighted_score += skill_level * loading
                            total_loading += loading

                        # åŠ é‡å¹³å‡
                        if total_loading > 0:
                            latent_score = weighted_score / total_loading
                        else:
                            latent_score = 0.0
                    else:
                        latent_score = 0.0

                    # 0-1ã®ç¯„å›²ã«åˆ¶é™
                    latent_score = min(1.0, max(0.0, latent_score))

                    member_scores[latent_factor.factor_name] = latent_score

            self.member_latent_scores[member_id] = member_scores

        logger.info(f"Estimated latent scores for {len(self.member_latent_scores)} members")

    def _estimate_structural_model(self):
        """
        æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã‚’æ¨å®šï¼ˆæ½œåœ¨å¤‰æ•°é–“ã®å› æœåŠ¹æœï¼‰

        å®Ÿéš›ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚¹ã‚³ã‚¢ã‹ã‚‰ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã—ã€çµ±è¨ˆçš„æ¤œå®šã‚’å®Ÿæ–½
        """
        for domain_name, domain_struct in self.domain_structures.items():
            latent_factors = domain_struct.latent_factors

            # åŒã˜é ˜åŸŸå†…ã®æ®µéšçš„é·ç§»ï¼ˆåˆç´šâ†’ä¸­ç´šâ†’ä¸Šç´šï¼‰
            for i in range(len(latent_factors) - 1):
                from_factor = latent_factors[i]
                to_factor = latent_factors[i + 1]

                # ãƒ¡ãƒ³ãƒãƒ¼ã®ã‚¹ã‚³ã‚¢ãƒšã‚¢ã‚’å–å¾—
                from_scores = []
                to_scores = []

                for member_id in self.member_latent_scores.keys():
                    from_score = self.member_latent_scores[member_id].get(
                        from_factor.factor_name
                    )
                    to_score = self.member_latent_scores[member_id].get(
                        to_factor.factor_name
                    )

                    if from_score is not None and to_score is not None:
                        from_scores.append(from_score)
                        to_scores.append(to_score)

                # ãƒ‘ã‚¹ä¿‚æ•°ã‚’æ¨å®š
                path_coef = self._calculate_path_coefficient(
                    from_scores, to_scores, from_factor.factor_name, to_factor.factor_name
                )
                domain_struct.path_coefficients.append(path_coef)

    def _calculate_path_coefficient(
        self,
        from_scores: List[float],
        to_scores: List[float],
        from_name: str,
        to_name: str,
    ) -> PathCoefficient:
        """
        ãƒ‘ã‚¹ä¿‚æ•°ã‚’è¨ˆç®—ï¼ˆçµ±è¨ˆçš„æ¤œå®šä»˜ãï¼‰

        ç›¸é–¢ä¿‚æ•°ã‹ã‚‰tå€¤ã¨på€¤ã‚’è¨ˆç®—
        """
        if len(from_scores) < 3:
            # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            return PathCoefficient(
                from_factor=from_name,
                to_factor=to_name,
                coefficient=0.0,
                std_error=0.0,
                t_value=0.0,
                p_value=1.0,
                ci_lower=0.0,
                ci_upper=0.0,
                is_significant=False,
            )

        # ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
        from_array = np.array(from_scores)
        to_array = np.array(to_scores)

        # æ¨™æº–åŒ–ï¼ˆå¹³å‡0ã€æ¨™æº–åå·®1ï¼‰
        from_std = (from_array - from_array.mean()) / (from_array.std() + 1e-10)
        to_std = (to_array - to_array.mean()) / (to_array.std() + 1e-10)

        # ãƒ‘ã‚¹ä¿‚æ•°ï¼ˆç›¸é–¢ä¿‚æ•°ï¼‰
        coefficient = np.corrcoef(from_std, to_std)[0, 1]
        if np.isnan(coefficient):
            coefficient = 0.0

        # tå€¤ã‚’è¨ˆç®—
        n = len(from_scores)
        if abs(coefficient) < 0.9999:
            t_value = coefficient * np.sqrt(n - 2) / np.sqrt(
                max(1 - coefficient**2, 1e-10)
            )
        else:
            t_value = 0.0

        # på€¤ã‚’è¨ˆç®—ï¼ˆä¸¡å´æ¤œå®šï¼‰
        p_value = 2 * (1 - stats.t.cdf(abs(t_value), n - 2))

        # ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ï¼ˆãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼ã®zå¤‰æ›ï¼‰
        z = 0.5 * np.log((1 + coefficient) / (1 - coefficient + 1e-10))
        se_z = 1.0 / np.sqrt(n - 3)
        z_critical = stats.norm.ppf(
            (1 + self.confidence_level) / 2
        )  # ä¾‹ï¼š95%ãªã‚‰1.96
        ci_lower = np.tanh(z - z_critical * se_z)
        ci_upper = np.tanh(z + z_critical * se_z)

        is_significant = p_value < 0.05

        return PathCoefficient(
            from_factor=from_name,
            to_factor=to_name,
            coefficient=coefficient,
            std_error=1.0 / np.sqrt(n),
            t_value=t_value,
            p_value=p_value,
            ci_lower=ci_lower,
            ci_upper=ci_upper,
            is_significant=is_significant,
        )

    def calculate_sem_score(self, member_code: str, skill_code: str) -> float:
        """
        SEMã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆæ¨è–¦ã‚¹ã‚³ã‚¢ã«çµ±åˆç”¨ï¼‰

        ãƒ¡ãƒ³ãƒãƒ¼ãŒã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—ã™ã‚‹ç¢ºç‡ã‚’ã€ãƒ‘ã‚¹ä¿‚æ•°ã«åŸºã¥ã„ã¦æ¨å®š
        """
        domain = self._find_skill_domain(skill_code)
        if not domain:
            return 0.0

        member_scores = self.member_latent_scores.get(member_code, {})
        domain_struct = self.domain_structures.get(domain)

        if not domain_struct:
            return 0.0

        # ãƒ¡ãƒ³ãƒãƒ¼ã®ã“ã®é ˜åŸŸã§ã®ç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«ã‚’æ¨å®š
        current_level = self._estimate_current_level(member_code, domain)

        # æœ€é«˜ãƒ¬ãƒ™ãƒ«ã«æ—¢ã«åˆ°é”ã—ã¦ã„ã‚‹å ´åˆ
        if current_level >= len(domain_struct.latent_factors) - 1:
            return 0.8  # ç¿’å¾—ç¢ºç‡80%ï¼ˆæ—¢ã«é«˜åº¦ãªã‚¹ã‚­ãƒ«ã‚’æŒã£ã¦ã„ã‚‹ï¼‰

        if current_level < 0:  # ã‚¹ã‚­ãƒ«ãŒãªã„å ´åˆ
            return 0.3  # ç¿’å¾—ç¢ºç‡30%

        # æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã¸ã®ãƒ‘ã‚¹ä¿‚æ•°ã‚’å–å¾—
        current_factor = domain_struct.latent_factors[current_level]
        current_score = member_scores.get(current_factor.factor_name, 0.0)

        # æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã¸ã®ãƒ‘ã‚¹ä¿‚æ•°
        path_coef = None
        for pc in domain_struct.path_coefficients:
            if pc.from_factor == current_factor.factor_name:
                path_coef = pc
                break

        if path_coef and path_coef.is_significant:
            # ãƒ‘ã‚¹ä¿‚æ•°ãŒã‚ã‚‹å ´åˆï¼šç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«ã‚¹ã‚³ã‚¢ Ã— ãƒ‘ã‚¹ä¿‚æ•°
            sem_score = current_score * path_coef.coefficient
        else:
            # ãƒ‘ã‚¹ä¿‚æ•°ãŒãªã„å ´åˆï¼šç¾åœ¨ã®ã‚¹ã‚³ã‚¢ã‚’ãã®ã¾ã¾ä½¿ç”¨
            sem_score = current_score * 0.6

        # 0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
        return min(1.0, max(0.0, sem_score))

    def _estimate_current_level(self, member_code: str, domain_category: str) -> int:
        """
        ãƒ¡ãƒ³ãƒãƒ¼ã®é ˜åŸŸå†…ã§ã®ç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«ã‚’æ¨å®šï¼ˆæ®µéšçš„ï¼‰

        Args:
            member_code: ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰
            domain_category: é ˜åŸŸå

        Returns:
            ãƒ¬ãƒ™ãƒ«ï¼ˆ-1: æœªç¿’å¾—, 0: åˆç´š, 1: ä¸­ç´š, 2: ä¸Šç´šï¼‰
        """
        member_scores = self.member_latent_scores.get(member_code, {})
        domain_struct = self.domain_structures.get(domain_category)

        if not domain_struct:
            return -1

        # ã‚¹ã‚³ã‚¢ã‚’å–å¾—
        scores = [
            member_scores.get(f.factor_name, 0.0) for f in domain_struct.latent_factors
        ]

        if not scores:
            return -1

        # æ®µéšçš„ãªãƒ¬ãƒ™ãƒ«åˆ¤å®š
        max_score = max(scores)

        if max_score < 0.3:
            return -1  # æœªç¿’å¾—
        elif max_score < 0.6:
            return 0  # åˆç´š
        elif max_score < 0.8:
            return 1  # ä¸­ç´š
        else:
            return 2  # ä¸Šç´š

    def _find_skill_domain(self, skill_code: str) -> Optional[str]:
        """ã‚¹ã‚­ãƒ«ã‚³ãƒ¼ãƒ‰ã‹ã‚‰æ‰€å±é ˜åŸŸã‚’æ¤œç´¢"""
        for domain_name, domain_struct in self.domain_structures.items():
            for latent_factor in domain_struct.latent_factors:
                if skill_code in latent_factor.observed_skills:
                    return domain_name
        return None

    def get_domain_info(self, domain_name: str) -> Dict[str, Any]:
        """é ˜åŸŸã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        domain_struct = self.domain_structures.get(domain_name)
        if not domain_struct:
            return {}

        return {
            "domain_name": domain_name,
            "num_latent_factors": len(domain_struct.latent_factors),
            "latent_factors": [
                {
                    "name": f.factor_name,
                    "level": f.level,
                    "num_skills": len(f.observed_skills),
                    "factor_loadings": f.factor_loadings,
                }
                for f in domain_struct.latent_factors
            ],
            "path_coefficients": [
                {
                    "from": p.from_factor,
                    "to": p.to_factor,
                    "coefficient": round(p.coefficient, 3),
                    "p_value": round(p.p_value, 4),
                    "t_value": round(p.t_value, 3),
                    "is_significant": p.is_significant,
                    "ci": (round(p.ci_lower, 3), round(p.ci_upper, 3)),
                }
                for p in domain_struct.path_coefficients
            ],
        }

    def get_all_domains(self) -> List[str]:
        """å…¨é ˜åŸŸåã‚’å–å¾—"""
        return list(self.domain_structures.keys())

    def get_member_domain_profile(self, member_code: str) -> Dict[str, Dict[str, float]]:
        """ãƒ¡ãƒ³ãƒãƒ¼ã®é ˜åŸŸåˆ¥ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        member_scores = self.member_latent_scores.get(member_code, {})
        profile = {}

        for domain_name, domain_struct in self.domain_structures.items():
            profile[domain_name] = {}
            for latent_factor in domain_struct.latent_factors:
                score = member_scores.get(latent_factor.factor_name, 0.0)
                profile[domain_name][latent_factor.factor_name] = score

        return profile

    def get_model_fit_indices(self, domain_name: str) -> Dict[str, float]:
        """
        ãƒ¢ãƒ‡ãƒ«é©åˆåº¦æŒ‡æ¨™ã‚’å–å¾—ï¼ˆæ‹¡å¼µç‰ˆï¼‰

        Returns:
            Dict containing:
            - avg_path_coefficient: å¹³å‡ãƒ‘ã‚¹ä¿‚æ•°
            - significant_paths: æœ‰æ„ãªãƒ‘ã‚¹æ•°
            - total_paths: ç·ãƒ‘ã‚¹æ•°
            - avg_loading: å¹³å‡å› å­è² è·é‡
            - avg_effect_size: å¹³å‡åŠ¹æœã‚µã‚¤ã‚ºï¼ˆCohen's dï¼‰
            - model_variance_explained: èª¬æ˜åˆ†æ•£ï¼ˆRÂ²ï¼‰
            - gfi: é©åˆåº¦æŒ‡æ¨™ï¼ˆGFIï¼‰
            - nfi: è¦æº–é©åˆåº¦æŒ‡æ¨™ï¼ˆNFIï¼‰
        """
        domain_struct = self.domain_structures.get(domain_name)
        if not domain_struct:
            return {}

        # ãƒ‘ã‚¹ä¿‚æ•°ã®çµ±è¨ˆ
        path_coeffs = [p.coefficient for p in domain_struct.path_coefficients]
        significant_paths = sum(
            1 for p in domain_struct.path_coefficients if p.is_significant
        )

        # å¹³å‡å› å­è² è·é‡
        loadings = [
            loading
            for f in domain_struct.latent_factors
            for loading in f.factor_loadings.values()
        ]
        avg_loading = np.mean(loadings) if loadings else 0.0

        # åŠ¹æœã‚µã‚¤ã‚ºï¼ˆCohen's dï¼‰ã®è¨ˆç®—
        # ãƒ‘ã‚¹ä¿‚æ•°ã‚’æ¨™æº–åŒ–ã•ã‚ŒãŸåŠ¹æœã‚µã‚¤ã‚ºã¨ã—ã¦æ‰±ã†
        effect_sizes = [abs(p.coefficient) for p in domain_struct.path_coefficients]
        avg_effect_size = np.mean(effect_sizes) if effect_sizes else 0.0

        # èª¬æ˜åˆ†æ•£ï¼ˆRÂ²ï¼‰ã®æ¨å®š
        # å› å­è² è·é‡ã®äºŒä¹—å¹³å‡ã¨ã—ã¦è¨ˆç®—
        variance_explained = np.mean([l**2 for l in loadings]) if loadings else 0.0

        # GFIï¼ˆé©åˆåº¦æŒ‡æ¨™ï¼‰ã®ç°¡æ˜“æ¨å®š
        # 1ã«è¿‘ã„ã»ã©è‰¯å¥½ï¼ˆ0.9ä»¥ä¸ŠãŒæœ›ã¾ã—ã„ï¼‰
        # æœ‰æ„ãªãƒ‘ã‚¹ã®å‰²åˆã¨å¹³å‡ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‹ã‚‰æ¨å®š
        sig_ratio = significant_paths / len(domain_struct.path_coefficients) if domain_struct.path_coefficients else 0
        gfi = (sig_ratio * 0.5) + (avg_loading * 0.5)

        # NFIï¼ˆè¦æº–é©åˆåº¦æŒ‡æ¨™ï¼‰ã®ç°¡æ˜“æ¨å®š
        # 1ã«è¿‘ã„ã»ã©è‰¯å¥½ï¼ˆ0.9ä»¥ä¸ŠãŒæœ›ã¾ã—ã„ï¼‰
        # ãƒ‘ã‚¹ä¿‚æ•°ã®å¤§ãã•ã¨æœ‰æ„æ€§ã‹ã‚‰æ¨å®š
        nfi = (np.mean([abs(p.coefficient) for p in domain_struct.path_coefficients if p.is_significant])
               if any(p.is_significant for p in domain_struct.path_coefficients) else 0.0)

        return {
            "avg_path_coefficient": np.mean(path_coeffs) if path_coeffs else 0.0,
            "significant_paths": significant_paths,
            "total_paths": len(domain_struct.path_coefficients),
            "avg_loading": avg_loading,
            "avg_effect_size": avg_effect_size,
            "variance_explained": variance_explained,
            "gfi": min(gfi, 1.0),  # 0-1ã®ç¯„å›²ã«åˆ¶é™
            "nfi": min(nfi, 1.0),  # 0-1ã®ç¯„å›²ã«åˆ¶é™
        }

    def get_skill_dependency_graph(self, domain_name: str) -> Optional[Dict[str, Any]]:
        """
        ã‚¹ã‚­ãƒ«ä¾å­˜é–¢ä¿‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆï¼ˆå€‹åˆ¥åŠ›é‡ãƒ¬ãƒ™ãƒ«ï¼‰

        Args:
            domain_name: é ˜åŸŸå

        Returns:
            ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã‚’å«ã‚€ã‚°ãƒ©ãƒ•æ§‹é€ ï¼ˆå€‹åˆ¥ã®åŠ›é‡ã‚’ãƒãƒ¼ãƒ‰ã¨ã—ã¦è¡¨ç¤ºï¼‰
        """
        domain_struct = self.domain_structures.get(domain_name)
        if not domain_struct:
            return None

        # ãƒãƒ¼ãƒ‰æƒ…å ±ï¼ˆå€‹åˆ¥ã®åŠ›é‡ï¼‰
        nodes = []
        skill_to_factor = {}  # ã‚¹ã‚­ãƒ«ãŒã©ã®æ½œåœ¨å› å­ã«å±ã™ã‚‹ã‹ã®ãƒãƒƒãƒ”ãƒ³ã‚°

        for latent_factor in domain_struct.latent_factors:
            for skill_code in latent_factor.observed_skills:
                # åŠ›é‡ãƒã‚¹ã‚¿ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
                skill_info = self.competence_master_df[
                    self.competence_master_df['åŠ›é‡ã‚³ãƒ¼ãƒ‰'] == skill_code
                ]

                if not skill_info.empty:
                    skill_row = skill_info.iloc[0]
                    skill_name = skill_row.get('åŠ›é‡å', skill_code)
                    skill_type = skill_row.get('åŠ›é‡ã‚¿ã‚¤ãƒ—', 'UNKNOWN')

                    # ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—
                    factor_loading = latent_factor.factor_loadings.get(skill_code, 0.0)

                    nodes.append({
                        "id": skill_code,
                        "label": skill_name,
                        "competence_type": skill_type,
                        "factor_name": latent_factor.factor_name,
                        "factor_loading": factor_loading,
                        "level": latent_factor.level,
                    })

                    skill_to_factor[skill_code] = latent_factor.factor_name

        # ã‚¨ãƒƒã‚¸æƒ…å ±ï¼ˆæ½œåœ¨å› å­é–“ã®ãƒ‘ã‚¹ä¿‚æ•°ã«åŸºã¥ãåŠ›é‡é–“ã®é–¢ä¿‚ï¼‰
        edges = []
        for path_coeff in domain_struct.path_coefficients:
            from_factor = path_coeff.from_factor
            to_factor = path_coeff.to_factor

            # ã“ã®2ã¤ã®æ½œåœ¨å› å­ã«å±ã™ã‚‹åŠ›é‡åŒå£«ã®é–¢ä¿‚ã‚’ä½œæˆ
            from_skills = [
                lf for lf in domain_struct.latent_factors
                if lf.factor_name == from_factor
            ]
            to_skills = [
                lf for lf in domain_struct.latent_factors
                if lf.factor_name == to_factor
            ]

            if from_skills and to_skills:
                from_latent = from_skills[0]
                to_latent = to_skills[0]

                # å„åŠ›é‡ãƒšã‚¢ã«å¯¾ã—ã¦ã‚¨ãƒƒã‚¸ã‚’ä½œæˆ
                # ã‚¨ãƒƒã‚¸ã®é‡ã¿ã¯: ãƒ‘ã‚¹ä¿‚æ•° Ã— from_loading Ã— to_loading
                for from_skill in from_latent.observed_skills:
                    from_loading = from_latent.factor_loadings.get(from_skill, 0.5)

                    for to_skill in to_latent.observed_skills:
                        to_loading = to_latent.factor_loadings.get(to_skill, 0.5)

                        # è¤‡åˆçš„ãªå½±éŸ¿åº¦ã‚’è¨ˆç®—
                        combined_coefficient = (
                            path_coeff.coefficient * from_loading * to_loading
                        )

                        edges.append({
                            "from": from_skill,
                            "to": to_skill,
                            "coefficient": combined_coefficient,
                            "path_coefficient": path_coeff.coefficient,
                            "from_loading": from_loading,
                            "to_loading": to_loading,
                            "p_value": path_coeff.p_value,
                            "is_significant": path_coeff.is_significant,
                            "t_value": path_coeff.t_value,
                        })

        return {
            "domain": domain_name,
            "nodes": nodes,
            "edges": edges,
        }

    def visualize_domain_network(
        self,
        domain_name: str,
        layout: str = "spring",
        show_all_edges: bool = False,
        min_coefficient: float = 0.0
    ) -> Optional[go.Figure]:
        """
        é ˜åŸŸã®ã‚¹ã‚­ãƒ«ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ‹¡å¼µç‰ˆï¼‰

        Args:
            domain_name: é ˜åŸŸå
            layout: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ‰‹æ³• ("spring", "circular", "hierarchical")
            show_all_edges: ã™ã¹ã¦ã®ã‚¨ãƒƒã‚¸ã‚’è¡¨ç¤ºï¼ˆæœ‰æ„ã§ãªã„ã‚‚ã®ã‚‚å«ã‚€ï¼‰
            min_coefficient: è¡¨ç¤ºã™ã‚‹æœ€å°ãƒ‘ã‚¹ä¿‚æ•°ï¼ˆçµ¶å¯¾å€¤ï¼‰

        Returns:
            Plotly Figureï¼ˆã‚°ãƒ©ãƒ•ãŒãªã„å ´åˆã¯Noneï¼‰
        """
        if not HAS_VISUALIZATION:
            logger.warning("networkx and plotly are required for visualization")
            return None

        graph_data = self.get_skill_dependency_graph(domain_name)
        if not graph_data or not graph_data["edges"]:
            return None

        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        G = nx.DiGraph()

        # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        for node in graph_data["nodes"]:
            G.add_node(
                node["id"],
                label=node["label"],
                competence_type=node["competence_type"],
                factor_name=node["factor_name"],
                factor_loading=node["factor_loading"],
                level=node["level"]
            )

        # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
        edge_data_list = []
        for edge in graph_data["edges"]:
            if show_all_edges or edge["is_significant"]:
                if abs(edge["coefficient"]) >= min_coefficient:
                    G.add_edge(
                        edge["from"],
                        edge["to"],
                        weight=abs(edge["coefficient"]),
                        coefficient=edge["coefficient"],
                        p_value=edge["p_value"],
                        t_value=edge["t_value"],
                        is_significant=edge["is_significant"]
                    )
                    edge_data_list.append(edge)

        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨ˆç®—
        if layout == "spring":
            try:
                pos = nx.spring_layout(G, k=2, iterations=50, seed=42)
            except Exception as e:
                logger.warning(f"Spring layout failed: {e}, using circular layout")
                pos = nx.circular_layout(G)
        elif layout == "circular":
            pos = nx.circular_layout(G)
        elif layout == "hierarchical":
            try:
                pos = nx.kamada_kawai_layout(G)
            except Exception as e:
                logger.warning(f"Hierarchical layout failed: {e}, using spring layout")
                pos = nx.spring_layout(G, k=2, iterations=50, seed=42)
        else:
            pos = nx.spring_layout(G, k=2, iterations=50, seed=42)

        # ã‚¨ãƒƒã‚¸ã‚’æç”»ï¼ˆãƒ‘ã‚¹ä¿‚æ•°ã«å¿œã˜ãŸå¤ªã•ã¨è‰²ï¼‰
        edge_traces = []
        for edge_data in edge_data_list:
            edge_from = edge_data["from"]
            edge_to = edge_data["to"]

            if edge_from not in pos or edge_to not in pos:
                continue

            x0, y0 = pos[edge_from]
            x1, y1 = pos[edge_to]

            # ãƒ‘ã‚¹ä¿‚æ•°ã®å¤§ãã•ã«å¿œã˜ã¦ã‚¨ãƒƒã‚¸ã®å¤ªã•ã‚’å¤‰æ›´
            width = abs(edge_data["coefficient"]) * 5 + 0.5

            # æœ‰æ„æ€§ã«å¿œã˜ã¦è‰²ã‚’å¤‰æ›´
            color = "#2E7D32" if edge_data["is_significant"] else "#BDBDBD"

            edge_trace = go.Scatter(
                x=[x0, x1, None],
                y=[y0, y1, None],
                mode="lines",
                line=dict(width=width, color=color),
                hoverinfo="text",
                hovertext=f"è¤‡åˆä¿‚æ•°: {edge_data['coefficient']:.3f}<br>"
                         f"ãƒ‘ã‚¹ä¿‚æ•°: {edge_data['path_coefficient']:.3f}<br>"
                         f"From Loading: {edge_data['from_loading']:.3f}<br>"
                         f"To Loading: {edge_data['to_loading']:.3f}<br>"
                         f"tå€¤: {edge_data['t_value']:.3f}<br>"
                         f"på€¤: {edge_data['p_value']:.4f}<br>"
                         f"æœ‰æ„: {'Yes' if edge_data['is_significant'] else 'No'}",
                showlegend=False,
            )
            edge_traces.append(edge_trace)

        # ãƒãƒ¼ãƒ‰ã‚’æç”»ï¼ˆåŠ›é‡ã‚¿ã‚¤ãƒ—ã”ã¨ã«è‰²åˆ†ã‘ï¼‰
        node_x, node_y, node_text, node_hover = [], [], [], []
        node_sizes = []
        node_colors = []

        # åŠ›é‡ã‚¿ã‚¤ãƒ—ã”ã¨ã®è‰²å®šç¾©
        type_colors = {
            'SKILL': '#1f77b4',      # é’
            'EDUCATION': '#ff7f0e',  # ã‚ªãƒ¬ãƒ³ã‚¸
            'LICENSE': '#2ca02c',    # ç·‘
            'UNKNOWN': '#7f7f7f',    # ã‚°ãƒ¬ãƒ¼
        }

        for node in G.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)

            # ãƒãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—
            node_info = next((n for n in graph_data["nodes"] if n["id"] == node), None)

            if node_info:
                competence_type = node_info.get("competence_type", "UNKNOWN")
                factor_loading = node_info.get("factor_loading", 0.5)
                factor_name = node_info.get("factor_name", "")
                level_name = ["åˆç´š", "ä¸­ç´š", "ä¸Šç´š"][node_info.get("level", 0)]

                # ãƒãƒ¼ãƒ‰ãƒ†ã‚­ã‚¹ãƒˆï¼ˆåŠ›é‡åï¼‰
                label = node_info["label"]
                # é•·ã„åå‰ã¯çœç•¥
                display_label = label if len(label) <= 15 else label[:12] + "..."
                node_text.append(display_label)

                # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã‚’ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«å¿œã˜ã¦èª¿æ•´
                node_sizes.append(15 + factor_loading * 30)

                # ãƒãƒ¼ãƒ‰è‰²ã‚’åŠ›é‡ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦è¨­å®š
                node_colors.append(type_colors.get(competence_type, type_colors['UNKNOWN']))

                # ãƒ›ãƒãƒ¼æƒ…å ±
                hover_text = f"<b>{label}</b><br>"
                hover_text += f"åŠ›é‡ã‚¿ã‚¤ãƒ—: {competence_type}<br>"
                hover_text += f"æ½œåœ¨å¤‰æ•°: {factor_name}<br>"
                hover_text += f"ãƒ¬ãƒ™ãƒ«: {level_name}<br>"
                hover_text += f"ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {factor_loading:.3f}<br>"

                # å…¥åŠ›ãƒ»å‡ºåŠ›ã‚¨ãƒƒã‚¸ã®æƒ…å ±
                in_edges = [e for e in edge_data_list if e["to"] == node]
                out_edges = [e for e in edge_data_list if e["from"] == node]

                if in_edges:
                    hover_text += f"<br><b>å…¥åŠ›ãƒ‘ã‚¹ ({len(in_edges)}å€‹):</b><br>"
                    for e in in_edges[:3]:  # æœ€å¤§3ã¤è¡¨ç¤º
                        hover_text += f"  â€¢ {e['coefficient']:.3f} (p={e['p_value']:.3f})<br>"
                    if len(in_edges) > 3:
                        hover_text += f"  ... ä»– {len(in_edges) - 3} å€‹<br>"

                if out_edges:
                    hover_text += f"<br><b>å‡ºåŠ›ãƒ‘ã‚¹ ({len(out_edges)}å€‹):</b><br>"
                    for e in out_edges[:3]:  # æœ€å¤§3ã¤è¡¨ç¤º
                        hover_text += f"  â€¢ {e['coefficient']:.3f} (p={e['p_value']:.3f})<br>"
                    if len(out_edges) > 3:
                        hover_text += f"  ... ä»– {len(out_edges) - 3} å€‹<br>"

                node_hover.append(hover_text)
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                node_text.append(node)
                node_sizes.append(20)
                node_colors.append('#7f7f7f')
                node_hover.append(f"<b>{node}</b>")

        node_trace = go.Scatter(
            x=node_x,
            y=node_y,
            mode="markers+text",
            text=node_text,
            textposition="top center",
            hoverinfo="text",
            hovertext=node_hover,
            marker=dict(
                size=node_sizes,
                color=node_colors,
                line_width=2,
                line_color="#ffffff",
            ),
        )

        # Figureã‚’ä½œæˆï¼ˆã™ã¹ã¦ã®ã‚¨ãƒƒã‚¸ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ãƒãƒ¼ãƒ‰ãƒˆãƒ¬ãƒ¼ã‚¹ï¼‰
        fig_data = edge_traces + [node_trace]
        fig = go.Figure(data=fig_data)

        fig.update_layout(
            title=f"ğŸ“Š {domain_name} - åŠ›é‡ä¾å­˜é–¢ä¿‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆå€‹åˆ¥åŠ›é‡ãƒ¬ãƒ™ãƒ«ï¼‰",
            showlegend=False,
            hovermode="closest",
            margin=dict(b=40, l=5, r=5, t=80),
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            height=700,
            # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
            dragmode='pan',  # ãƒ‘ãƒ³æ“ä½œã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
        )

        # åŠ›é‡ã‚¿ã‚¤ãƒ—ã®å‡¡ä¾‹ã‚’è¿½åŠ 
        fig.add_annotation(
            text="<b>åŠ›é‡ã‚¿ã‚¤ãƒ—:</b> ğŸ”µ SKILLï¼ˆã‚¹ã‚­ãƒ«ï¼‰ | ğŸŸ  EDUCATIONï¼ˆæ•™è‚²ï¼‰ | ğŸŸ¢ LICENSEï¼ˆè³‡æ ¼ï¼‰",
            xref="paper", yref="paper",
            x=0.5, y=1.05,
            showarrow=False,
            font=dict(size=11, color="black"),
            xanchor='center'
        )

        # ã‚ºãƒ¼ãƒ ãƒ»ãƒ‘ãƒ³æ©Ÿèƒ½ã®ãƒ˜ãƒ«ãƒ—ã‚’è¿½åŠ 
        fig.add_annotation(
            text="ãƒ’ãƒ³ãƒˆ: ãƒã‚¦ã‚¹ãƒ›ã‚¤ãƒ¼ãƒ«ã§ã‚ºãƒ¼ãƒ ã€ãƒ‰ãƒ©ãƒƒã‚°ã§ãƒ‘ãƒ³ã€ãƒãƒ¼ãƒ‰/ã‚¨ãƒƒã‚¸ã«ãƒ›ãƒãƒ¼ã§è©³ç´°è¡¨ç¤º<br>"
                 "ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º = ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¼·åº¦ã€ã‚¨ãƒƒã‚¸å¤ªã• = ãƒ‘ã‚¹ä¿‚æ•°Ã—ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç©",
            xref="paper", yref="paper",
            x=0.5, y=-0.05,
            showarrow=False,
            font=dict(size=10, color="gray"),
            xanchor='center'
        )

        return fig
